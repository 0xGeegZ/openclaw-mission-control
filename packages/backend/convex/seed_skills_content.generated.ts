// Generated by scripts/seed-skills-generate.ts. Do not edit by hand.

export const contentBySlug: Record<string, string> = {
  "accessibility-testing": `---
name: accessibility-testing
description: WCAG 2.1 compliance verification, screen reader testing, keyboard navigation, and accessible design patterns
---

# Accessibility Testing

## Overview

Ensure applications are usable by everyone, including users with disabilities. This skill covers WCAG 2.1 compliance, automated testing, and manual verification techniques.

**Use this skill when:**
- Building customer-facing applications
- Meeting legal compliance requirements
- Testing with assistive technologies
- Reviewing UI designs for accessibility
- Improving user experience for all

## WCAG 2.1 Standards

### Accessibility Pyramid

\`\`\`
Level AAA (Enhanced)
├─ All AA requirements plus additional improvements
├─ Target: Government/large organizations
├─ Examples: Extended color contrast, sign language video

Level AA (Recommended)
├─ Most common target for web applications
├─ Legal requirement in many jurisdictions
├─ Examples: Minimum color contrast 4.5:1, accessible forms

Level A (Minimum)
├─ Basic accessibility
└─ Rarely sufficient for modern applications
\`\`\`

**Recommendation:** Aim for WCAG 2.1 Level AA compliance.

## Key Accessibility Principles (POUR)

### 1. Perceivable
**Information must be available to the senses**

**Color Contrast:**
\`\`\`css
/* ❌ Bad: 2.5:1 ratio (fails WCAG AA) */
color: #999;
background-color: #f0f0f0;

/* ✅ Good: 7:1 ratio (exceeds WCAG AAA) */
color: #333;
background-color: #ffffff;
\`\`\`

**Alternative Text for Images:**
\`\`\`html
<!-- ❌ Bad: No alt text -->
<img src="dashboard.png">

<!-- ✅ Good: Descriptive alt text -->
<img src="dashboard.png" alt="Sales dashboard showing 15% growth over last quarter">

<!-- ✅ Good: Decorative image (empty alt) -->
<img src="decorative-border.png" alt="">
\`\`\`

### 2. Operable
**Users must be able to navigate using keyboard**

**Keyboard Navigation:**
\`\`\`html
<!-- ✅ Good: Proper tab order -->
<form>
  <input type="text" placeholder="Username">
  <input type="password" placeholder="Password">
  <button type="submit">Login</button>
</form>

<!-- ❌ Bad: Hidden focus indicator -->
button { outline: none; }

<!-- ✅ Good: Visible focus -->
button:focus {
  outline: 2px solid #0066cc;
  outline-offset: 2px;
}
\`\`\`

**Skip Links:**
\`\`\`html
<!-- Allow keyboard users to skip navigation -->
<body>
  <a href="#main-content" class="skip-link">Skip to main content</a>
  
  <nav><!-- navigation links --></nav>
  
  <main id="main-content">
    <!-- Main content -->
  </main>
</body>

<style>
.skip-link {
  position: absolute;
  left: -9999px;  /* Hidden off-screen */
}

.skip-link:focus {
  left: 0;  /* Visible on focus */
}
</style>
\`\`\`

### 3. Understandable
**Content must be clear and predictable**

**Readable Text:**
\`\`\`html
<!-- ❌ Bad: Complex sentence structure, jargon -->
<p>The utilization of our platform engenders a paradigm shift in productivity metrics.</p>

<!-- ✅ Good: Clear, simple language -->
<p>Our platform helps you work faster and more efficiently.</p>
\`\`\`

**Form Labels:**
\`\`\`html
<!-- ❌ Bad: No label association -->
Email: <input type="email">

<!-- ✅ Good: Label properly associated -->
<label for="email">Email:</label>
<input type="email" id="email">
\`\`\`

### 4. Robust
**Content must work with assistive technologies**

**Semantic HTML:**
\`\`\`html
<!-- ❌ Bad: Using div for everything -->
<div class="button" onclick="submit()">Submit</div>

<!-- ✅ Good: Semantic buttons -->
<button type="submit">Submit</button>

<!-- ❌ Bad: No heading structure -->
<div class="title">Section Title</div>

<!-- ✅ Good: Proper heading hierarchy -->
<h1>Page Title</h1>
<h2>Section Title</h2>
<h3>Subsection</h3>
\`\`\`

## Automated Testing

### axe DevTools

\`\`\`bash
npm install --save-dev @axe-core/react
\`\`\`

\`\`\`javascript
// React component testing
import { axe, toHaveNoViolations } from 'jest-axe';

expect.extend(toHaveNoViolations);

test('should have no accessibility violations', async () => {
  const { container } = render(<MyComponent />);
  const results = await axe(container);
  expect(results).toHaveNoViolations();
});
\`\`\`

### Lighthouse Accessibility Audit

\`\`\`bash
# Generate accessibility report
lighthouse https://example.com --output=json --output-path=./report.json

# Check specific audit
cat report.json | grep -A5 "accessibility"
\`\`\`

### ESLint Accessibility Plugin

\`\`\`bash
npm install --save-dev eslint-plugin-jsx-a11y
\`\`\`

\`\`\`javascript
// .eslintrc.js
{
  "plugins": ["jsx-a11y"],
  "rules": {
    "jsx-a11y/alt-text": "error",
    "jsx-a11y/label-has-associated-control": "error",
    "jsx-a11y/no-static-element-interactions": "warn"
  }
}
\`\`\`

## Manual Testing

### Keyboard Navigation Testing

**Test Procedure:**
1. Disable mouse/trackpad
2. Use \`Tab\` to navigate forward
3. Use \`Shift+Tab\` to navigate backward
4. Use \`Enter\` to activate buttons
5. Use \`Space\` for checkboxes/radio buttons
6. Use arrow keys in menus

**Checklist:**
- [ ] All interactive elements reachable via keyboard
- [ ] Tab order logical and predictable
- [ ] Focus indicator clearly visible
- [ ] No keyboard traps (can't escape with keyboard)
- [ ] Modal dialogs trap focus appropriately

### Screen Reader Testing

**NVDA (Windows, Free):**
\`\`\`bash
# Download: https://www.nvaccess.org/
# Keyboard: Insert + arrow keys to navigate
\`\`\`

**JAWS (Windows, Commercial):**
- Industry standard
- More features than NVDA
- ~\$90/year for updates

**VoiceOver (macOS/iOS, Free):**
\`\`\`bash
# Enable: System Preferences → Accessibility → VoiceOver
# Keyboard: Cmd + F5
# Navigation: VO + arrow keys
\`\`\`

**Test Scenarios:**
- [ ] Page heading announced clearly
- [ ] Form labels associated with inputs
- [ ] Button purposes clear from text
- [ ] Images have meaningful alt text
- [ ] Navigation structure understood
- [ ] Focus order logical

## Color & Contrast

**Color Contrast Checker:**
\`\`\`bash
npm install --save-dev wcag-contrast
\`\`\`

**Testing:**
\`\`\`javascript
import { isLevelAA, isLevelAAA } from 'wcag-contrast';

const foreground = '#333';
const background = '#fff';

console.log(isLevelAA(foreground, background)); // true
console.log(isLevelAAA(foreground, background)); // true
\`\`\`

**Minimum Ratios:**
- Level A: 3:1 (large text) or 4.5:1 (normal text)
- Level AA: 4.5:1 (normal) or 3:1 (large text)
- Level AAA: 7:1 (normal) or 4.5:1 (large text)

## Accessible Component Patterns

### Accessible Buttons

\`\`\`tsx
// ✅ Good button implementation
interface ButtonProps {
  children: React.ReactNode;
  onClick: () => void;
  ariaLabel?: string;
}

export function Button({ children, onClick, ariaLabel }: ButtonProps) {
  return (
    <button 
      onClick={onClick}
      aria-label={ariaLabel}
      className="btn"
    >
      {children}
    </button>
  );
}
\`\`\`

### Accessible Forms

\`\`\`tsx
// ✅ Good form implementation
export function LoginForm() {
  const [email, setEmail] = React.useState('');
  const [errors, setErrors] = React.useState<string[]>([]);
  const errorId = 'email-error';

  return (
    <form>
      <label htmlFor="email">Email:</label>
      <input
        id="email"
        type="email"
        value={email}
        onChange={(e) => setEmail(e.target.value)}
        aria-invalid={errors.length > 0}
        aria-describedby={errors.length > 0 ? errorId : undefined}
      />
      {errors.length > 0 && (
        <div id={errorId} role="alert">
          {errors.join(', ')}
        </div>
      )}
      <button type="submit">Login</button>
    </form>
  );
}
\`\`\`

## Accessibility Checklist

### Design
- [ ] Color contrast meets WCAG AA (4.5:1)
- [ ] No information conveyed by color alone
- [ ] Font size readable (min 14px)
- [ ] Sufficient spacing between clickable elements (min 44px)

### HTML/Markup
- [ ] Semantic HTML used (button, input, etc.)
- [ ] Proper heading hierarchy (h1, h2, h3)
- [ ] Form labels associated with inputs
- [ ] Images have descriptive alt text
- [ ] Links have meaningful text (not "click here")

### Keyboard Navigation
- [ ] All features accessible via keyboard
- [ ] Logical tab order
- [ ] Focus indicator visible
- [ ] No keyboard traps

### Screen Readers
- [ ] Page structure clear
- [ ] Form instructions provided
- [ ] Error messages announced
- [ ] Loading states indicated
- [ ] Modal dialogs properly focused

### Testing
- [ ] Automated tests with axe
- [ ] Lighthouse audit >= 90
- [ ] Keyboard navigation tested
- [ ] Screen reader tested (NVDA or JAWS)

## Common Issues & Fixes

| Issue | Impact | Fix |
|-------|--------|-----|
| Missing alt text | Screen reader users miss images | Add descriptive alt text |
| Poor color contrast | Low vision users can't read | Increase contrast ratio to 4.5:1 |
| No focus indicator | Keyboard users lost | Add visible focus style |
| Form labels missing | Screen reader users confused | Use label elements with htmlFor |
| Click-only interactions | Keyboard users stuck | Add keyboard handlers |

## Resources & Tools

- **WCAG Guidelines:** https://www.w3.org/WAI/WCAG21/quickref/
- **axe DevTools:** https://www.deque.com/axe/devtools/
- **Lighthouse:** Built into Chrome DevTools
- **WebAIM:** https://webaim.org/articles/
- **A11y Project:** https://www.a11yproject.com/

## Related Skills

- @frontend-nextjs - Implement accessible React patterns
- @test-automation - Automate accessibility tests in CI
- @code-review-checklist - Review code for accessibility issues
- @performance-profiling - Monitor performance with screen readers
`,
  "address-github-pr-comments": `---
name: address-github-pr-comments
description: Address GitHub PR Comments
disable-model-invocation: true
---

# Address GitHub PR Comments

## Overview

Process outstanding reviewer feedback, apply required fixes, and draft clear
responses for each GitHub pull-request comment.

## Steps

1. **Sync and audit comments**
   - Pull the latest branch changes
   - Open the PR conversation view and read every unresolved comment
   - Group comments by affected files or themes
2. **Plan resolutions**
   - List the requested code edits for each thread
   - Identify clarifications or additional context you must provide
   - Note any dependencies or blockers before implementing changes
3. **Implement fixes**
   - Apply targeted updates addressing one comment thread at a time
   - Run relevant tests or linters after impactful changes
   - Stage changes with commits that reference the addressed feedback
4. **Draft responses**
   - Summarize the action taken or reasoning provided for each comment
   - Link to commits or lines when clarification helps reviewers verify
   - Highlight any remaining questions or follow-up needs

## Response Checklist

- [ ] All reviewer comments acknowledged
- [ ] Required code changes implemented and tested
- [ ] Clarifying explanations prepared for nuanced threads
- [ ] Follow-up items documented or escalated
- [ ] PR status updated for reviewers
`,
  "api-design": `---
name: api-design
description: RESTful and GraphQL API design, OpenAPI documentation, versioning strategies, and API contracts
---

# API Design

## Overview

Design scalable, maintainable APIs using REST and GraphQL best practices. This skill covers API contracts, OpenAPI documentation, versioning strategies, and backward compatibility.

**Use this skill when:**
- Designing new API endpoints
- Creating API documentation
- Planning API versioning
- Evaluating REST vs. GraphQL trade-offs
- Establishing API governance standards

## REST API Design Principles

### Resource-Oriented Design

Model your API around resources, not actions.

**❌ Wrong (action-oriented):**
\`\`\`
POST /api/users/123/sendEmail
POST /api/invoices/456/generate
GET /api/getActiveUsers
\`\`\`

**✅ Right (resource-oriented):**
\`\`\`
POST /api/users/123/emails          # Create email resource
POST /api/invoices/456/pdf          # Create PDF resource
GET /api/users?status=active        # Query resource
\`\`\`

### HTTP Methods (Semantics Matter)

| Method | Semantics | Idempotent | Safe | Example |
|--------|-----------|-----------|------|---------|
| GET | Retrieve | Yes | Yes | \`GET /api/users/123\` |
| POST | Create | No | No | \`POST /api/users\` |
| PUT | Replace full | Yes | No | \`PUT /api/users/123\` |
| PATCH | Partial update | No | No | \`PATCH /api/users/123\` |
| DELETE | Remove | Yes | No | \`DELETE /api/users/123\` |

### HTTP Status Codes (Standard)

**2xx Success:**
- 200 OK - Successful GET/PUT/PATCH
- 201 Created - Successful POST
- 204 No Content - Successful DELETE

**4xx Client Error:**
- 400 Bad Request - Invalid parameters
- 401 Unauthorized - Missing credentials
- 403 Forbidden - Authenticated but not authorized
- 404 Not Found - Resource doesn't exist
- 422 Unprocessable Entity - Validation failed

**5xx Server Error:**
- 500 Internal Server Error
- 503 Service Unavailable

### API Versioning Strategy

**Option 1: URL Path (Recommended for major breaking changes)**
\`\`\`
GET /api/v1/users
GET /api/v2/users      # Different response structure
\`\`\`

**Option 2: Query Parameter**
\`\`\`
GET /api/users?version=1
GET /api/users?version=2
\`\`\`

**Option 3: Accept Header (Content negotiation)**
\`\`\`
GET /api/users
Accept: application/vnd.company.v1+json
\`\`\`

**Best Practice:**
- Use URL path for major versions (v1, v2, etc.)
- Use headers for minor versions and formats
- Deprecate old versions with warning headers
- Maintain 2 versions max in production

### Pagination

\`\`\`typescript
// Good pagination implementation
GET /api/users?page=2&limit=50

Response: {
  data: [...],
  pagination: {
    page: 2,
    limit: 50,
    total: 1000,
    pages: 20,
    hasMore: true
  }
}
\`\`\`

### Filtering & Sorting

\`\`\`typescript
// Filtering
GET /api/users?status=active&role=admin

// Sorting
GET /api/users?sort=-createdAt,name  // desc by date, asc by name

// Sparse fields (bandwidth optimization)
GET /api/users?fields=id,name,email
\`\`\`

## GraphQL Design

### Schema Best Practices

\`\`\`graphql
type User {
  id: ID!
  email: String!
  name: String!
  createdAt: DateTime!
  posts(first: 10, after: String): PostConnection!
}

type Query {
  user(id: ID!): User
  users(first: 10, after: String): UserConnection!
  search(query: String!): SearchResult!
}

type Mutation {
  createUser(input: CreateUserInput!): CreateUserPayload!
  updateUser(id: ID!, input: UpdateUserInput!): UpdateUserPayload!
  deleteUser(id: ID!): DeleteUserPayload!
}
\`\`\`

### Key Principles

1. **Type Safety:** All fields and arguments strongly typed
2. **Null Safety:** Use \`!\` (non-null) carefully
3. **Connections Pattern:** Use for pagination and filtering
4. **Input Types:** Wrap mutations in dedicated input types
5. **Payloads:** Return status + data from mutations

## API Documentation (OpenAPI/Swagger)

### Minimal OpenAPI Example

\`\`\`yaml
openapi: 3.0.0
info:
  title: User API
  version: 1.0.0
paths:
  /api/users:
    get:
      summary: List users
      parameters:
        - name: page
          in: query
          schema: { type: integer, default: 1 }
        - name: limit
          in: query
          schema: { type: integer, default: 50 }
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                type: object
                properties:
                  data:
                    type: array
                    items:
                      \$ref: '#/components/schemas/User'
    post:
      summary: Create user
      requestBody:
        required: true
        content:
          application/json:
            schema:
              \$ref: '#/components/schemas/CreateUserInput'
      responses:
        '201':
          description: Created
components:
  schemas:
    User:
      type: object
      properties:
        id: { type: string }
        email: { type: string, format: email }
        name: { type: string }
\`\`\`

### Documentation Tools

- **Swagger UI:** Interactive API explorer
- **ReDoc:** Beautiful documentation site
- **Stoplight:** Visual API design tool
- **Postman:** API testing and documentation

## REST vs. GraphQL Decision Matrix

| Criteria | REST | GraphQL |
|----------|------|---------|
| Learning Curve | Low | Steep |
| Performance | Network requests can be multiple | Single request, precise fields |
| Caching | HTTP cache friendly | Requires custom layer |
| Real-time | Polling or WebSocket | Subscriptions built-in |
| Complexity | Low (CRUD) to high (complex queries) | High (query optimization) |
| Team Size | Good for small teams | Better for large teams |

**Use REST for:** Simple CRUD APIs, microservices, public APIs, CDN-able resources

**Use GraphQL for:** Complex nested data, mobile clients, rapid frontend iteration

## API Security

1. **Authentication**
   - JWT tokens for stateless auth
   - OAuth 2.0 for third-party access
   - API keys for service-to-service

2. **Authorization**
   - Role-based access control (RBAC)
   - Scope-based permissions
   - Resource ownership validation

3. **Rate Limiting**
   \`\`\`
   X-RateLimit-Limit: 1000
   X-RateLimit-Remaining: 999
   X-RateLimit-Reset: 1234567890
   \`\`\`

4. **Input Validation**
   - Whitelist allowed characters
   - Length limits
   - Type validation

## Related Skills

- @backend-convex - Implement APIs in Convex
- @doc-generation - Auto-generate API documentation
- @security-hardening - Secure API endpoints
- @performance-profiling - Optimize API response times
`,
  "async-concurrency-patterns": `# async-concurrency-patterns

**Tier:** MEDIUM (Phase 3)  
**Author:** Engineer (Full-Stack)  
**Category:** Async/Concurrency & Performance  
**Status:** Operational  

## Overview
Advanced async/concurrency patterns skill enabling safe Promise handling, race condition prevention, deadlock avoidance, and robust error handling in JavaScript/TypeScript asynchronous code. Critical for production reliability and performance optimization.

## Core Competencies

### 1. Promise Handling
- Promise creation and resolution/rejection patterns
- \`.then()\`, \`.catch()\`, \`.finally()\` semantics
- Async/await syntax and control flow
- Promise chaining vs. composition
- Promise.all(), Promise.race(), Promise.allSettled()
- Promise.any() and iterator patterns
- Microtask queue behavior
- Exception propagation in Promise chains

### 2. Race Conditions
- Identifying race condition vulnerabilities
- State mutation in concurrent contexts
- Resource locking mechanisms
- Atomic operations implementation
- Pessimistic vs. optimistic concurrency control
- CAS (Compare-And-Swap) patterns
- Version-based conflict detection
- Database transaction isolation levels

### 3. Deadlock Prevention
- Circular dependency detection
- Lock ordering enforcement
- Timeout mechanisms
- Resource allocation strategies
- Wait-for graph analysis
- Avoidance vs. detection approaches
- Single-threaded JavaScript event loop understanding
- Promise queue management

### 4. Async Error Handling
- Try/catch in async functions
- Error propagation in Promise chains
- Unhandled rejection prevention
- Error context preservation
- Graceful degradation strategies
- Retry logic with exponential backoff
- Error recovery patterns
- Logging and observability for async errors

## Implementation Patterns

### Safe Promise Composition
\`\`\`javascript
// Parallel execution with error isolation
Promise.allSettled([
  asyncTask1(),
  asyncTask2(),
  asyncTask3()
]).then(results => {
  // Handle both fulfilled and rejected promises
});

// Sequential execution with error handling
async function safeSequence() {
  try {
    const result1 = await asyncTask1();
    const result2 = await asyncTask2(result1);
    return await asyncTask3(result2);
  } catch (error) {
    // Handle and recover
  }
}
\`\`\`

### Race Condition Prevention
\`\`\`javascript
// Using locks for critical sections
const lock = new AsyncLock();
let sharedState = 0;

async function criticalSection() {
  return lock.acquire('key', async () => {
    // Atomic read-modify-write
    const value = sharedState;
    // ... computation ...
    sharedState = value + 1;
  });
}
\`\`\`

### Deadlock Prevention
\`\`\`javascript
// Ordered resource acquisition
async function orderedAcquisition() {
  const lock1 = await acquireLock('resourceA');
  const lock2 = await acquireLock('resourceB');
  
  try {
    // Use both resources
  } finally {
    // Release in reverse order
    await lock2.release();
    await lock1.release();
  }
}

// Timeout protection
const withTimeout = (promise, ms) => 
  Promise.race([
    promise,
    new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Timeout')), ms)
    )
  ]);
\`\`\`

### Error Handling with Retry
\`\`\`javascript
async function retryWithBackoff(fn, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;
      const delay = Math.pow(2, attempt) * 1000;
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw lastError;
}
\`\`\`

## Cross-Functional Validation Points

**@qa Validation:**
- Concurrency test coverage (race conditions)
- Deadlock detection under load
- Error handling completeness
- Promise chain correctness
- Timeout boundary conditions
- Memory leak prevention in async contexts
- Event loop blocking detection

**Test Coverage:**
- Unit: Individual Promise patterns, error scenarios
- Integration: Multi-async component interaction
- Concurrency: Load testing with race condition injection
- E2E: Real-world concurrent workflows

## CLI Tools & Debugging

\`\`\`bash
# Detect unhandled promise rejections
node --unhandled-rejections=strict app.js

# Profile async performance
node --prof app.js
node --prof-process isolate-*.log > profile.txt

# Debug race conditions
node --expose-gc --inspect app.js
# Use Chrome DevTools for Timeline analysis
\`\`\`

## JavaScript/TypeScript Async APIs

### Promise APIs
- \`Promise.all()\` - Wait for all, fail on first error
- \`Promise.allSettled()\` - Wait for all, include results
- \`Promise.race()\` - Return first settled promise
- \`Promise.any()\` - Return first fulfilled promise
- \`Promise.resolve()\` / \`Promise.reject()\`

### Async/Await
- Syntactic sugar for Promise chains
- Exception handling with try/catch
- Sequential vs. parallel patterns
- Generator functions and async iterators

### Control Mechanisms
- \`AbortController\` for cancellation
- Timeout patterns (Promise.race)
- Semaphores for concurrency limiting
- Mutexes for mutual exclusion

## Performance Considerations

| Pattern | Pros | Cons |
|---------|------|------|
| Promise.all() | Parallel execution, fail-fast | One failure cancels all |
| Promise.allSettled() | All results captured | Slower if error expected |
| Sequential async/await | Clear logic, error handling | Slower execution |
| Concurrent async/await | Faster execution | Complex error handling |
| Promise.race() | Fast response | Wastes losing promises |

## Common Pitfalls & Solutions

| Pitfall | Solution |
|---------|----------|
| Forgotten await | Enable linter rules, use ESLint async rules |
| Unhandled rejections | Add global rejection handlers, .catch() all |
| Race conditions in state | Use locks, atomic operations, version control |
| Deadlocks from circular waits | Enforce lock ordering, use timeouts |
| Memory leaks from retained promises | Clean up event listeners, cancel long-running operations |
| Event loop blocking | Use workers for CPU-intensive async work |

## Advanced Patterns

### Semaphore (Concurrency Limiting)
\`\`\`javascript
class Semaphore {
  constructor(max) {
    this.max = max;
    this.current = 0;
    this.queue = [];
  }
  
  async acquire() {
    while (this.current >= this.max) {
      await new Promise(resolve => this.queue.push(resolve));
    }
    this.current++;
  }
  
  release() {
    this.current--;
    this.queue.shift()?.();
  }
}
\`\`\`

### Timeout Wrapper
\`\`\`javascript
function withTimeout(promise, ms, message) {
  let timeoutHandle;
  const timeoutPromise = new Promise((_, reject) => {
    timeoutHandle = setTimeout(() => {
      reject(new Error(message || \`Operation timed out after \${ms}ms\`));
    }, ms);
  });
  
  return Promise.race([promise, timeoutPromise])
    .finally(() => clearTimeout(timeoutHandle));
}
\`\`\`

## Related Skills
- **dependency-management** (async module loading)
- **environment-configuration** (async setup initialization)
- **error-handling-resilience** (error recovery patterns)
- **logging-observability** (async operation tracing)

## References & Standards
- [MDN Promise Documentation](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)
- [JavaScript Async/Await Spec](https://tc39.es/ecma262/#sec-async-function-definitions)
- [Node.js Event Loop Guide](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/)
- [Concurrency Patterns (Go context)](https://pkg.go.dev/context)
- [Database Transaction Isolation](https://en.wikipedia.org/wiki/Isolation_(database_systems))

## Skill Maturity

**Level 1 (Foundational):** Basic Promises, async/await, simple error handling
**Level 2 (Intermediate):** Race condition awareness, retry patterns, concurrency limiting
**Level 3 (Advanced):** Deadlock prevention, complex coordination, performance optimization
**Current:** Level 2 (Intermediate)

---
**Last Updated:** 2026-02-06
**Phase:** 3 (Medium Priority)
`,
  "backend-convex": `---
name: backend-convex
description: Convex schema, queries, mutations, auth guards, and indexes. Follow project patterns in packages/backend/convex.
---

# Backend Convex

Use this skill when working with the Convex backend: schema, queries, mutations, auth guards, and indexes. Follow project patterns in \`packages/backend/convex\`.

## Multi-tenancy (critical)

- Every table except \`accounts\` has \`accountId\`.
- Every query and mutation must scope by \`accountId\`. No cross-account data access.
- Use \`requireAccountMember(ctx, accountId)\` (or \`requireAccountAdmin\` when needed) at the start of user-facing handlers to enforce membership and get \`accountId\` in scope.

## Auth

- **User-facing:** \`requireAuth(ctx)\` for identity only; \`requireAccountMember(ctx, accountId)\` for identity + account membership. Both throw on failure.
- **Service / runtime:** Use \`convex/service/*\` and service auth tokens; do not use user identity in those paths.
- Identity comes from Clerk via \`ctx.auth.getUserIdentity()\`; use \`lib/auth.ts\` helpers only.

## Schema and validators

- Define tables in \`schema.ts\` with \`defineSchema\` and \`defineTable\`. Use \`v\` from \`convex/values\` for all fields.
- Shared union validators (e.g. task status, agent status) live in \`lib/validators.ts\` and are reused in schema and args.
- Define an index for every query pattern; avoid full table scans. Use \`.index("by_account", ["accountId"])\` and compound indexes like \`["accountId", "status"]\` as needed.

## Queries and mutations

- Always use \`.withIndex()\` for queries; match the index fields to the filter (e.g. \`by_account\`, \`by_account_status\`, \`by_account_user\`).
- Use \`.unique()\` for at-most-one results, \`.first()\` or \`.collect()\` for lists. Prefer indexing over \`.filter()\` on large sets.
- Use \`internalQuery\` / \`internalMutation\` for server-only callers (e.g. standup, cron); use \`query\` / \`mutation\` for the HTTP/API surface and always guard with auth.
- Await all async work (e.g. \`ctx.scheduler.runAfter\`, \`ctx.db.patch\`) to avoid floating promises.

## Activity and notifications

- Log meaningful state changes with \`logActivity\` from \`lib/activity.ts\` (e.g. task status, assignments, doc updates).
- Use helpers in \`lib/notifications.ts\` for creating notifications (mentions, assignments, status changes). Notifications are consumed by the runtime for delivery.

## Conventions

- **File naming:** snake_case for all files under \`convex/\` (e.g. \`tasks.ts\`, \`seed_skills_build.ts\`).
- **Imports:** Use \`api\` from \`_generated/api\`, \`Id\`/\`Doc\` from \`_generated/dataModel\`, and server types from \`_generated/server\`.
- **Args:** Validate all arguments with \`v.*\` validators; reuse shared validators from \`lib/validators.ts\` where applicable.

## References

- Convex docs: [Schemas](https://docs.convex.dev/database/schemas), [Indexes](https://docs.convex.dev/database/reading-data/indexes), [Best practices](https://docs.convex.dev/production/best-practices).
- Project: \`packages/backend/convex/README.md\`, \`convex/schema.ts\`, \`convex/lib/auth.ts\`.
`,
  "backlog-refinement": `---
name: backlog-refinement
description: Epic breakdown, user story creation, acceptance criteria definition, MoSCoW prioritization, and backlog hygiene
---

# Backlog Refinement

## Overview

Refine product backlog by breaking down epics into user stories, defining clear acceptance criteria, and prioritizing work using structured frameworks. This skill bridges strategic goals and tactical sprint execution.

**Use this skill when:**
- Breaking down epics into implementable stories
- Writing user stories with clear acceptance criteria
- Prioritizing backlog using MoSCoW or similar framework
- Estimating story complexity with story points
- Grooming backlog for upcoming sprints

## User Story Framework

### Story Structure

\`\`\`markdown
## [Story Title]

**As a** [user type]
**I want to** [capability/feature]
**So that** [business value/outcome]

### Acceptance Criteria

- [ ] Criterion 1 (specific, measurable, testable)
- [ ] Criterion 2
- [ ] Criterion 3

### Definition of Done

- [ ] Code complete and peer reviewed
- [ ] Unit tests passing (>80% coverage)
- [ ] Integration tests passing
- [ ] Documentation updated
- [ ] Deployed to staging
- [ ] QA approved

### Story Points Estimate

5 points (small, <2 days)
\`\`\`

### Good User Stories (INVEST)

- **I**ndependent: Can be developed independently
- **N**egotiable: Details can be discussed
- **V**aluable: Delivers business value
- **E**stimable: Can be estimated by dev team
- **S**mall: Completable in one sprint
- **T**estable: Clear acceptance criteria

### Bad Examples to Avoid

\`\`\`markdown
❌ "Fix the bug" - Too vague, no context
❌ "Add authentication" - Too large, needs breakdown
❌ "Make the UI better" - Not testable, no acceptance criteria
❌ "As a user, I want a feature" - No specific capability stated
\`\`\`

## Epic Breakdown Process

### Step 1: Identify Epic Goal

\`\`\`
Epic: "User authentication and authorization"
Goal: Enable secure user access with role-based permissions
\`\`\`

### Step 2: Break into Stories

Story 1: "User login with email and password"
Story 2: "Password reset flow"
Story 3: "Role-based access control (RBAC)"
Story 4: "OAuth2 social login integration"
Story 5: "Session management and logout"

### Step 3: Add Details to Each Story

\`\`\`markdown
## User Story: Login with Email and Password

**As a** new user
**I want to** log in with email and password
**So that** I can access my account securely

### Acceptance Criteria

- [ ] User can enter email and password
- [ ] Invalid credentials show error message
- [ ] Successful login creates session
- [ ] Session persists across page refreshes
- [ ] User can access protected routes
- [ ] Password is hashed (never stored plaintext)

### Definition of Done

- [ ] Login page UI complete
- [ ] Backend authentication endpoint implemented
- [ ] Session management integrated
- [ ] Error handling for invalid credentials
- [ ] Security audit passed
- [ ] QA approval received

### Estimated Points

8 points (medium, 2-3 days)
\`\`\`

## MoSCoW Prioritization

Prioritize backlog items by business value and urgency:

### Must Have (Critical)
- **Definition:** Essential for product launch, legal/compliance requirements
- **Example:** User authentication, GDPR compliance
- **Target:** 50% of sprint capacity

### Should Have (High)
- **Definition:** Important for user experience but can be deferred
- **Example:** Password reset, email verification
- **Target:** 30% of sprint capacity

### Could Have (Medium)
- **Definition:** Nice-to-have, low business impact
- **Example:** Social login, advanced search
- **Target:** 20% of sprint capacity

### Won't Have (Low)
- **Definition:** Out of scope for current release
- **Example:** Internationalization, advanced analytics
- **Target:** 0% (deferred to future)

## Story Point Estimation

### Fibonacci Scale

- **1 point:** Trivial (1-2 hours, routine task)
- **2 points:** Very small (2-4 hours, straightforward)
- **3 points:** Small (4-8 hours, some complexity)
- **5 points:** Medium (1-2 days, moderate complexity)
- **8 points:** Large (2-3 days, significant complexity)
- **13 points:** Very large (3-5 days, high complexity or unknowns)
- **21+ points:** Too large, needs breakdown

### Estimation Technique: Planning Poker

1. **Present story** to team
2. **Discuss** questions and unknowns
3. **Each estimator** selects a card
4. **Reveal simultaneously**
5. **Discuss outliers** (high/low estimates)
6. **Re-estimate** if needed

## Acceptance Criteria Checklist

Good acceptance criteria should be:

- [ ] **Specific** — Concrete, measurable, not vague
- [ ] **Testable** — QA can verify with clear pass/fail
- [ ] **Realistic** — Achievable within sprint
- [ ] **Business-focused** — Aligned with user value, not technical details
- [ ] **Complete** — Cover main paths and edge cases

**Example:**

\`\`\`markdown
✅ Good:
- User can click "Login" button and be redirected to login page
- Invalid email format shows error "Please enter a valid email"
- After 3 failed attempts, account is locked for 15 minutes
- Session expires after 30 minutes of inactivity

❌ Bad:
- Use JWT tokens (implementation detail)
- Make it secure (vague)
- Database should have user table (not user-facing)
- The system should work (not testable)
\`\`\`

## Backlog Grooming Cadence

### Weekly Refinement

- **Duration:** 1-2 hours
- **Participants:** PM, tech lead, optional engineers
- **Agenda:**
  - Review next 2-3 sprints of backlog
  - Break down large epics into stories
  - Add/update acceptance criteria
  - Estimate new stories
  - Prioritize using MoSCoW

### Sprint Planning (Before Each Sprint)

- **Duration:** 1-2 hours
- **Participants:** Full team
- **Agenda:**
  - Select top-priority items
  - Ensure stories are ready (estimated, criteria defined)
  - Assign to developers
  - Discuss technical approach
  - Commit to capacity

### Sprint Review & Retro (End of Sprint)

- **Duration:** 1-2 hours
- **Participants:** Full team + stakeholders
- **Agenda:**
  - Demo completed stories
  - Get stakeholder feedback
  - Discuss velocity and improvements
  - Update backlog priorities based on feedback

## Related Skills

- @capacity-planning - Estimate team velocity and capacity
- @risk-management - Identify risks in story execution
- @metrics-reporting - Track backlog health and velocity trends
- @sprint-planning - Execute backlog in sprints
`,
  "capacity-planning": `---
name: capacity-planning
description: Team velocity forecasting, resource allocation, sprint capacity planning, estimation techniques, and workload balancing
---

# Capacity Planning

## Overview

Plan team capacity by measuring velocity, forecasting story completion, allocating resources effectively, and balancing workload across sprints. This skill enables realistic sprint planning and prevents overcommitment.

**Use this skill when:**
- Planning sprint capacity before sprint starts
- Forecasting when features will be complete
- Allocating team members to stories
- Identifying bottlenecks and capacity constraints
- Adjusting team composition or workload

## Velocity Measurement

Velocity = sum of story points completed in a sprint

### Tracking Velocity

**Example:** Last 4 sprints

\`\`\`
Sprint 1: 32 points completed
Sprint 2: 41 points completed
Sprint 3: 38 points completed
Sprint 4: 35 points completed

Average Velocity: 36.5 points/sprint
\`\`\`

### Establishing Baseline

**First Sprint (Unproven Team):**
- Start conservative (60% capacity)
- Plan 20-24 points for 4-person team
- Measure actual completion

**Sprints 2-4:**
- Adjust based on actual velocity
- Account for holidays, planned absences
- Target 85-90% capacity utilization

**After Sprint 4+:**
- Use historical average as baseline
- Plan within 5-10% of average
- Account for context-switching, meetings, support

## Capacity Planning Formula

\`\`\`
Available Capacity = Team Size × Hours/Day × Days/Sprint × Utilization%

Example:
4 people × 6 productive hours/day × 10 days × 85% = 204 person-hours
Assuming 1 story point = 4-6 hours
→ Plan 34-51 story points (conservative: ~40 points)
\`\`\`

### Adjusting for Reality

Actual productivity < theoretical maximum due to:

- **Meetings:** 15-20% of time (standups, planning, refinement)
- **Support:** 10-15% (production issues, mentoring, code review)
- **Context-switching:** 5-10% (task switching overhead)
- **Vacation/PTO:** % of team out
- **Onboarding:** New team members reduce velocity initially

**Realistic Utilization:** 70-80% (not 100%)

## Resource Allocation

### Team Composition Model

\`\`\`
Sprint Team: 4 engineers

Distribution by Skill Level:
- 1 Senior (mentoring, complex tasks, architectural decisions)
- 2 Mid-level (core feature development)
- 1 Junior (bug fixes, documentation, small features)

Story Assignment Strategy:
Senior: 5-8 points (complex, risky, mentoring)
Mid-level: 8-13 points each (core work, some complexity)
Junior: 3-5 points (clear scope, low risk)
\`\`\`

### Balancing Workload

**Anti-pattern:** One person gets all complex work

\`\`\`
❌ Bad Distribution:
- Senior: 20 points (overloaded, no mentoring)
- Mid-level: 15 points
- Mid-level: 12 points
- Junior: 3 points (underutilized, doesn't grow)

✅ Good Distribution:
- Senior: 8 points (complex) + mentoring
- Mid-level: 12 points each (balanced)
- Junior: 4 points (clear scope) + learning
\`\`\`

## Sprint Capacity Planning

### Pre-Sprint Planning Meeting

**1. Calculate Available Capacity**

\`\`\`
Team: 4 engineers
Planned absences: 0.5 person (2 days)
Effective team: 3.5 people

Historical velocity: 36 points
Confidence: 85% (after 4 sprints of data)
Conservative estimate: 30 points
Optimistic estimate: 42 points
\`\`\`

**2. Inspect Backlog**

\`\`\`
Top stories by priority:
- Story 1: 5 points (Must Have)
- Story 2: 8 points (Must Have)
- Story 3: 3 points (Must Have)
- Story 4: 13 points (Should Have)
- Story 5: 8 points (Should Have)
\`\`\`

**3. Commit to Stories**

\`\`\`
Must Have: 5 + 8 + 3 = 16 points (REQUIRED)
Should Have: 13 + 8 = 21 points (STRETCH GOAL)
Total: 16 + 21 = 37 points (within 85-90% of velocity)
\`\`\`

**4. Allocate Resources**

\`\`\`
Story 1 (5 pts, Login): Mid-level engineer
Story 2 (8 pts, Database schema): Senior engineer (architect)
Story 3 (3 pts, Bug fix): Junior engineer
Story 4 (13 pts, Authorization): Mid-level + Senior pair
Story 5 (8 pts, API design): Senior engineer (review + feedback)
\`\`\`

## Velocity Forecasting

### Release Planning

**Question:** When will feature X be ready?

**Data:**
- Epic is 40 story points
- Team velocity: 36 points/sprint
- Planned absences: 0.5 days in next 2 weeks

**Calculation:**

\`\`\`
40 points ÷ 36 points/sprint = 1.1 sprints
1.1 sprints × 2 weeks = 2.2 weeks (accounting for sprint boundary)
= ~3 weeks

Accounting for 0.5 days absence: Add 1 day buffer
Revised estimate: 3.5 weeks = End of sprint 2
\`\`\`

### Burndown Tracking

**Sprint Progress:**

\`\`\`
Sprint Started: 37 points committed
Day 1:  37 remaining (0 completed) - kicked off
Day 3:  28 remaining (9 completed) - on track
Day 5:  18 remaining (19 completed) - ahead of schedule
Day 7:  8 remaining (29 completed) - strong progress
Day 9:  2 remaining (35 completed) - finishing strong
Day 10: 0 remaining (37 completed) - SPRINT COMPLETE ✅
\`\`\`

## Constraint Management

### Identifying Bottlenecks

**Database Performance:** Only senior engineer knows tuning
**Solution:** Knowledge sharing session, document patterns

**Third-party Dependency:** Waiting on API response
**Solution:** Build mock, parallelize work

**Skill Gap:** New tech stack, nobody expert
**Solution:** Spike story, allocate learning time

### Adjusting Capacity

**If velocity trending down:**
- Investigate blockers (dependencies, unclear requirements)
- Reduce sprint commitment (lower scope)
- Add resources or pair programming
- Reassess utilization %

**If velocity trending up:**
- Gradually increase commitment (safer to underpromise)
- Celebrate wins, identify what's working
- Invest in tech debt/refactoring

## Capacity Planning Metrics

### Key Indicators

| Metric | Target | Warning |
|--------|--------|---------|
| Velocity Consistency | ±5% variation | >10% variation suggests instability |
| Sprint Completion | 85-95% | <80% = overcommitted, >100% = undercommitted |
| Planned vs Actual | 1:1 ratio | Consistent miss indicates estimation bias |
| Team Utilization | 70-80% | <60% = underutilized, >90% = burnout risk |

### Forecasting Confidence

\`\`\`
After 1 sprint: Low confidence (30%) - too much variance
After 4 sprints: Medium confidence (70%) - pattern emerging
After 8+ sprints: High confidence (85%+) - stable velocity
\`\`\`

## Related Skills

- @backlog-refinement - Estimate and refine stories for capacity planning
- @sprint-planning - Execute capacity plan in sprints
- @metrics-reporting - Track velocity trends and forecast accuracy
- @risk-management - Plan for unknowns and resource constraints
`,
  "clarify-task": `---
name: clarify-task
description: Clarify Task
disable-model-invocation: true
---

# Clarify Task

Before doing ANY coding work on the task I describe:

1. **Ask clarifying questions** - Use 2-4 multiple choice questions to clarify requirements:
   - Data flow and architecture
   - APIs and integrations
   - Authentication/authorization
   - Edge cases and error handling
   - UI/UX expectations (if applicable)

2. **Restate requirements** - After I answer, restate the final requirements in your own words to confirm understanding.

3. **Confirm before proceeding** - ONLY then ask if I want to proceed to planning/implementation.

Keep asking questions until you have enough context to give an accurate & confident answer.
`,
  "code-review-checklist": `---
name: code-review-checklist
description: Code Review
disable-model-invocation: true
---

# Code Review

## Overview

Perform a thorough code review that verifies functionality, maintainability, and
security before approving a change. Focus on architecture, readability,
performance implications, and provide actionable suggestions for improvement.

## Steps

1. **Understand the change**
   - Read the PR description and related issues for context
   - Identify the scope of files and features impacted
   - Note any assumptions or questions to clarify with the author
2. **Validate functionality**
   - Confirm the code delivers the intended behavior
   - Exercise edge cases or guard conditions mentally or by running locally
   - Check error handling paths and logging for clarity
3. **Assess quality**
   - Ensure functions are focused, names are descriptive, and code is readable
   - Watch for duplication, dead code, or missing tests
   - Verify documentation and comments reflect the latest changes
4. **Review security and risk**
   - Look for injection points, insecure defaults, or missing validation
   - Confirm secrets or credentials are not exposed
   - Evaluate performance or scalability impacts of the change

## Review Checklist

### Functionality

- [ ] Intended behavior works and matches requirements
- [ ] Edge cases handled gracefully
- [ ] Error handling is appropriate and informative

### Code Quality

- [ ] Code structure is clear and maintainable
- [ ] No unnecessary duplication or dead code
- [ ] Tests/documentation updated as needed

### Security & Safety

- [ ] No obvious security vulnerabilities introduced
- [ ] Inputs validated and outputs sanitized
- [ ] Sensitive data handled correctly

## Additional Review Notes

- Architecture and design decisions considered
- Performance bottlenecks or regressions assessed
- Coding standards and best practices followed
- Resource management, error handling, and logging reviewed
- Suggested alternatives, additional test cases, or documentation updates
  captured

Provide constructive feedback with concrete examples and actionable guidance for
the author.
`,
  "commit": `---
name: commit
description: Commit current work
disable-model-invocation: true
---

# Commit current work

Commit current work.

## Important

- Prepend GIT_EDITOR=true to all git commands you run, especially the ones looking at diffs, so you can avoid getting blocked as you execute commands
- If you can't get any information from git diff, just using your working memory to determine what has changed

## Instructions

Review each file individually to make sure they're related to the work you just did, then write a brief commit message in the following format:

- Short title description (< 80 characters)
- 2~3 bullet points (< 80 characters) with a quick description

## Notes

- You should only commit work when instructed. Do not keep committing subsquent work unless explicitly told so

Optional: ask me if I would like to push the commit. (Only if I'm not on main)
`,
  "contract-testing-openapi": `---
name: contract-testing-openapi
description: OpenAPI contract testing, API schema validation, service mocking, and ensuring API contracts remain in sync with implementation
---

# Contract Testing & OpenAPI

## Overview

Ensure API contracts remain consistent between consumers and providers through contract testing with OpenAPI schema validation. This skill covers contract-first testing, schema validation, service mocking, and preventing API breaking changes.

**Use this skill when:**
- Evolving API contracts safely
- Ensuring frontend/backend API alignment
- Validating API responses against schema
- Testing service integrations
- Preventing breaking API changes

**Cross-functional pairing:** @engineer **error-handling-resilience** — Contract tests validate error responses conform to API contracts and are properly documented

---

## Contract-First Testing Approach

### What is Contract Testing?

**Traditional API Testing:**

\`\`\`typescript
// ❌ Bad: Tests implementation details
test('GET /users returns array of users', async () => {
  const response = await api.get('/users');
  
  // Tightly coupled to implementation
  expect(response.body[0].name).toBe('John');
  expect(response.body[0].email).toBeDefined();
});
\`\`\`

**Contract Testing:**

\`\`\`typescript
// ✅ Good: Tests the contract (schema)
test('GET /users conforms to OpenAPI schema', async () => {
  const response = await api.get('/users');
  
  // Validates against contract
  expect(response).toConformToSchema(openAPISpec, '/users', 'get');
  expect(response.statusCode).toBe(200);
});
\`\`\`

### Consumer vs. Provider

\`\`\`
Consumer (Frontend)          Provider (Backend)
    ↓                               ↓
  Expects API to return:      Implements API to return:
  - User with id, name        - User(id, name, email)
  - Status 200                - Status 200
    ↓                               ↓
    └──────── OpenAPI Contract ────→
           (Single source of truth)
\`\`\`

---

## OpenAPI Schema Definition

### Basic OpenAPI Schema

\`\`\`yaml
# openapi.yaml
openapi: 3.0.0
info:
  title: OpenClaw API
  version: 1.0.0

paths:
  /api/users:
    get:
      summary: List all users
      responses:
        '200':
          description: List of users
          content:
            application/json:
              schema:
                type: array
                items:
                  \$ref: '#/components/schemas/User'
    
    post:
      summary: Create user
      requestBody:
        required: true
        content:
          application/json:
            schema:
              \$ref: '#/components/schemas/CreateUserRequest'
      responses:
        '201':
          description: User created
          content:
            application/json:
              schema:
                \$ref: '#/components/schemas/User'

  /api/users/{id}:
    get:
      summary: Get user by ID
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User found
          content:
            application/json:
              schema:
                \$ref: '#/components/schemas/User'
        '404':
          description: User not found

components:
  schemas:
    User:
      type: object
      required: [id, name, email, createdAt]
      properties:
        id:
          type: string
        name:
          type: string
        email:
          type: string
          format: email
        createdAt:
          type: string
          format: date-time

    CreateUserRequest:
      type: object
      required: [name, email]
      properties:
        name:
          type: string
        email:
          type: string
          format: email
\`\`\`

---

## Schema Validation Testing

### Validate Response Against Schema

\`\`\`typescript
import Ajv from 'ajv';
import openAPISpec from './openapi.yaml';

const ajv = new Ajv();

// Compile schemas from OpenAPI spec
const userListSchema = ajv.getSchema('#/components/schemas/User');
const userSchema = ajv.getSchema('#/components/schemas/User');

test('GET /users response conforms to schema', async () => {
  const response = await fetch('http://localhost:3000/api/users');
  const data = await response.json();
  
  // Validate each user
  const valid = data.every(user => userSchema(user));
  expect(valid).toBe(true);
});

test('Error responses conform to error schema', async () => {
  const response = await fetch('http://localhost:3000/api/users/invalid');
  const data = await response.json();
  
  // Validate error format
  expect(data.error).toBeDefined();
  expect(data.statusCode).toBe(404);
});
\`\`\`

### Using OpenAPI Validator

\`\`\`bash
npm install --save-dev openapi-validator

# Validate API implementation
openapi-validator validate \\
  --spec openapi.yaml \\
  --server http://localhost:3000
\`\`\`

---

## Consumer Contract Tests

\`\`\`typescript
import { PactV3 } from '@pact-foundation/pact';

const provider = new PactV3({
  consumer: 'WebApp',
  provider: 'UserAPI'
});

describe('User API Consumer Contract', () => {
  test('GET /users returns user list', async () => {
    await provider
      .addInteraction({
        states: [{ description: 'users exist' }],
        uponReceiving: 'a request for all users',
        withRequest: {
          method: 'GET',
          path: '/api/users',
        },
        willRespondWith: {
          status: 200,
          body: [
            {
              id: expect.any(String),
              name: expect.any(String),
              email: expect.any(String),
              createdAt: expect.any(String),
            },
          ],
        },
      })
      .executeTest(async (mockServer) => {
        const response = await fetch(\`\${mockServer.url}/api/users\`);
        const users = await response.json();
        
        expect(users).toHaveLength(1);
        expect(users[0].id).toBeDefined();
      });
  });

  test('POST /users creates user', async () => {
    await provider
      .addInteraction({
        uponReceiving: 'a request to create a user',
        withRequest: {
          method: 'POST',
          path: '/api/users',
          body: {
            name: 'Jane Doe',
            email: 'jane@example.com',
          },
        },
        willRespondWith: {
          status: 201,
          body: {
            id: expect.any(String),
            name: 'Jane Doe',
            email: 'jane@example.com',
            createdAt: expect.any(String),
          },
        },
      })
      .executeTest(async (mockServer) => {
        const response = await fetch(\`\${mockServer.url}/api/users\`, {
          method: 'POST',
          body: JSON.stringify({ name: 'Jane Doe', email: 'jane@example.com' }),
        });
        
        expect(response.status).toBe(201);
      });
  });
});
\`\`\`

---

## Service Mocking for Contract Tests

### Mock Service Using OpenAPI Schema

\`\`\`typescript
import { createMockServer } from 'openapi-backend';

const mockAPI = createMockServer({
  definition: './openapi.yaml',
  strict: true,  // Strict schema validation
});

// Mock GET /users
mockAPI.mock.register({
  operationId: 'listUsers',
  handler: (_c, _req, res) => {
    res.status(200).json([
      { id: '1', name: 'John', email: 'john@example.com', createdAt: '2026-01-01T00:00:00Z' },
      { id: '2', name: 'Jane', email: 'jane@example.com', createdAt: '2026-01-02T00:00:00Z' },
    ]);
  },
});

// Mock POST /users
mockAPI.mock.register({
  operationId: 'createUser',
  handler: (c, _req, res) => {
    const { name, email } = c.request.body;
    res.status(201).json({
      id: 'new-id',
      name,
      email,
      createdAt: new Date().toISOString(),
    });
  },
});

test('create user via mocked API', async () => {
  const response = await mockAPI.handleRequest({
    method: 'POST',
    url: '/api/users',
    body: { name: 'Bob', email: 'bob@example.com' },
  });
  
  expect(response.status).toBe(201);
  expect(response.body.name).toBe('Bob');
});
\`\`\`

---

## Error Contract Testing

### Validate Error Responses

\`\`\`typescript
const errorSchema = {
  type: 'object',
  required: ['error', 'statusCode', 'message'],
  properties: {
    error: { type: 'string' },
    statusCode: { type: 'number' },
    message: { type: 'string' },
    details: { type: 'object' },
  },
};

test('404 error conforms to contract', async () => {
  const response = await fetch('http://localhost:3000/api/users/invalid');
  const data = await response.json();
  
  expect(response.status).toBe(404);
  expect(ajv.validate(errorSchema, data)).toBe(true);
});

test('validation error includes details', async () => {
  const response = await fetch('http://localhost:3000/api/users', {
    method: 'POST',
    body: JSON.stringify({ name: '' }),  // Invalid
  });
  const data = await response.json();
  
  expect(response.status).toBe(400);
  expect(data.error).toBe('VALIDATION_ERROR');
  expect(data.details).toBeDefined();
});
\`\`\`

---

## Contract Evolution

### Breaking vs. Non-Breaking Changes

\`\`\`yaml
# ✅ Non-breaking: Add optional field
User:
  properties:
    id: { type: string }
    name: { type: string }
    email: { type: string }
    phone: { type: string }  # NEW: Optional

# ❌ Breaking: Remove required field
User:
  required: [id, name]
  # email removed (breaking!)

# ❌ Breaking: Change type
User:
  properties:
    age: { type: number }  # Was: string (breaking!)

# ✅ Non-breaking: Relax constraint
User:
  properties:
    phone: { type: string }  # Removed required constraint
\`\`\`

### Versioning Strategy

\`\`\`yaml
# api/v1/openapi.yaml - Stable
# api/v2/openapi.yaml - New features, deprecated endpoints

paths:
  /api/v1/users:
    get:
      # stable endpoint
  
  /api/v2/users:
    get:
      # new endpoint with enhancements
\`\`\`

---

## CI/CD Contract Validation

### GitHub Actions

\`\`\`yaml
# .github/workflows/contract-test.yml
name: Contract Tests

on: [push, pull_request]

jobs:
  contract:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      
      - run: npm ci
      - run: npm run test:contract
      
      - name: Validate OpenAPI schema
        run: npx openapi-validator validate --spec openapi.yaml
      
      - name: Check for breaking changes
        run: |
          npx openapi-diff openapi-old.yaml openapi.yaml \\
            --fail-on-breaking
\`\`\`

---

## Contract Testing Checklist

- [ ] OpenAPI schema defined for all endpoints
- [ ] Consumer contract tests written
- [ ] Schema validation integrated in tests
- [ ] Error responses conform to schema
- [ ] Breaking changes detected in CI/CD
- [ ] Non-breaking changes allowed
- [ ] Mock server validates against schema
- [ ] API versioning strategy defined
- [ ] Contract tests run before deployment
- [ ] Pact/OpenAPI contracts shared between teams

---

## Related Skills

- @error-handling-resilience - Error responses must conform to contracts
- @test-coverage-analysis - Coverage for contract test paths
- @api-design - Define contracts before implementation
- @regression-testing - Detect contract regressions
`,
  "create-pr": `---
name: create-pr
description: PR Creation Command
disable-model-invocation: true
---

---

description: |
Complete PR creation workflow: analyze changes, stage/commit if needed,
create branch (if not already), generate PR title & description, and
submit PR using GitHub CLI. Handles the full end-to-end process.
globs:

- "\\*_/_"
  alwaysApply: false

---

# PR Creation Command

When invoked, execute the following workflow:

## 1. Analyze Current State

**Check git status:**

\`\`\`bash
git status
git diff --stat
git log --oneline dev..HEAD
\`\`\`

**Determine action needed:**

- If uncommitted changes exist → stage and commit them
- If on dev → create feature branch
- If commits exist on branch → check if PR already exists

## 2. Handle Uncommitted Changes (if present)

**Stage relevant files:**

\`\`\`bash
git add <files>
\`\`\`

**Generate commit message:**

- Format: \`type(scope): description\`
- Types: \`feat\`, \`fix\`, \`refactor\`, \`test\`, \`docs\`, \`chore\`, \`perf\`
- Keep under 72 characters
- Example: \`feat(rules): preserve context on rule blocking\`

**Commit:**

\`\`\`bash
git commit -m "type(scope): description"
\`\`\`

## 3. Ensure Feature Branch (if needed)

**If currently on dev, create branch:**

- Format: \`<type>/<short-description>\`
- Example: \`feat/context-on-failure\`, \`fix/rule-evaluation\`
- Keep concise, use kebab-case

\`\`\`bash
git checkout -b <branch-name>
\`\`\`

## 4. Analyze Changes for PR

**Review diff scope:**

\`\`\`bash
git diff dev --stat
git diff dev --name-status
\`\`\`

**Group changes by purpose:**

- Core changes (main feature/fix)
- Tests (new/updated test coverage)
- Documentation (README, comments)
- Dependencies (package.json updates)
- Configuration (build, lint, env)

## 5. Generate PR Content

**Title (< 72 chars):**

- Format: \`Type: Brief description of main change\`
- Example: \`Feat: Preserve context when rules block evaluation\`
- Capitalize first word, no period at end

**Description structure:**

\`\`\`markdown
## Summary

[One paragraph explaining what this PR does and why]

## Changes

**🔧 Core Changes**
_[Brief description of main implementation]_

- \`file1.ts\`: description
- \`file2.ts\`: description

**✅ Tests**
_[Brief description of test coverage]_

- \`test1.spec.ts\`: description
- \`test2.spec.ts\`: description

**📚 Documentation** (if applicable)
_[Brief description of doc updates]_

- \`README.md\`: description

## Related

Closes #[issue-number] (if applicable)
Ref #[issue-number] (if related but not closing)

## Testing

1. Run \`npm test\` and verify all tests pass
2. [Specific test scenario 1]
3. [Specific test scenario 2]
\`\`\`

**Guidelines:**

- Keep descriptions concise and actionable
- No code snippets in PR description
- Defer detailed rationale to linked issues
- Focus on WHAT changed, not WHY (unless critical)

## 6. Create PR with GitHub CLI

**Check if PR exists:**

\`\`\`bash
gh pr list --head \$(git branch --show-current)
\`\`\`

**Create PR if it doesn't exist:**

\`\`\`bash
gh pr create \\
  --title "<PR Title>" \\
  --body "<PR Description>" \\
  --base dev
\`\`\`

**Options to consider:**

- \`--draft\` - Create as draft PR
- \`--assignee @me\` - Auto-assign to self
- \`--reviewer <username>\` - Request review

## 7. Confirm and Output

**Display:**

- ✅ Branch: \`<branch-name>\`
- ✅ Commits: \`<commit-count>\` commit(s)
- ✅ PR created: \`<PR-URL>\`
- 📝 Title: \`<PR-title>\`

**Next steps for user:**

- Review PR at the provided URL
- Wait for CI checks to complete
- Address review feedback if needed

---

## Example Usage

**User says:** "Create a PR for my changes"

**Command executes:**

1. Checks git status → finds uncommitted changes
2. Stages files → commits with \`feat(rules): preserve context on blocking\`
3. Already on feature branch → continues
4. Analyzes diff → groups changes
5. Generates PR title and description
6. Creates PR via \`gh pr create\`
7. Outputs PR URL and summary
`,
  "database-optimization": `---
name: database-optimization
description: Convex schema design, indexing strategies, query optimization, performance tuning, and safe migration patterns
---

# Database Optimization

## Overview

Optimize database performance through intelligent schema design, indexing strategies, and query optimization. This skill covers Convex-specific patterns for building scalable, efficient data layers.

**Use this skill when:**
- Designing database schemas for new features
- Identifying slow queries and bottlenecks
- Planning database migrations
- Implementing indexing strategies
- Optimizing existing data structures

**Cross-functional pairing:** @qa **test-coverage-analysis** — Database changes should include coverage validation of new/modified query paths

---

## Convex Schema Design

### Data Normalization vs. Denormalization Trade-offs

**Normalization (Reduces redundancy):**
\`\`\`typescript
// Normalized: separate tables
export const users = defineTable({
  name: v.string(),
  email: v.string(),
  organizationId: v.id('organizations'),
});

export const organizations = defineTable({
  name: v.string(),
  slug: v.string(),
});

export const memberships = defineTable({
  userId: v.id('users'),
  organizationId: v.id('organizations'),
  role: v.union(v.literal('admin'), v.literal('member')),
});

// Query: Join required to get user's org
const user = await ctx.db.get(userId);
const org = await ctx.db.get(user.organizationId);
const memberships = await ctx.db
  .query('memberships')
  .filter(q => q.eq(q.field('userId'), userId))
  .collect();
\`\`\`

**Denormalization (Improves query speed, increases storage):**
\`\`\`typescript
// Denormalized: cache org data on user doc
export const users = defineTable({
  name: v.string(),
  email: v.string(),
  organizationId: v.id('organizations'),
  // Cached data
  organizationName: v.string(),
  organizationSlug: v.string(),
  userRole: v.union(v.literal('admin'), v.literal('member')),
});

// Single query: no joins needed
const user = await ctx.db.get(userId);
// user.organizationName, user.organizationSlug available immediately
\`\`\`

**Decision Matrix:**
| Scenario | Approach | Reason |
|----------|----------|--------|
| Frequently queried relationships | Denormalize | Reduces query count |
| Infrequently accessed data | Normalize | Saves storage, reduces update surface |
| Data changes frequently | Normalize | Easier maintenance, no cache busting |
| Real-time queries with < 100ms target | Denormalize | Eliminates join latency |
| Analytics/reporting | Normalize | Flexibility for aggregations |

---

## Indexing Strategies in Convex

### When to Index

**Create indexes for:**
- Frequently filtered fields (\`where\` clauses)
- Sorted fields (\`orderBy\`)
- Fields used in joins
- Compound queries (multiple filters)

**Avoid indexing:**
- Fields rarely queried
- Low cardinality fields (few unique values)
- Fields that change constantly
- Text fields (use full-text search instead)

### Index Patterns

\`\`\`typescript
// Single-field index
export const usersTable = defineTable({
  email: v.string(),
  status: v.string(),
}).index('email', ['email'])
 .index('status', ['status']);

// Compound index (multiple fields)
export const ordersTable = defineTable({
  userId: v.id('users'),
  status: v.string(),
  createdAt: v.number(),
}).index('userStatus', ['userId', 'status'])
 .index('statusCreated', ['status', 'createdAt']);

// Query efficiently using indexes
async function getUserOrders(ctx, userId, status) {
  // Uses userStatus index: fast
  return await ctx.db
    .query('orders')
    .filter(q => q.and(
      q.eq(q.field('userId'), userId),
      q.eq(q.field('status'), status)
    ))
    .collect();
}

async function getRecentOrders(ctx, status) {
  // Uses statusCreated index, sorts by createdAt
  return await ctx.db
    .query('orders')
    .filter(q => q.eq(q.field('status'), status))
    .order('desc')
    .collect();
}
\`\`\`

### Index Cost Analysis

\`\`\`typescript
// ❌ Inefficient: query without index
async function findUserByPartialEmail(ctx, emailPattern) {
  return await ctx.db
    .query('users')
    .filter(q => q.match(q.field('email'), emailPattern))
    .collect(); // Scans entire table!
}

// ✅ Better: exact match with index
async function findUserByEmail(ctx, email) {
  return await ctx.db
    .query('users')
    .filter(q => q.eq(q.field('email'), email))
    .collect(); // Uses index, O(log n)
}

// ✅ Best: use full-text search for patterns
export const usersTable = defineTable({
  email: v.string(),
  name: v.string(),
}).searchIndex('search_email', {
  searchField: 'email',
});

async function searchUsers(ctx, query) {
  return await ctx.db
    .query('users')
    .search('search_email', q => q.search(query))
    .collect();
}
\`\`\`

---

## Query Optimization

### N+1 Query Problem

\`\`\`typescript
// ❌ Bad: N+1 queries
async function getUsersWithOrgs(ctx) {
  const users = await ctx.db.query('users').collect();
  
  // This loops through and makes N+1 queries!
  return Promise.all(users.map(async user => ({
    ...user,
    org: await ctx.db.get(user.organizationId), // Extra query per user
  })));
}

// ✅ Good: batch load with index
async function getUsersWithOrgs(ctx) {
  const users = await ctx.db.query('users').collect();
  
  // Get unique org IDs
  const orgIds = [...new Set(users.map(u => u.organizationId))];
  
  // Single query to get all orgs
  const orgs = new Map();
  for (const orgId of orgIds) {
    const org = await ctx.db.get(orgId);
    orgs.set(orgId, org);
  }
  
  return users.map(user => ({
    ...user,
    org: orgs.get(user.organizationId),
  }));
}

// ✅ Best: denormalize when appropriate
async function getUsersWithOrgs(ctx) {
  // If org data is cached, single query
  return await ctx.db.query('users').collect();
}
\`\`\`

### Pagination for Large Result Sets

\`\`\`typescript
// ❌ Bad: loading all results
async function getAllPosts(ctx) {
  return await ctx.db.query('posts').collect(); // Could be 100k+ docs!
}

// ✅ Good: paginate with cursor
async function getPosts(ctx, cursor, pageSize = 20) {
  let query = ctx.db.query('posts').order('desc');
  
  if (cursor) {
    query = query.filter(q => q.lt(q.field('_creationTime'), cursor));
  }
  
  const posts = await query.take(pageSize + 1);
  
  return {
    posts: posts.slice(0, pageSize),
    nextCursor: posts.length > pageSize ? posts[pageSize]._creationTime : null,
  };
}

// Usage
const { posts, nextCursor } = await ctx.runQuery(getPosts, null);
const { posts: nextBatch } = await ctx.runQuery(getPosts, nextCursor);
\`\`\`

---

## Performance Tuning

### Identifying Slow Queries

**Convex query logs show:**
- Execution time (ms)
- Rows scanned
- Indexes used
- Estimated cost

**Warning signs:**
- Full table scans (rows scanned >> results returned)
- Multiple sequential queries for related data
- Large result sets paginated client-side

### Query Metrics

\`\`\`typescript
// Log query performance in development
async function findPostsForUser(ctx, userId) {
  const start = Date.now();
  
  const posts = await ctx.db
    .query('posts')
    .filter(q => q.eq(q.field('userId'), userId))
    .order('desc')
    .collect();
  
  const duration = Date.now() - start;
  console.log(\`Query took \${duration}ms, returned \${posts.length} docs\`);
  
  return posts;
}

// Track over time: if regression detected, investigate indexing
\`\`\`

### Common Optimization Techniques

| Issue | Solution | Trade-off |
|-------|----------|-----------|
| **Slow filters** | Add index | Storage cost |
| **N+1 queries** | Batch/denormalize | Complexity or storage |
| **Large sorts** | Index on sort field | Maintenance |
| **Complex filters** | Simplify queries | May require schema change |
| **Full table scans** | Add covering index | Write latency |

---

## Safe Database Migrations

### Migration Checklist

\`\`\`typescript
// 1. ADD NEW FIELD (backward compatible)
export const usersTable = defineTable({
  email: v.string(),
  name: v.string(),
  // NEW: Optional field with default
  avatarUrl: v.optional(v.string()),
});

// 2. BACKFILL DATA (mutation)
export const backfillAvatars = internalMutation({
  async handler(ctx) {
    const users = await ctx.db.query('users').collect();
    
    for (const user of users) {
      if (!user.avatarUrl) {
        await ctx.db.patch(user._id, {
          avatarUrl: \`/avatars/\${user._id}.png\`,
        });
      }
    }
    
    console.log(\`Backfilled \${users.length} users\`);
  },
});

// 3. MAKE FIELD REQUIRED (after backfill)
// Remove v.optional() from schema
// Verify all docs have the field
// Commit the change

// 4. REMOVE OLD FIELD (after code cleanup)
// Remove all references from mutations/queries
// Remove from schema
// Clean up in database
\`\`\`

### Rollback Strategy

\`\`\`typescript
// Before migration, export current schema and data
export const exportDatabase = internalMutation({
  async handler(ctx) {
    // Store snapshot for rollback
    const snapshot = {
      timestamp: Date.now(),
      tables: {},
    };
    
    // Would export all data to backup table
    // Store snapshot safely
  },
});

// If needed, restore from snapshot
export const restoreFromSnapshot = internalMutation({
  async handler(ctx, snapshotId) {
    // Restore previous state
  },
});
\`\`\`

---

## Related Skills

- @convex-backend — Convex mutations and queries
- @logging-observability — Monitor query performance with structured logs
- @test-coverage-analysis (QA) — Ensure query changes are tested
- @performance-profiling — Profile full app including database tier

## References

- [Convex Docs: Data Modeling](https://docs.convex.dev)
- [Indexing Best Practices](https://docs.convex.dev/database/indexes)
- [Query Performance](https://docs.convex.dev/database/performance)
`,
  "debug-issue": `---
name: debug-issue
description: Debug Issue
disable-model-invocation: true
---

# Debug Issue

## Overview

Help debug the current issue in the code by walking through the debugging process systematically and providing clear, actionable solutions.

## Steps

1. **Problem Analysis**
   - Identify the specific problem or error
   - Understand the expected vs actual behavior
   - Trace the execution flow to find the root cause
2. **Debugging Strategy**
   - Add appropriate logging statements
   - Suggest debugging tools and techniques
   - Identify key variables and states to monitor
   - Recommend breakpoint locations
3. **Solution Approach**
   - Propose potential fixes with explanations
   - Consider multiple solution approaches
   - Evaluate trade-offs of different approaches
   - Provide step-by-step resolution plan
4. **Prevention**
   - Suggest ways to prevent similar issues
   - Recommend additional tests or checks
   - Identify code patterns that could be improved

## Debug Issue Checklist

- [ ] Identified the specific problem or error
- [ ] Understood expected vs actual behavior
- [ ] Traced execution flow to find root cause
- [ ] Added appropriate logging statements
- [ ] Proposed potential fixes with explanations
- [ ] Evaluated trade-offs of different approaches
- [ ] Provided step-by-step resolution plan
- [ ] Suggested ways to prevent similar issues
- [ ] Recommended additional tests or checks
`,
  "dependency-management": `# dependency-management

**Tier:** MEDIUM (Phase 3)  
**Author:** Engineer (Full-Stack)  
**Category:** Supply Chain & Security  
**Status:** Operational  

## Overview
Comprehensive dependency lifecycle management skill enabling supply chain security, vulnerability scanning, version updates, and dependency auditing across Node.js/npm ecosystems. Ensures production-grade dependency hygiene and compliance.

## Core Competencies

### 1. Supply Chain Security
- **npm audit** scanning and vulnerability remediation
- Automated security vulnerability detection
- Dependency provenance verification
- Software Bill of Materials (SBOM) generation
- CVE monitoring and alerting
- Lockfile integrity validation

### 2. npm Audit & Scanning
- Full dependency tree analysis
- \`npm audit\` command execution and parsing
- Vulnerability severity classification (critical, high, moderate, low)
- Automated fix recommendations
- Audit report generation and archival
- Custom audit policies and thresholds

### 3. Update Strategies
- Semantic versioning compliance (major/minor/patch)
- Automated update workflows
- Dependency constraint evaluation
- Breaking change detection
- Version pinning vs. range strategies
- Outdated package identification
- Release notes integration

### 4. Version Management
- Monorepo version synchronization
- Workspace dependency alignment
- Version lock enforcement
- Rollback procedures
- Migration path planning
- Deprecation tracking
- License compliance verification

## Implementation Patterns

### npm Audit Workflow
\`\`\`javascript
// Execute npm audit scan
// Parse vulnerability data
// Classify by severity
// Generate remediation recommendations
// Apply fixes (if safe)
// Validate lockfile
// Report results
\`\`\`

### Dependency Update Process
\`\`\`javascript
// Check for outdated packages
// Evaluate breaking changes
// Run test suite pre-update
// Apply version increments
// Update lockfiles
// Test post-update
// Create PR with changelog
\`\`\`

### Version Compliance Check
\`\`\`javascript
// Validate semantic versioning
// Check license compatibility
// Verify deprecation status
// Confirm security posture
// Report compliance status
\`\`\`

## Cross-Functional Validation Points

**@qa Validation:**
- Dependency scanning accuracy and completeness
- Vulnerability detection reliability
- Update recommendation safety
- Lockfile integrity after modifications
- Compliance report accuracy

**Test Coverage:**
- Unit: npm audit parsing, version comparison logic
- Integration: Full dependency update workflow
- E2E: Security scanning with real vulnerable packages

## CLI Commands & Examples

\`\`\`bash
# Audit dependencies for vulnerabilities
npm audit

# Audit with JSON output for parsing
npm audit --json

# Auto-fix vulnerabilities (safe fixes only)
npm audit fix

# Check for outdated packages
npm outdated

# Update specific package
npm update <package-name>

# Install with specific version
npm install <package>@<version>

# List vulnerabilities with custom output
npm audit --severity=high
\`\`\`

## Configuration & Integration

### .npmrc Settings
\`\`\`
audit-level=moderate
legacy-peer-deps=false
\`\`\`

### Integration Points
- CI/CD pipeline security scanning
- Dependency dashboards
- Release management systems
- License scanning tools
- Container vulnerability scanning

## Security Considerations
- Validate fixes don't introduce breaking changes
- Test updates in isolated environments pre-production
- Maintain audit trails for compliance
- Monitor transitive dependencies
- Use integrity hashes in lockfiles
- Implement version pinning for critical dependencies

## Common Challenges & Resolutions

| Challenge | Resolution |
|-----------|-----------|
| Conflicting peer dependencies | Evaluate compatibility or use legacy-peer-deps |
| Breaking changes in updates | Run comprehensive test suite, review changelogs |
| Transitive vulnerability injection | Deep scan and constraint analysis |
| License incompatibility | Implement license scanning and policy enforcement |
| Supply chain attacks | Verify package provenance and use lock files |

## Metrics & Monitoring

- Vulnerability count by severity
- Mean time to remediation (MTTR)
- Outdated package ratio
- Successful update rate
- Dependency freshness score
- License compliance percentage

## Related Skills
- **async-concurrency-patterns** (dependency loading, version resolution)
- **environment-configuration** (dependency setup by environment)
- **error-handling-resilience** (graceful dependency failure handling)
- **logging-observability** (audit trail logging)

## References & Standards
- [npm audit documentation](https://docs.npmjs.com/cli/v8/commands/npm-audit)
- [OWASP Dependency-Check](https://owasp.org/www-project-dependency-check/)
- [CycloneDX SBOM Standard](https://cyclonedx.org/)
- [NIST Software Supply Chain Security](https://csrc.nist.gov/publications/detail/sp/800-53/rev-5)
- [Semantic Versioning](https://semver.org/)

## Skill Maturity

**Level 1 (Foundational):** Basic audit and update capabilities
**Level 2 (Intermediate):** Automated workflows, policy enforcement
**Level 3 (Advanced):** Supply chain security, SBOM, provenance verification
**Current:** Level 2 (Intermediate)

---
**Last Updated:** 2026-02-06
**Phase:** 3 (Medium Priority)
`,
  "deslop": `---
name: deslop
description: Remove AI code slop
disable-model-invocation: true
---

# Remove AI code slop

Check the diff against main, and remove all AI generated slop introduced in this branch.

This includes:

- Commented-out code that should be removed or implemented (not TODO/FIXME comments - keep those)
- Casts to \`any\` to get around type issues (fix with proper types instead)
- Extra defensive checks or try/catch blocks that are abnormal for that area of the codebase (especially if called by
  trusted / validated codepaths)
- Comments that ONLY restate what the code does without adding context (keep comments that explain "why" or provide
  important context)
- Avoid re exporting type from a different file

**IMPORTANT**: Be conservative with comments. Only remove comments that are clearly redundant or explain obvious things.

Keep:

- TODO/FIXME comments (they mark work to be done)
- JSDoc comments that document functions/components
- Comments explaining "why" something is done
- Comments providing context about non-obvious logic
- Comments that match the style of the existing codebase

Report at the end with only a 1-3 sentence summary of what you changed
`,
  "doc-generation": `---
name: doc-generation
description: API documentation, code documentation, TypeDoc/JSDoc, Swagger/OpenAPI automation, and maintainable documentation practices
---

# Documentation Generation

## Overview

Build comprehensive, maintainable documentation through automation and best practices. This skill covers API docs, inline code documentation, and tools that keep docs in sync with code.

**Use this skill when:**
- Publishing APIs to external users or teams
- Onboarding new developers to the codebase
- Generating reference documentation
- Creating architecture diagrams
- Publishing TypeScript type definitions

**Cross-functional pairing:** @qa **mutation-testing** — Well-documented code is easier to test thoroughly; docs clarify intent and edge cases

---

## JSDoc & TypeDoc

### Inline Code Documentation with JSDoc

\`\`\`typescript
/**
 * Fetches a user by ID from the database.
 * 
 * @param userId - The unique identifier of the user to fetch
 * @returns A promise that resolves to the User object, or null if not found
 * @throws {ValidationError} If userId is not a valid format
 * @example
 * const user = await getUser('user-123');
 * if (user) {
 *   console.log(\`Hello, \${user.name}\`);
 * }
 */
export async function getUser(userId: string): Promise<User | null> {
  if (!userId || !userId.startsWith('user-')) {
    throw new ValidationError('Invalid user ID format');
  }
  
  return db.get(userId);
}

/**
 * Generates a cryptographically secure random token.
 * 
 * @param length - Token length in bytes (default: 32)
 * @returns A hex-encoded random string
 * 
 * @example
 * const token = generateToken(16); // 32-char hex string
 * const refreshToken = generateToken(64); // 128-char hex string
 */
export function generateToken(length: number = 32): string {
  return crypto.randomBytes(length).toString('hex');
}

/**
 * Configuration options for the API server.
 * 
 * @property port - The port to listen on (default: 3000)
 * @property host - The hostname to bind to (default: 'localhost')
 * @property tlsEnabled - Whether to enable TLS/HTTPS
 * @property logLevel - Logging verbosity ('debug' | 'info' | 'warn' | 'error')
 */
interface ServerConfig {
  port: number;
  host: string;
  tlsEnabled: boolean;
  logLevel: 'debug' | 'info' | 'warn' | 'error';
}
\`\`\`

### Generating TypeDoc Documentation

\`\`\`bash
# Install TypeDoc
npm install --save-dev typedoc

# Generate HTML documentation
npx typedoc src/ --out docs/

# Generate markdown documentation
npx typedoc src/ --out docs/ --plugin typedoc-plugin-markdown
\`\`\`

**tsconfig.json configuration:**
\`\`\`json
{
  "compilerOptions": {
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "typedocOptions": {
    "entryPoints": ["src/index.ts"],
    "out": "docs",
    "titleLink": "https://example.com",
    "excludePrivate": true,
    "excludeInternal": true
  }
}
\`\`\`

---

## Convex API Documentation

### Documenting Convex Mutations & Queries

\`\`\`typescript
/**
 * Creates a new blog post.
 * 
 * @param title - Post title (1-200 characters)
 * @param content - Post content (markdown format)
 * @param tags - Optional tags for categorization
 * 
 * @returns The ID of the created post
 * 
 * @throws {ValidationError} If title is empty or content exceeds limits
 * @throws {AuthenticationError} If user is not authenticated
 * 
 * @example
 * const postId = await ctx.runMutation(api.posts.createPost, {
 *   title: 'My First Post',
 *   content: '# Hello World\\n\\nThis is my first post.',
 *   tags: ['hello', 'world'],
 * });
 */
export const createPost = mutation({
  args: {
    title: v.string(),
    content: v.string(),
    tags: v.optional(v.array(v.string())),
  },
  handler: async (ctx, args) => {
    // Implementation
  },
});

/**
 * Lists all blog posts for the authenticated user.
 * 
 * @param limit - Maximum number of posts to return (default: 20, max: 100)
 * @param cursor - Cursor for pagination (from previous response)
 * 
 * @returns Object containing posts array and next cursor
 * 
 * @example
 * const { posts, nextCursor } = await ctx.runQuery(api.posts.listUserPosts, {
 *   limit: 50,
 * });
 * 
 * // Get next page
 * const { posts: nextPage } = await ctx.runQuery(api.posts.listUserPosts, {
 *   limit: 50,
 *   cursor: nextCursor,
 * });
 */
export const listUserPosts = query({
  args: {
    limit: v.optional(v.number()),
    cursor: v.optional(v.string()),
  },
  handler: async (ctx, args) => {
    // Implementation
  },
});
\`\`\`

---

## OpenAPI/Swagger Documentation

### Generating OpenAPI from Next.js API Routes

\`\`\`typescript
// api/posts/index.ts
/**
 * @swagger
 * /api/posts:
 *   get:
 *     summary: List all posts
 *     parameters:
 *       - in: query
 *         name: page
 *         schema:
 *           type: integer
 *         required: false
 *         description: Page number (default: 1)
 *       - in: query
 *         name: limit
 *         schema:
 *           type: integer
 *         required: false
 *         description: Items per page (default: 20, max: 100)
 *     responses:
 *       200:
 *         description: List of posts
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 posts:
 *                   type: array
 *                   items:
 *                     \$ref: '#/components/schemas/Post'
 *                 pagination:
 *                   \$ref: '#/components/schemas/Pagination'
 *       400:
 *         description: Invalid query parameters
 *   post:
 *     summary: Create a new post
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             \$ref: '#/components/schemas/CreatePostRequest'
 *     responses:
 *       201:
 *         description: Post created
 *         content:
 *           application/json:
 *             schema:
 *               \$ref: '#/components/schemas/Post'
 *       401:
 *         description: Unauthorized
 */

import swaggerJsdoc from 'swagger-jsdoc';

const options = {
  definition: {
    openapi: '3.0.0',
    info: {
      title: 'OpenClaw Blog API',
      version: '1.0.0',
      description: 'API for blog post management',
    },
    servers: [
      {
        url: 'http://localhost:3000',
        description: 'Development',
      },
      {
        url: 'https://api.example.com',
        description: 'Production',
      },
    ],
    components: {
      schemas: {
        Post: {
          type: 'object',
          properties: {
            id: { type: 'string' },
            title: { type: 'string' },
            content: { type: 'string' },
            createdAt: { type: 'string', format: 'date-time' },
          },
          required: ['id', 'title', 'content', 'createdAt'],
        },
        CreatePostRequest: {
          type: 'object',
          properties: {
            title: { type: 'string', minLength: 1, maxLength: 200 },
            content: { type: 'string', minLength: 1 },
            tags: {
              type: 'array',
              items: { type: 'string' },
            },
          },
          required: ['title', 'content'],
        },
        Pagination: {
          type: 'object',
          properties: {
            page: { type: 'integer' },
            limit: { type: 'integer' },
            total: { type: 'integer' },
            pages: { type: 'integer' },
          },
        },
      },
    },
  },
  apis: ['./pages/api/**/*.ts'],
};

export const specs = swaggerJsdoc(options);

// In your Next.js config
import swaggerUi from 'swagger-ui-express';

export default function handler(req, res) {
  swaggerUi.setup(specs)(req, res);
}
\`\`\`

### Generate and Serve OpenAPI Docs

\`\`\`typescript
// pages/api/docs.ts
import { NextApiRequest, NextApiResponse } from 'next';
import swaggerUi from 'swagger-ui-express';
import { specs } from '@/lib/swagger';

const handler = swaggerUi.setup(specs, {
  swaggerUrl: '/api/swagger.json',
  customCss: '.swagger-ui { max-width: 1200px; margin: 0 auto; }',
});

export default handler;

// pages/api/swagger.json.ts
import { NextApiRequest, NextApiResponse } from 'next';
import { specs } from '@/lib/swagger';

export default function handler(
  req: NextApiRequest,
  res: NextApiResponse
) {
  res.setHeader('Content-Type', 'application/json');
  res.write(JSON.stringify(specs, null, 2));
  res.end();
}
\`\`\`

---

## Architecture Documentation

### C4 Model Diagrams

\`\`\`markdown
# System Architecture

## Context Diagram

\`\`\`
User <-> OpenClaw Web App <-> Convex Backend
         (Next.js + React)  (GraphQL API)
                |
                v
          Clerk Auth
\`\`\`

## Container Diagram

\`\`\`
OpenClaw System:
  ├─ Web Application (Next.js)
  │  ├─ Server Components
  │  ├─ Client Components
  │  └─ API Routes
  ├─ Backend (Convex)
  │  ├─ Database (Convex Storage)
  │  ├─ Queries
  │  ├─ Mutations
  │  └─ Webhooks
  └─ Authentication (Clerk)
     ├─ Sign In
     ├─ Sign Up
     └─ MFA

Data Flow:
  User -> Web App -> Convex API -> Database
\`\`\`
\`\`\`

### Using Mermaid for Diagrams

\`\`\`typescript
// In markdown files
\\\`\\\`\\\`mermaid
graph TD
    A[User] -->|Login| B[Clerk Auth]
    B -->|Token| C[Web App]
    C -->|Query| D[Convex API]
    D -->|Results| C
    C -->|Render| A
\\\`\\\`\\\`

// Or in TypeScript
import mermaid from 'mermaid';

const diagram = \`
  graph TD
    A[Start] --> B{Valid?}
    B -->|Yes| C[Process]
    B -->|No| D[Error]
\`;

mermaid.render('diagram-id', diagram);
\`\`\`

---

## README Best Practices

\`\`\`markdown
# OpenClaw Mission Control

Brief description of the project (1-2 sentences).

## Features

- ✅ Feature 1
- ✅ Feature 2
- ✅ Feature 3

## Getting Started

### Prerequisites
- Node.js >= 24.0.0
- npm >= 11.0.0

### Installation

\\\`\\\`\\\`bash
npm install
\\\`\\\`\\\`

### Running Locally

\\\`\\\`\\\`bash
npm run dev
\\\`\\\`\\\`

## API Reference

See [API Docs](./docs/api.md) for endpoint documentation.

## Development Guide

See [CONTRIBUTING.md](./CONTRIBUTING.md) for development setup and conventions.

## Architecture

See [ARCHITECTURE.md](./docs/ARCHITECTURE.md) for system design and technical decisions.

## Testing

\\\`\\\`\\\`bash
npm test
\\\`\\\`\\\`

## Troubleshooting

### Common Issues

**Issue:** Build fails with "Cannot find module X"

**Solution:** 
1. Clear node_modules: \\\`rm -rf node_modules package-lock.json\\\`
2. Reinstall: \\\`npm install\\\`
3. Clear cache: \\\`npm cache clean --force\\\`

## License

MIT
\`\`\`

---

## Keeping Docs in Sync with Code

### Automated Documentation Updates

\`\`\`typescript
// CI/CD: Generate docs on every push
name: Update Documentation

on:
  push:
    branches: [master]

jobs:
  docs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install dependencies
        run: npm install
      
      - name: Generate TypeDoc
        run: npx typedoc src/ --out docs/api
      
      - name: Generate OpenAPI
        run: npx swagger-jsdoc --definition swagger.js --apis "pages/api/**/*.ts" > docs/swagger.json
      
      - name: Commit changes
        run: |
          git config user.name "Documentation Bot"
          git add docs/
          git commit -m "docs: auto-generated documentation [skip ci]" || true
          git push
\`\`\`

### Documentation Validation

\`\`\`typescript
// Ensure JSDoc exists for exported functions
import fs from 'fs';
import ts from 'typescript';

const validateJSDoc = (filePath: string) => {
  const source = fs.readFileSync(filePath, 'utf-8');
  const sourceFile = ts.createSourceFile(
    filePath,
    source,
    ts.ScriptTarget.Latest
  );
  
  const missingDocs: string[] = [];
  
  ts.forEachChild(sourceFile, (node) => {
    if (ts.isFunctionDeclaration(node) || ts.isClassDeclaration(node)) {
      // Check if export
      const isExported = node.modifiers?.some(
        m => m.kind === ts.SyntaxKind.ExportKeyword
      );
      
      if (isExported && !ts.getLeadingCommentRanges(source, node.getStart())) {
        missingDocs.push(node.name?.text || 'unknown');
      }
    }
  });
  
  if (missingDocs.length > 0) {
    console.warn(\`Missing JSDoc for: \${missingDocs.join(', ')}\`);
  }
};
\`\`\`

---

## Documentation Tools

| Tool | Purpose | Best For |
|------|---------|----------|
| **TypeDoc** | Auto-generate docs from JSDoc | TypeScript APIs |
| **Swagger/OpenAPI** | API specification & interactive docs | REST APIs |
| **Mermaid** | Diagram generation (markdown) | Architecture, workflows |
| **Docusaurus** | Documentation site | Large documentation |
| **Storybook** | Component documentation | UI components |
| **Plato** | Code complexity analysis | Code health reporting |

---

## Related Skills

- @api-design — Design APIs that are well-documented
- @logging-observability — Document observability patterns
- @backend-convex — Document Convex schema and functions
- @mutation-testing (QA) — Well-documented code is easier to test

## References

- [Google Technical Writing Course](https://developers.google.com/tech-writing)
- [The Good Docs Project](https://www.thegooddocsproject.dev/)
- [JSDoc Documentation](https://jsdoc.app/)
- [OpenAPI Specification](https://spec.openapis.org/)
- [Mermaid Diagrams](https://mermaid.js.org/)
`,
  "environment-configuration": `# environment-configuration

**Tier:** MEDIUM (Phase 3)  
**Author:** Engineer (Full-Stack)  
**Category:** Configuration & Secrets Management  
**Status:** Operational  

## Overview
Comprehensive environment configuration and secrets management skill enabling .env file handling, secrets rotation, multi-environment setup, and configuration validation. Ensures secure and consistent application configuration across development, staging, and production environments.

## Core Competencies

### 1. .env Management
- \`.env\` file parsing and validation
- Environment variable loading and precedence
- Local vs. repository \`.env\` files
- \`.env.local\`, \`.env.example\` patterns
- Dotenv library integration (\`dotenv\`, \`dotenv-expand\`)
- Variable expansion and interpolation
- Comment handling and parsing
- Type coercion and casting

### 2. Secrets Rotation
- Automated secret rotation scheduling
- Secret versioning and history
- Key rotation without service downtime
- Gradual rollover strategies
- Revocation and expiry management
- Audit logging for all secret operations
- Access control for secret rotation
- Emergency rotation procedures

### 3. Multi-Environment Setup
- Environment detection (dev/staging/prod)
- Environment-specific configuration files
- Configuration inheritance and overrides
- Environment variable naming conventions
- Conditional logic based on environment
- Feature flag configuration per environment
- Build-time vs. runtime configuration
- Configuration export and import

### 4. Configuration Validation
- Schema validation (JSON Schema, Zod, Yup)
- Type checking for configuration values
- Required field enforcement
- Default value application
- Value range validation
- Format validation (URLs, emails, ports)
- Dependency validation between values
- Configuration drift detection

## Implementation Patterns

### Environment-Specific Configuration
\`\`\`typescript
// config.ts - Centralized configuration
interface AppConfig {
  nodeEnv: 'development' | 'staging' | 'production';
  database: {
    host: string;
    port: number;
    ssl: boolean;
  };
  api: {
    baseUrl: string;
    timeout: number;
  };
  secrets: {
    jwtSecret: string;
    apiKey: string;
  };
}

function loadConfig(): AppConfig {
  const env = process.env.NODE_ENV || 'development';
  
  return {
    nodeEnv: env,
    database: {
      host: process.env.DB_HOST || 'localhost',
      port: parseInt(process.env.DB_PORT || '5432'),
      ssl: env === 'production'
    },
    api: {
      baseUrl: process.env.API_BASE_URL,
      timeout: parseInt(process.env.API_TIMEOUT || '30000')
    },
    secrets: {
      jwtSecret: process.env.JWT_SECRET,
      apiKey: process.env.API_KEY
    }
  };
}
\`\`\`

### Secrets Rotation Implementation
\`\`\`typescript
// secretsManager.ts
interface SecretRotationConfig {
  scheduleInterval: number; // ms
  gracefulTimeout: number;  // ms for old secret acceptance
  maxRetries: number;
}

async function rotateSecret(
  secretName: string,
  config: SecretRotationConfig
): Promise<void> {
  // Generate new secret
  const newSecret = await generateSecret();
  
  // Store new secret in vault (inactive)
  await vaultClient.storeSecret(secretName, newSecret, { active: false });
  
  // Notify services of pending rotation
  await notifyServices(secretName);
  
  // Wait for graceful period
  await sleep(config.gracefulTimeout);
  
  // Activate new secret
  await vaultClient.activateSecret(secretName, newSecret);
  
  // Audit rotation
  await auditLog('secret_rotated', { secretName, timestamp: Date.now() });
}
\`\`\`

### Configuration Validation with Zod
\`\`\`typescript
import { z } from 'zod';

const EnvSchema = z.object({
  NODE_ENV: z.enum(['development', 'staging', 'production']),
  DB_HOST: z.string().default('localhost'),
  DB_PORT: z.coerce.number().min(1).max(65535).default(5432),
  DB_USER: z.string(),
  DB_PASSWORD: z.string(),
  API_TIMEOUT: z.coerce.number().min(1000).max(300000).default(30000),
  JWT_SECRET: z.string().min(32),
  LOG_LEVEL: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
});

type Env = z.infer<typeof EnvSchema>;

function validateEnvironment(): Env {
  const result = EnvSchema.safeParse(process.env);
  
  if (!result.success) {
    console.error('Environment validation failed:');
    console.error(result.error.format());
    process.exit(1);
  }
  
  return result.data;
}
\`\`\`

### .env File Loading with Fallback
\`\`\`typescript
import dotenv from 'dotenv';
import path from 'path';

function loadEnvFiles() {
  const env = process.env.NODE_ENV || 'development';
  
  // Load in order of precedence (lowest to highest)
  const envFiles = [
    '.env',                      // Shared defaults
    \`.env.\${env}\`,              // Environment-specific
    '.env.local',               // Local overrides (not committed)
    \`.env.\${env}.local\`,        // Environment + local
  ];
  
  for (const file of envFiles) {
    const filePath = path.resolve(process.cwd(), file);
    
    try {
      dotenv.config({ path: filePath, override: true });
      console.log(\`Loaded environment: \${file}\`);
    } catch (error) {
      // File doesn't exist, continue
      if (error.code !== 'ENOENT') {
        throw error;
      }
    }
  }
}
\`\`\`

## Cross-Functional Validation Points

**@qa Validation:**
- Configuration correctness in different environments
- Secrets properly isolated and not leaked
- Environment-specific behavior validation
- Configuration validation accuracy
- Secret rotation without service disruption
- Fallback to default values when expected
- File parsing and interpolation accuracy

**Test Coverage:**
- Unit: Config parsing, validation, type coercion
- Integration: Multi-environment config loading
- E2E: Full application startup with various env configs
- Security: Secrets not logged, not exposed in errors

## Tools & Standards

### Configuration Management Tools
- \`dotenv\` - Simple .env loading
- \`dotenv-expand\` - Variable expansion
- \`zod\` / \`yup\` - Schema validation
- \`joi\` - Data validation
- AWS Secrets Manager / HashiCorp Vault - Secrets management

### Environment Variable Naming Conventions
\`\`\`
DATABASE_*          // Database connection settings
API_*              // API configuration
JWT_*              // JWT/Auth secrets
LOG_*              // Logging configuration
FEATURE_*          // Feature flags
CACHE_*            // Cache configuration
REDIS_*            // Redis connection
AWS_*              // AWS service configuration
\`\`\`

### File Structure
\`\`\`
.env                    # Base configuration (can commit)
.env.example           # Template for required vars (commit this)
.env.development       # Dev-specific (commit or git-ignore)
.env.staging          # Staging-specific (do not commit)
.env.production        # Production-specific (do not commit)
.env.local            # Local overrides (always .gitignore)
.env.*.local          # Env-specific local (always .gitignore)
\`\`\`

## Security Best Practices

| Practice | Reason |
|----------|--------|
| Never commit secrets | Prevent credential exposure in VCS history |
| Use .env.example template | Document required variables without secrets |
| Add .env* to .gitignore | Protect sensitive local files |
| Validate all configuration | Catch misconfigurations early |
| Rotate secrets regularly | Reduce impact of compromise |
| Use vault/secrets manager | Centralized secret management |
| Log configuration access | Audit trail for compliance |
| Encrypt secrets at rest | Protect stored credentials |

## Common Pitfalls & Solutions

| Pitfall | Solution |
|---------|----------|
| Secrets in version control | Use .gitignore, pre-commit hooks, git-secrets |
| Hardcoded values | Use environment variables consistently |
| Missing validation | Add schema validation at startup |
| Wrong env precedence | Document and test load order |
| Env pollution | Isolate environments, clear between tests |
| Rotation downtime | Implement graceful acceptance period |
| Configuration drift | Regular audits, IaC templating |

## Metrics & Monitoring

- Configuration validation success rate
- Secret rotation frequency and duration
- Configuration audit events
- Environment-specific error rates
- Secrets access frequency and patterns
- Configuration deployment time

## Environment-Specific Configurations

### Development
\`\`\`bash
NODE_ENV=development
LOG_LEVEL=debug
API_TIMEOUT=60000
DATABASE_URL=postgresql://user:pass@localhost/dbname_dev
FEATURE_VERBOSE_ERRORS=true
\`\`\`

### Staging
\`\`\`bash
NODE_ENV=staging
LOG_LEVEL=info
API_TIMEOUT=30000
DATABASE_URL=<vault-managed-secret>
FEATURE_VERBOSE_ERRORS=false
\`\`\`

### Production
\`\`\`bash
NODE_ENV=production
LOG_LEVEL=warn
API_TIMEOUT=10000
DATABASE_URL=<vault-managed-secret>
FEATURE_VERBOSE_ERRORS=false
ENABLE_APM=true
\`\`\`

## Related Skills
- **dependency-management** (configuration-dependent package selection)
- **async-concurrency-patterns** (async config initialization)
- **error-handling-resilience** (handling config errors gracefully)
- **logging-observability** (config-driven logging levels)
- **security-hardening** (secrets protection)

## References & Standards
- [12-Factor App - Config](https://12factor.net/config)
- [OWASP Secrets Management](https://owasp.org/www-community/Sensitive_Data_Exposure)
- [Node.js dotenv Documentation](https://github.com/motdotla/dotenv)
- [AWS Secrets Manager Best Practices](https://docs.aws.amazon.com/secretsmanager/latest/userguide/best-practices.html)
- [HashiCorp Vault Documentation](https://www.vaultproject.io/docs)
- [JSON Schema Specification](https://json-schema.org/)

## Skill Maturity

**Level 1 (Foundational):** Basic .env loading, environment detection
**Level 2 (Intermediate):** Multi-env setup, validation, secrets rotation
**Level 3 (Advanced):** Dynamic secrets, complex rotation strategies, observability
**Current:** Level 2 (Intermediate)

---
**Last Updated:** 2026-02-06
**Phase:** 3 (Medium Priority)
`,
  "error-handling-resilience": `---
name: error-handling-resilience
description: Exception handling patterns, circuit breakers, retry logic, fallback strategies, and graceful degradation
---

# Error Handling & Resilience

## Overview

Build resilient systems that gracefully handle failures and recover automatically. This skill covers defensive programming patterns, retry logic, circuit breakers, and strategies for maintaining availability during partial failures.

**Use this skill when:**
- Calling external APIs or services
- Handling network failures
- Designing fault-tolerant systems
- Planning recovery strategies
- Building redundancy and failover logic

**Cross-functional pairing:** @qa **contract-testing-openapi** — Ensure error responses conform to API contracts and are properly tested

---

## Error Classification

### Expected vs. Unexpected Errors

\`\`\`typescript
// Error types
enum ErrorType {
  // Expected (client/request errors) - don't retry
  VALIDATION = 'VALIDATION',         // Invalid input
  AUTHENTICATION = 'AUTHENTICATION', // Missing/invalid auth
  AUTHORIZATION = 'AUTHORIZATION',   // Insufficient permissions
  NOT_FOUND = 'NOT_FOUND',          // Resource doesn't exist
  CONFLICT = 'CONFLICT',             // Resource already exists
  
  // Transient (server/temporary) - retry with backoff
  TIMEOUT = 'TIMEOUT',               // Request timed out
  RATE_LIMIT = 'RATE_LIMIT',         // Too many requests
  SERVICE_UNAVAILABLE = 'SERVICE_UNAVAILABLE', // Server down
  TEMPORARY_FAILURE = 'TEMPORARY_FAILURE',     // Network glitch
  
  // Unexpected (programmer errors) - log and alert
  INTERNAL_ERROR = 'INTERNAL_ERROR', // Unhandled exception
  UNKNOWN = 'UNKNOWN',               // Unknown error
}

// Map HTTP status to error type
const httpStatusToErrorType = (status: number): ErrorType => {
  if (status === 400) return ErrorType.VALIDATION;
  if (status === 401) return ErrorType.AUTHENTICATION;
  if (status === 403) return ErrorType.AUTHORIZATION;
  if (status === 404) return ErrorType.NOT_FOUND;
  if (status === 409) return ErrorType.CONFLICT;
  if (status === 408 || status === 504) return ErrorType.TIMEOUT;
  if (status === 429) return ErrorType.RATE_LIMIT;
  if (status === 503) return ErrorType.SERVICE_UNAVAILABLE;
  if (status >= 500) return ErrorType.INTERNAL_ERROR;
  return ErrorType.UNKNOWN;
};

// Determine if error is retryable
const isRetryable = (errorType: ErrorType): boolean => {
  const retryableErrors = [
    ErrorType.TIMEOUT,
    ErrorType.RATE_LIMIT,
    ErrorType.SERVICE_UNAVAILABLE,
    ErrorType.TEMPORARY_FAILURE,
  ];
  return retryableErrors.includes(errorType);
};
\`\`\`

---

## Retry Logic

### Exponential Backoff with Jitter

\`\`\`typescript
interface RetryConfig {
  maxAttempts: number;
  initialDelayMs: number;
  maxDelayMs: number;
  backoffMultiplier: number;
  jitterFraction: number; // 0-1, recommended 0.1
}

const DEFAULT_RETRY_CONFIG: RetryConfig = {
  maxAttempts: 3,
  initialDelayMs: 100,
  maxDelayMs: 10000,
  backoffMultiplier: 2,
  jitterFraction: 0.1,
};

// Calculate delay for retry attempt
const calculateRetryDelay = (
  attempt: number,
  config: RetryConfig
): number => {
  // Exponential backoff: 100ms, 200ms, 400ms, 800ms, ...
  const baseDelay = Math.min(
    config.initialDelayMs * Math.pow(config.backoffMultiplier, attempt),
    config.maxDelayMs
  );
  
  // Add jitter to prevent thundering herd
  const jitter = baseDelay * config.jitterFraction * Math.random();
  
  return baseDelay + jitter;
};

// Retry function
export const withRetry = async <T>(
  operation: () => Promise<T>,
  config: RetryConfig = DEFAULT_RETRY_CONFIG
): Promise<T> => {
  let lastError: Error | null = null;
  
  for (let attempt = 0; attempt < config.maxAttempts; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error as Error;
      const errorType = classifyError(error);
      
      // Don't retry if error is not retryable
      if (!isRetryable(errorType)) {
        throw error;
      }
      
      // Don't sleep on last attempt
      if (attempt < config.maxAttempts - 1) {
        const delayMs = calculateRetryDelay(attempt, config);
        await new Promise(resolve => setTimeout(resolve, delayMs));
      }
      
      console.log(\`Retry attempt \${attempt + 1}/\${config.maxAttempts} after \${delayMs}ms\`);
    }
  }
  
  throw lastError;
};

// Usage
const result = await withRetry(
  () => fetchFromExternalAPI(),
  {
    maxAttempts: 5,
    initialDelayMs: 50,
    maxDelayMs: 5000,
    backoffMultiplier: 2,
    jitterFraction: 0.1,
  }
);
\`\`\`

### Circuit Breaker Pattern

\`\`\`typescript
enum CircuitState {
  CLOSED = 'CLOSED',       // Normal operation, requests pass through
  OPEN = 'OPEN',           // Too many failures, requests fail fast
  HALF_OPEN = 'HALF_OPEN', // Testing if service recovered
}

interface CircuitBreakerConfig {
  failureThreshold: number;      // Failures before opening (e.g., 5)
  successThreshold: number;      // Successes to close from half-open (e.g., 2)
  timeoutMs: number;             // Time before half-open (e.g., 30000ms)
}

class CircuitBreaker<T> {
  private state = CircuitState.CLOSED;
  private failureCount = 0;
  private successCount = 0;
  private lastFailureTime = 0;
  
  constructor(
    private operation: () => Promise<T>,
    private config: CircuitBreakerConfig
  ) {}
  
  async call(): Promise<T> {
    if (this.state === CircuitState.OPEN) {
      const timeSinceLastFailure = Date.now() - this.lastFailureTime;
      
      if (timeSinceLastFailure > this.config.timeoutMs) {
        // Try to recover
        this.state = CircuitState.HALF_OPEN;
        this.successCount = 0;
        console.log('Circuit breaker: transitioning to HALF_OPEN');
      } else {
        // Still open, fail fast
        throw new Error('Circuit breaker is OPEN');
      }
    }
    
    try {
      const result = await this.operation();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  private onSuccess() {
    this.failureCount = 0;
    
    if (this.state === CircuitState.HALF_OPEN) {
      this.successCount++;
      
      if (this.successCount >= this.config.successThreshold) {
        this.state = CircuitState.CLOSED;
        console.log('Circuit breaker: CLOSED (recovered)');
      }
    }
  }
  
  private onFailure() {
    this.failureCount++;
    this.lastFailureTime = Date.now();
    
    if (this.failureCount >= this.config.failureThreshold && 
        this.state === CircuitState.CLOSED) {
      this.state = CircuitState.OPEN;
      console.log('Circuit breaker: OPEN (too many failures)');
    }
  }
}

// Usage
const apiBreaker = new CircuitBreaker(
  () => fetchFromAPI(),
  {
    failureThreshold: 5,
    successThreshold: 2,
    timeoutMs: 30000,
  }
);

// Requests will fail fast if service is down
const data = await apiBreaker.call();
\`\`\`

---

## Fallback Strategies

### Graceful Degradation

\`\`\`typescript
// ❌ Bad: no fallback, complete failure
async function getUserDashboard(userId: string) {
  const [profile, posts, followers] = await Promise.all([
    fetchUserProfile(userId),    // External API
    fetchUserPosts(userId),      // Database
    fetchFollowerCount(userId),  // External service
  ]);
  
  return { profile, posts, followers };
}

// ✅ Good: fallback for optional data
async function getUserDashboard(userId: string) {
  const profile = await fetchUserProfile(userId); // Critical, fail
  
  // Non-critical, use fallbacks
  let posts = [];
  try {
    posts = await fetchUserPosts(userId);
  } catch (error) {
    console.warn('Failed to fetch posts, showing empty', { userId });
    posts = [];
  }
  
  let followers = 0;
  try {
    followers = await fetchFollowerCount(userId);
  } catch (error) {
    console.warn('Failed to fetch follower count, showing 0', { userId });
    followers = 0;
  }
  
  return { profile, posts, followers };
}
\`\`\`

### Cache Fallback

\`\`\`typescript
const cache = new Map<string, { data: any; expireAt: number }>();

async function getWithFallback<T>(
  key: string,
  fetcher: () => Promise<T>,
  ttlMs: number = 5 * 60 * 1000 // 5 minutes default
): Promise<T> {
  // Try fresh data first
  try {
    const data = await fetcher();
    
    // Cache for fallback
    cache.set(key, {
      data,
      expireAt: Date.now() + ttlMs,
    });
    
    return data;
  } catch (error) {
    // Fallback to cached data if available
    const cached = cache.get(key);
    
    if (cached && Date.now() < cached.expireAt) {
      console.warn('Using stale cache due to fetch error', { key });
      return cached.data;
    }
    
    // No cache available, fail
    throw error;
  }
}

// Usage
const userData = await getWithFallback(
  \`user-\${userId}\`,
  () => fetchFromExternalAPI(userId),
  10 * 60 * 1000 // 10 minute cache
);
\`\`\`

---

## Timeout Handling

\`\`\`typescript
// Helper to add timeout to any promise
const withTimeout = <T>(
  promise: Promise<T>,
  timeoutMs: number
): Promise<T> => {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(
        () => reject(new Error(\`Operation timed out after \${timeoutMs}ms\`)),
        timeoutMs
      )
    ),
  ]);
};

// Usage
try {
  const result = await withTimeout(
    fetchFromSlowAPI(),
    5000 // 5 second timeout
  );
} catch (error) {
  if (error.message.includes('timed out')) {
    console.error('API request timed out');
    // Use fallback
  }
}

// In Convex mutations/queries
export const getUserWithTimeout = query({
  handler: async (ctx) => {
    return withTimeout(
      ctx.db.query('users').collect(),
      2000 // 2 second database timeout
    );
  },
});
\`\`\`

---

## Bulkhead Pattern

Isolate failures so they don't cascade across the system.

\`\`\`typescript
// Limit concurrent requests to external service
class Bulkhead {
  private activeRequests = 0;
  private queue: Array<{
    fn: () => Promise<any>;
    resolve: (value: any) => void;
    reject: (error: any) => void;
  }> = [];
  
  constructor(private maxConcurrent: number) {}
  
  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.activeRequests < this.maxConcurrent) {
      this.activeRequests++;
      
      try {
        return await fn();
      } finally {
        this.activeRequests--;
        this.processQueue();
      }
    }
    
    // Queue if at capacity
    return new Promise((resolve, reject) => {
      this.queue.push({
        fn,
        resolve,
        reject,
      });
    });
  }
  
  private async processQueue() {
    if (this.queue.length === 0) return;
    
    const { fn, resolve, reject } = this.queue.shift()!;
    
    try {
      const result = await this.execute(fn);
      resolve(result);
    } catch (error) {
      reject(error);
    }
  }
}

// Usage: limit API calls to 10 concurrent
const apiBulkhead = new Bulkhead(10);

const response = await apiBulkhead.execute(() =>
  fetchFromExternalAPI()
);
\`\`\`

---

## Error Response Format

\`\`\`typescript
// Consistent error response format for APIs
interface ErrorResponse {
  success: false;
  error: {
    code: string;        // Machine-readable code
    message: string;     // User-friendly message
    details?: any;       // Optional additional details
    traceId?: string;    // For debugging
  };
}

// Example implementations
const createValidationError = (details: any): ErrorResponse => ({
  success: false,
  error: {
    code: 'VALIDATION_ERROR',
    message: 'Invalid request parameters',
    details,
  },
});

const createNotFoundError = (resource: string): ErrorResponse => ({
  success: false,
  error: {
    code: 'NOT_FOUND',
    message: \`\${resource} not found\`,
  },
});

const createInternalError = (traceId: string): ErrorResponse => ({
  success: false,
  error: {
    code: 'INTERNAL_ERROR',
    message: 'An unexpected error occurred',
    traceId,
  },
});
\`\`\`

---

## Related Skills

- @logging-observability — Log errors and recovery attempts
- @database-optimization — Handle database connection failures
- @doc-generation — Document error codes and recovery procedures
- @contract-testing-openapi (QA) — Validate error responses match contracts

## References

- [Release It! By Michael Nygard](https://pragprog.com/titles/mnee2/release-it-second-edition/) — Circuit breakers, bulkheads, timeouts
- [AWS Well-Architected Framework: Resilience](https://docs.aws.amazon.com/wellarchitected/latest/resilience-pillar/)
- [Google SRE Book: Handling Overload](https://sre.google/books/)
- [Exponential Backoff And Jitter](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/)
`,
  "fix-merge-conflict": `---
name: fix-merge-conflict
description: Fix all merge conflicts on the current Git branch non-interactively
disable-model-invocation: true
---

Fix all merge conflicts on the current Git branch non-interactively and make the repo buildable and tested.

Requirements and constraints:

- Operate from the repository root. If not in a Git repo, stop and report.
- Do not ask the user for input. Choose sensible defaults and explain decisions in a brief summary.
- Prefer minimal, correct changes that preserve both sides' intent when possible.
- Use non-interactive flags for any tools you invoke.
- Do not push or tag; only commit locally.

High-level plan:

1. Detect conflicts
   - Run: git status --porcelain | cat
   - Collect files with conflict markers (U statuses or files containing <<<<<<< / ======= / >>>>>>>).
2. Resolve conflicts per file
   - Open each conflicting file and remove conflict markers.
   - Merge both sides logically when feasible. If mutually exclusive, pick the variant that:
     - Compiles and passes type checks, and
     - Preserves existing public APIs and behavior.
   - Language-aware strategy:
     - package.json/pnpm-lock.yaml/yarn.lock: merge keys conservatively; run install to regenerate lockfiles.
     - .lock files (package-lock.json, yarn.lock, pnpm-lock.yaml): prefer regenerating via the package manager rather than manual edits.
     - Generated files and build artifacts: prefer keeping them out of version control if applicable; otherwise prefer current branch (ours).
     - Config files: preserve union of safe settings; avoid deleting required fields.
     - Text/markdown: include both unique content, deduplicate headings.
     - Binary files: prefer current branch (ours) unless project docs indicate otherwise.
3. Validate
   - If Node/TypeScript/JS present: install deps if manifests changed (use --frozen-lockfile false equivalents), then run lint/typecheck/build/tests if available.
   - If other ecosystems detected (Python, Go, etc.), run their standard build/tests when available.
4. Finalize
   - Stage all resolved files and any regenerated lockfiles.
   - Create a single commit with message: "chore: resolve merge conflicts".
   - Output a concise summary of files touched and notable resolution choices.

Operational guidance:

- Assume the user isn't available; make best-effort decisions. If a resolution is ambiguous and blocks build/tests, prefer the variant that compiles and green-tests.
- If a file still contains conflict markers after your first pass, revisit and resolve them before proceeding.
- For large refactors causing conflicts, prefer keeping consistent imports, types, and module boundaries. Use exhaustive switch guards in TypeScript and explicit type annotations where needed.
- Keep edits minimal and readable; avoid reformatting unrelated code.

Deliverables:

- A clean working tree with all conflicts resolved.
- Successful build/tests where applicable.
- One local commit containing the resolutions.
`,
  "frontend-nextjs": `---
name: vercel-react-best-practices
description: React and Next.js performance optimization guidelines from Vercel Engineering. This skill should be used when writing, reviewing, or refactoring React/Next.js code to ensure optimal performance patterns. Triggers on tasks involving React components, Next.js pages, data fetching, bundle optimization, or performance improvements.
license: MIT
metadata:
  author: vercel
  version: "1.0.0"
---

# Vercel React Best Practices

Comprehensive performance optimization guide for React and Next.js applications, maintained by Vercel. Contains 57 rules across 8 categories, prioritized by impact to guide automated refactoring and code generation.

## When to Apply

Reference these guidelines when:
- Writing new React components or Next.js pages
- Implementing data fetching (client or server-side)
- Reviewing code for performance issues
- Refactoring existing React/Next.js code
- Optimizing bundle size or load times

## Rule Categories by Priority

| Priority | Category | Impact | Prefix |
|----------|----------|--------|--------|
| 1 | Eliminating Waterfalls | CRITICAL | \`async-\` |
| 2 | Bundle Size Optimization | CRITICAL | \`bundle-\` |
| 3 | Server-Side Performance | HIGH | \`server-\` |
| 4 | Client-Side Data Fetching | MEDIUM-HIGH | \`client-\` |
| 5 | Re-render Optimization | MEDIUM | \`rerender-\` |
| 6 | Rendering Performance | MEDIUM | \`rendering-\` |
| 7 | JavaScript Performance | LOW-MEDIUM | \`js-\` |
| 8 | Advanced Patterns | LOW | \`advanced-\` |

## Quick Reference

### 1. Eliminating Waterfalls (CRITICAL)

- \`async-defer-await\` - Move await into branches where actually used
- \`async-parallel\` - Use Promise.all() for independent operations
- \`async-dependencies\` - Use better-all for partial dependencies
- \`async-api-routes\` - Start promises early, await late in API routes
- \`async-suspense-boundaries\` - Use Suspense to stream content

### 2. Bundle Size Optimization (CRITICAL)

- \`bundle-barrel-imports\` - Import directly, avoid barrel files
- \`bundle-dynamic-imports\` - Use next/dynamic for heavy components
- \`bundle-defer-third-party\` - Load analytics/logging after hydration
- \`bundle-conditional\` - Load modules only when feature is activated
- \`bundle-preload\` - Preload on hover/focus for perceived speed

### 3. Server-Side Performance (HIGH)

- \`server-auth-actions\` - Authenticate server actions like API routes
- \`server-cache-react\` - Use React.cache() for per-request deduplication
- \`server-cache-lru\` - Use LRU cache for cross-request caching
- \`server-dedup-props\` - Avoid duplicate serialization in RSC props
- \`server-serialization\` - Minimize data passed to client components
- \`server-parallel-fetching\` - Restructure components to parallelize fetches
- \`server-after-nonblocking\` - Use after() for non-blocking operations

### 4. Client-Side Data Fetching (MEDIUM-HIGH)

- \`client-swr-dedup\` - Use SWR for automatic request deduplication
- \`client-event-listeners\` - Deduplicate global event listeners
- \`client-passive-event-listeners\` - Use passive listeners for scroll
- \`client-localstorage-schema\` - Version and minimize localStorage data

### 5. Re-render Optimization (MEDIUM)

- \`rerender-defer-reads\` - Don't subscribe to state only used in callbacks
- \`rerender-memo\` - Extract expensive work into memoized components
- \`rerender-memo-with-default-value\` - Hoist default non-primitive props
- \`rerender-dependencies\` - Use primitive dependencies in effects
- \`rerender-derived-state\` - Subscribe to derived booleans, not raw values
- \`rerender-derived-state-no-effect\` - Derive state during render, not effects
- \`rerender-functional-setstate\` - Use functional setState for stable callbacks
- \`rerender-lazy-state-init\` - Pass function to useState for expensive values
- \`rerender-simple-expression-in-memo\` - Avoid memo for simple primitives
- \`rerender-move-effect-to-event\` - Put interaction logic in event handlers
- \`rerender-transitions\` - Use startTransition for non-urgent updates
- \`rerender-use-ref-transient-values\` - Use refs for transient frequent values

### 6. Rendering Performance (MEDIUM)

- \`rendering-animate-svg-wrapper\` - Animate div wrapper, not SVG element
- \`rendering-content-visibility\` - Use content-visibility for long lists
- \`rendering-hoist-jsx\` - Extract static JSX outside components
- \`rendering-svg-precision\` - Reduce SVG coordinate precision
- \`rendering-hydration-no-flicker\` - Use inline script for client-only data
- \`rendering-hydration-suppress-warning\` - Suppress expected mismatches
- \`rendering-activity\` - Use Activity component for show/hide
- \`rendering-conditional-render\` - Use ternary, not && for conditionals
- \`rendering-usetransition-loading\` - Prefer useTransition for loading state

### 7. JavaScript Performance (LOW-MEDIUM)

- \`js-batch-dom-css\` - Group CSS changes via classes or cssText
- \`js-index-maps\` - Build Map for repeated lookups
- \`js-cache-property-access\` - Cache object properties in loops
- \`js-cache-function-results\` - Cache function results in module-level Map
- \`js-cache-storage\` - Cache localStorage/sessionStorage reads
- \`js-combine-iterations\` - Combine multiple filter/map into one loop
- \`js-length-check-first\` - Check array length before expensive comparison
- \`js-early-exit\` - Return early from functions
- \`js-hoist-regexp\` - Hoist RegExp creation outside loops
- \`js-min-max-loop\` - Use loop for min/max instead of sort
- \`js-set-map-lookups\` - Use Set/Map for O(1) lookups
- \`js-tosorted-immutable\` - Use toSorted() for immutability

### 8. Advanced Patterns (LOW)

- \`advanced-event-handler-refs\` - Store event handlers in refs
- \`advanced-init-once\` - Initialize app once per app load
- \`advanced-use-latest\` - useLatest for stable callback refs

## How to Use

Read individual rule files for detailed explanations and code examples:

\`\`\`
rules/async-parallel.md
rules/bundle-barrel-imports.md
\`\`\`

Each rule file contains:
- Brief explanation of why it matters
- Incorrect code example with explanation
- Correct code example with explanation
- Additional context and references

## Full Compiled Document

For the complete guide with all rules expanded: \`AGENTS.md\`
`,
  "generate-pr-description": `---
name: generate-pr-description
description: Generate PR Description
disable-model-invocation: true
---

# Generate PR Description

## Overview

Create a comprehensive pull request description based on the changes in this branch and format it as proper markdown for use in a GitHub PR description.

## Steps

1. **Summary**
   - Provide a clear, concise summary of what this PR accomplishes
2. **Changes Made**
   - List the key changes made in this PR
   - Include both code and non-code changes
   - Highlight any breaking changes
3. **Testing**
   - Describe how the changes were tested
   - Include any new test cases added
   - Note any manual testing performed
4. **Related Issues**
   - Link to any related issues or tickets
   - Use closing keywords if this PR resolves issues
5. **Additional Notes**
   - Any deployment considerations
   - Follow-up work required
   - Notes for reviewers

## Generate PR Description Checklist

- [ ] Provided clear, concise summary of what this PR accomplishes
- [ ] Listed all key changes made in this PR
- [ ] Highlighted any breaking changes
- [ ] Described how the changes were tested
- [ ] Included any new test cases added
- [ ] Noted any manual testing performed
- [ ] Linked to any related issues or tickets
- [ ] Included any deployment considerations
- [ ] Noted any follow-up work required
- [ ] Formatted as proper markdown for GitHub PR
`,
  "github-issue-triage": `---
name: github-issue-triage
description: Triage GitHub issues: label, prioritize, assign. Check repo CONTRIBUTING and issue templates.
---

# GitHub issue triage

Use this skill when triaging GitHub issues: label, prioritize, assign. Check repo CONTRIBUTING and issue templates.
`,
  "integration-testing": `---
name: integration-testing
description: Multi-service testing, contract testing with Pact, service mocking, and test data management
---

# Integration Testing

## Overview

Test interactions between multiple services and components to ensure they work correctly together. This skill covers integration test strategies, service mocking, contract testing, and test data management.

**Use this skill when:**
- Testing APIs that depend on other services
- Verifying microservices communication
- Testing database integration
- Validating external service interactions
- Ensuring contracts between services

## Integration Testing Pyramid

\`\`\`
        E2E Tests (Cypress, Playwright)
       /                              \\
      /        Few, Slow, Expensive    \\
     /_________________________________ \\
    /       Integration Tests           \\
   /        Many, Medium Speed, Medium  \\
  /____________________________________  \\
 /         Unit Tests                    \\
/__         Many, Fast, Cheap             \\
  \\
   Many    → More coverage, higher cost
   Few     ← Better ROI, catches regressions
\`\`\`

## Types of Integration Tests

### API-to-Database Integration

\`\`\`typescript
// Test: Create user → Save to DB → Query user
import { test, expect } from '@jest/globals';

describe('User API Integration with Database', () => {
  test('should create and retrieve user', async () => {
    // 1. Create user via API
    const createRes = await fetch('/api/users', {
      method: 'POST',
      body: JSON.stringify({
        email: 'test@example.com',
        name: 'Test User'
      })
    });
    
    expect(createRes.status).toBe(201);
    const user = await createRes.json();
    
    // 2. Query database directly to verify
    const dbUser = await db.users.findById(user.id);
    expect(dbUser.email).toBe('test@example.com');
    
    // 3. Retrieve via API and compare
    const getRes = await fetch(\`/api/users/\${user.id}\`);
    const retrievedUser = await getRes.json();
    expect(retrievedUser.email).toBe('test@example.com');
  });
});
\`\`\`

### Service-to-Service Integration

\`\`\`typescript
// Test: User Service calls Email Service
describe('User Service Integration with Email Service', () => {
  test('should send welcome email when user registers', async () => {
    // Mock Email Service
    const emailServiceMock = jest.mock('email-service');
    emailServiceMock.send = jest.fn().mockResolvedValue({ sent: true });
    
    // Call User Service
    const user = await userService.register({
      email: 'test@example.com',
      name: 'Test User'
    });
    
    // Verify Email Service was called
    expect(emailServiceMock.send).toHaveBeenCalledWith({
      to: 'test@example.com',
      template: 'welcome',
      variables: { name: 'Test User' }
    });
  });
});
\`\`\`

## Contract Testing with Pact

Contract testing verifies that services agree on communication format without requiring both services running.

### Setup Pact

\`\`\`bash
npm install --save-dev @pact-foundation/pact jest
\`\`\`

### Consumer Test (Client Side)

\`\`\`typescript
// user-api.test.ts - Consumer tests what it expects from API
import { PactV3 } from '@pact-foundation/pact';

const provider = new PactV3({
  consumer: 'UserUI',
  provider: 'UserAPI'
});

describe('User API Contract', () => {
  test('should get user by ID', async () => {
    await provider
      .addInteraction({
        states: [{ description: 'user 123 exists' }],
        uponReceiving: 'a request for user 123',
        withRequest: {
          method: 'GET',
          path: '/api/users/123'
        },
        willRespondWith: {
          status: 200,
          body: {
            id: '123',
            name: 'John Doe',
            email: 'john@example.com'
          }
        }
      })
      .executeTest(async (mockServer) => {
        const user = await fetch(\`\${mockServer.url}/api/users/123\`);
        expect(user.name).toBe('John Doe');
      });
  });
});
\`\`\`

### Provider Test (Server Side)

\`\`\`typescript
// user-api.provider.test.ts - Provider verifies it meets contract
import { Verifier } from '@pact-foundation/pact';

describe('User API Provider', () => {
  test('should meet user-ui consumer contract', async () => {
    const verifier = new Verifier({
      providerBaseUrl: 'http://localhost:3000',
      pactUrls: ['./pacts/userui-userapi.json']
    });

    await verifier
      .withStateHandler('user 123 exists', async () => {
        await db.users.create({
          id: '123',
          name: 'John Doe',
          email: 'john@example.com'
        });
      })
      .verifyProvider();
  });
});
\`\`\`

**Benefits:**
- Services can develop independently
- Catch breaking changes early
- Prevent integration surprises
- Clear contract documentation

## Service Mocking

### HTTP Mocking with MSW (Mock Service Worker)

\`\`\`typescript
// handlers.ts
import { http, HttpResponse } from 'msw';

export const handlers = [
  // Mock GET /api/users
  http.get('http://localhost:3000/api/users', () => {
    return HttpResponse.json([
      { id: '1', name: 'John', email: 'john@example.com' },
      { id: '2', name: 'Jane', email: 'jane@example.com' }
    ]);
  }),

  // Mock POST /api/users
  http.post('http://localhost:3000/api/users', async ({ request }) => {
    const body = await request.json();
    return HttpResponse.json({
      id: '3',
      ...body
    }, { status: 201 });
  })
];
\`\`\`

**Using in Tests:**

\`\`\`typescript
import { setupServer } from 'msw/node';
import { handlers } from './handlers';

const server = setupServer(...handlers);

describe('User Service', () => {
  beforeAll(() => server.listen());
  afterEach(() => server.resetHandlers());
  afterAll(() => server.close());

  test('should fetch users', async () => {
    const users = await userService.getUsers();
    expect(users).toHaveLength(2);
    expect(users[0].name).toBe('John');
  });

  test('should handle custom response', async () => {
    server.use(
      http.get('http://localhost:3000/api/users', () => {
        return HttpResponse.json([], { status: 500 });
      })
    );

    await expect(userService.getUsers()).rejects.toThrow();
  });
});
\`\`\`

## Test Data Management

### Fixture Factory Pattern

\`\`\`typescript
// factories.ts
export function createUser(overrides = {}) {
  return {
    id: '123',
    email: 'test@example.com',
    name: 'Test User',
    createdAt: new Date(),
    ...overrides
  };
}

export function createPost(overrides = {}) {
  return {
    id: '456',
    userId: '123',
    title: 'Test Post',
    content: 'Test content',
    ...overrides
  };
}

// In tests
test('should create post for user', () => {
  const user = createUser({ email: 'john@example.com' });
  const post = createPost({ userId: user.id });
  
  expect(post.userId).toBe(user.id);
});
\`\`\`

### Database Setup/Teardown

\`\`\`typescript
describe('User Repository', () => {
  beforeEach(async () => {
    // Clear database
    await db.users.deleteMany({});
    
    // Seed test data
    await db.users.insert([
      createUser({ id: '1' }),
      createUser({ id: '2' })
    ]);
  });

  afterEach(async () => {
    // Clean up after test
    await db.users.deleteMany({});
  });

  test('should find user by email', async () => {
    const user = await db.users.findByEmail('test@example.com');
    expect(user).toBeDefined();
  });
});
\`\`\`

### Transaction Isolation

\`\`\`typescript
// Use transactions to keep tests isolated
describe('User Service with Transactions', () => {
  test('should rollback failed transactions', async () => {
    const tx = db.transaction();
    
    try {
      await tx.users.insert({ email: 'test@example.com' });
      await tx.profiles.insert({ userId: 'invalid' }); // Fails
      await tx.commit();
    } catch {
      await tx.rollback();
    }

    // User should not exist
    const user = await db.users.findByEmail('test@example.com');
    expect(user).toBeNull();
  });
});
\`\`\`

## Testing Async Workflows

### Event-Driven Integration

\`\`\`typescript
// Test: Publish event → Service consumes → DB updated
describe('Event-Driven Integration', () => {
  test('should update user profile on user-updated event', async () => {
    const eventBus = new EventEmitter();
    const profileService = new ProfileService(eventBus);

    // Listen for profile-updated event
    const profileUpdated = new Promise(resolve => {
      eventBus.on('profile:updated', resolve);
    });

    // Publish event
    eventBus.emit('user:updated', {
      userId: '123',
      name: 'Updated Name'
    });

    // Wait for profile service to process
    await profileUpdated;

    // Verify DB updated
    const profile = await db.profiles.findByUserId('123');
    expect(profile.name).toBe('Updated Name');
  });
});
\`\`\`

### Queue/Message Testing

\`\`\`typescript
// Test: Message published → Service consumes → Action performed
describe('Message Queue Integration', () => {
  test('should process email queue message', async () => {
    const queue = new MessageQueue();

    // Listen for processing
    const processed = jest.fn();
    queue.on('processed', processed);

    // Publish message
    await queue.publish('emails', {
      to: 'test@example.com',
      template: 'welcome'
    });

    // Process queue
    await queue.process('emails', async (msg) => {
      await emailService.send(msg);
      processed();
    });

    // Verify
    expect(emailService.send).toHaveBeenCalled();
    expect(processed).toHaveBeenCalled();
  });
});
\`\`\`

## Integration Test Checklist

- [ ] Test APIs with actual database
- [ ] Test service-to-service communication
- [ ] Use Pact for contract testing
- [ ] Mock external services (HTTP, queues)
- [ ] Test error scenarios (service down, timeout)
- [ ] Use factory functions for test data
- [ ] Clean up test data after each test
- [ ] Test async workflows with proper waiting
- [ ] Document test scenarios
- [ ] Run integration tests in CI/CD

## Common Pitfalls

**❌ Avoid:**
- Testing implementation details
- Creating integration tests for simple logic
- Not cleaning up test data
- Testing with production data
- Brittle tests that break with minor changes

**✅ Do:**
- Test behavior, not implementation
- Use integration tests for complex interactions
- Use fixtures/factories for data
- Mock external dependencies
- Keep tests maintainable

## Related Skills

- @test-automation - Implement automated integration tests
- @backend-convex - Test Convex database integration
- @api-design - Test API contracts and schemas
- @security-hardening - Test security in integrations
`,
  "logging-observability": `---
name: logging-observability
description: Structured logging patterns, distributed tracing, log aggregation, and observability for production systems
---

# Logging & Observability

## Overview

Build observable systems through structured logging, distributed tracing, and log aggregation. This skill covers instrumentation patterns that enable debugging production issues and monitoring system health.

**Use this skill when:**
- Investigating production errors
- Debugging complex issues
- Monitoring application performance
- Tracking user journeys across services
- Building alerting and monitoring systems

**Cross-functional pairing:** @qa **regression-testing** — Observability data helps validate test behavior and catch regressions in production

---

## Structured Logging

### From Unstructured to Structured

\`\`\`typescript
// ❌ Bad: unstructured logs (hard to parse, search, aggregate)
console.log('User login attempt at 2026-02-06T10:00:00Z from 192.168.1.1');
console.log('Successfully authenticated user');
console.log('Database query took 45ms');

// ✅ Good: structured logs (JSON, searchable, queryable)
const logger = {
  info: (message, context) => console.log(JSON.stringify({
    timestamp: new Date().toISOString(),
    level: 'info',
    message,
    ...context,
  })),
};

logger.info('User login attempt', {
  userId: user._id,
  ipAddress: '192.168.1.1',
  userAgent: req.headers['user-agent'],
});

logger.info('User authenticated', {
  userId: user._id,
  method: 'oauth',
  duration: 150,
});
\`\`\`

### Log Levels and Usage

\`\`\`typescript
enum LogLevel {
  DEBUG = 'DEBUG',   // Detailed info for developers (off in production)
  INFO = 'INFO',     // General informational messages
  WARN = 'WARN',     // Warning conditions (recoverable errors)
  ERROR = 'ERROR',   // Error conditions (unrecoverable)
  FATAL = 'FATAL',   // System is shutting down
}

// Examples
logger.debug('Database query executed', { query, params, result });
logger.info('User created', { userId, email });
logger.warn('Slow query detected', { duration: 5000, threshold: 1000 });
logger.error('Payment processing failed', { reason, userId, orderId, attempt: 1 });
logger.fatal('Database connection lost', { error: err.message });
\`\`\`

### Structured Log Format

\`\`\`typescript
interface StructuredLog {
  timestamp: string;      // ISO 8601
  level: LogLevel;        // DEBUG, INFO, WARN, ERROR, FATAL
  message: string;        // Unique, searchable message
  traceId: string;        // Links logs from same request
  spanId: string;         // Links logs within a span
  userId?: string;        // For user-specific queries
  requestId?: string;     // For request-specific queries
  duration?: number;      // In milliseconds
  error?: {
    message: string;
    stack: string;
    code: string;
  };
  context: Record<string, any>; // Additional structured data
}

// Example log entry
const log: StructuredLog = {
  timestamp: '2026-02-06T10:00:00.123Z',
  level: 'INFO',
  message: 'Database query executed',
  traceId: 'abc123',
  spanId: 'span-456',
  userId: 'user-789',
  duration: 45,
  context: {
    table: 'posts',
    filter: 'userId = ?',
    rowsReturned: 25,
  },
};
\`\`\`

### Logging Context in Convex

\`\`\`typescript
// Helper for structured logging in mutations/queries
export const createLogger = (ctx) => {
  const traceId = crypto.randomUUID();
  
  return {
    debug: (message, context = {}) => {
      if (process.env.DEBUG) {
        console.log(JSON.stringify({
          timestamp: new Date().toISOString(),
          level: 'DEBUG',
          message,
          traceId,
          ...context,
        }));
      }
    },
    
    info: (message, context = {}) => {
      console.log(JSON.stringify({
        timestamp: new Date().toISOString(),
        level: 'INFO',
        message,
        traceId,
        ...context,
      }));
    },
    
    error: (message, error, context = {}) => {
      console.error(JSON.stringify({
        timestamp: new Date().toISOString(),
        level: 'ERROR',
        message,
        traceId,
        error: {
          message: error?.message,
          stack: error?.stack,
          code: error?.code,
        },
        ...context,
      }));
    },
  };
};

// Usage in mutation
export const createPost = mutation({
  args: { title: v.string(), content: v.string() },
  handler: async (ctx, args) => {
    const logger = createLogger(ctx);
    
    logger.info('Creating post', { title: args.title });
    
    try {
      const postId = await ctx.db.insert('posts', {
        title: args.title,
        content: args.content,
        userId: ctx.userId,
        createdAt: Date.now(),
      });
      
      logger.info('Post created successfully', {
        postId,
        duration: Date.now() - startTime,
      });
      
      return postId;
    } catch (error) {
      logger.error('Failed to create post', error, {
        title: args.title,
      });
      throw error;
    }
  },
});
\`\`\`

---

## Distributed Tracing

### Trace IDs and Span IDs

**Trace ID:** Unique identifier for an entire user request across services
**Span ID:** Identifier for a specific operation within the trace

\`\`\`typescript
// Request starts with trace ID
// Trace: abc-123-def
//   ├─ Span 1: HTTP request received
//   ├─ Span 2: Authenticate user (50ms)
//   ├─ Span 3: Query database (45ms)
//   │   ├─ Span 3.1: Build query (5ms)
//   │   └─ Span 3.2: Execute query (40ms)
//   ├─ Span 4: Process results (10ms)
//   └─ Span 5: Send response (2ms)

interface TraceContext {
  traceId: string;
  parentSpanId?: string;
  spanId: string;
  startTime: number;
}

export const createSpan = (
  traceId: string,
  spanName: string,
  parentSpan?: TraceContext
): TraceContext => ({
  traceId,
  parentSpanId: parentSpan?.spanId,
  spanId: \`\${spanName}-\${crypto.randomUUID()}\`,
  startTime: Date.now(),
});

// Log span completion
export const endSpan = (span: TraceContext) => {
  const duration = Date.now() - span.startTime;
  console.log(JSON.stringify({
    timestamp: new Date().toISOString(),
    level: 'DEBUG',
    message: 'Span completed',
    traceId: span.traceId,
    spanId: span.spanId,
    parentSpanId: span.parentSpanId,
    duration,
  }));
};

// Usage
const traceId = 'abc-123-def';
const authSpan = createSpan(traceId, 'authenticate');
await authenticateUser(user);
endSpan(authSpan);

const dbSpan = createSpan(traceId, 'database', authSpan);
const posts = await fetchUserPosts(userId);
endSpan(dbSpan);
\`\`\`

---

## Log Aggregation & Analysis

### Setting Up Log Aggregation

**Tools:** Datadog, ELK Stack, Splunk, CloudWatch, Loggly

\`\`\`typescript
// Example: Send logs to external service
const sendLog = async (log: StructuredLog) => {
  if (process.env.LOG_SERVICE_URL) {
    try {
      await fetch(process.env.LOG_SERVICE_URL, {
        method: 'POST',
        body: JSON.stringify(log),
        headers: { 'Content-Type': 'application/json' },
      });
    } catch (error) {
      // Fallback: log to console if service unavailable
      console.error('Failed to send log to service:', error);
    }
  }
};

// Buffer logs in batch for efficiency
const logBuffer = [];
const BATCH_SIZE = 100;
const FLUSH_INTERVAL = 5000; // 5 seconds

const addLog = async (log: StructuredLog) => {
  logBuffer.push(log);
  
  if (logBuffer.length >= BATCH_SIZE) {
    await flushLogs();
  }
};

const flushLogs = async () => {
  if (logBuffer.length === 0) return;
  
  const batch = logBuffer.splice(0, logBuffer.length);
  await Promise.all(batch.map(sendLog));
};

// Flush periodically
setInterval(flushLogs, FLUSH_INTERVAL);
\`\`\`

### Querying Logs

\`\`\`typescript
// Examples in log aggregation service (Datadog syntax)

// Find all errors from specific user
// level:ERROR AND userId:"user-123"

// Find slow database queries
// message:"Database query executed" AND duration:>1000

// Find errors in past hour
// level:ERROR AND timestamp:[now-1h TO now]

// Analyze error frequency by type
// GROUP BY error.code | COUNT AS error_count | SORT error_count DESC

// Correlation: Find all requests that led to payment failure
// traceId IN (SELECT traceId FROM logs WHERE message:"Payment failed")
\`\`\`

---

## Performance Monitoring

### Metrics to Track

\`\`\`typescript
interface PerformanceMetrics {
  // Latency
  p50: number;  // 50th percentile (median)
  p95: number;  // 95th percentile
  p99: number;  // 99th percentile
  
  // Throughput
  requestsPerSecond: number;
  
  // Errors
  errorRate: number;
  
  // Saturation
  cpuUsage: number;
  memoryUsage: number;
  databaseConnections: number;
}

// Log performance metrics
logger.info('Metrics snapshot', {
  metrics: {
    apiLatencyP95: 150, // ms
    databaseQueryP95: 45, // ms
    errorRate: 0.001, // 0.1%
    requestsPerSecond: 500,
  },
  timestamp: new Date().toISOString(),
});
\`\`\`

### Alerting Thresholds

\`\`\`typescript
const ALERT_THRESHOLDS = {
  API_LATENCY_P95_MS: 1000,
  ERROR_RATE_PERCENT: 1.0,
  DATABASE_CONNECTIONS_PERCENT: 80,
  MEMORY_USAGE_PERCENT: 85,
  QUEUE_LENGTH: 10000,
};

const checkAlerts = (metrics: PerformanceMetrics) => {
  if (metrics.p95 > ALERT_THRESHOLDS.API_LATENCY_P95_MS) {
    sendAlert({
      severity: 'warning',
      message: \`API latency P95 is \${metrics.p95}ms (threshold: \${ALERT_THRESHOLDS.API_LATENCY_P95_MS}ms)\`,
    });
  }
  
  if (metrics.errorRate > ALERT_THRESHOLDS.ERROR_RATE_PERCENT) {
    sendAlert({
      severity: 'critical',
      message: \`Error rate is \${metrics.errorRate}% (threshold: \${ALERT_THRESHOLDS.ERROR_RATE_PERCENT}%)\`,
    });
  }
};
\`\`\`

---

## Best Practices

### What To Log

✅ **DO log:**
- User actions (login, create post, purchase)
- Errors and exceptions (with full stack trace)
- Performance metrics (query time, API latency)
- Security events (failed auth, permission denied)
- System events (service started, database connected)

❌ **DON'T log:**
- Passwords, API keys, tokens
- Personal information (without consent)
- Sensitive financial data
- Entire request/response bodies (log relevant fields only)
- Spam messages (e.g., log every loop iteration)

### Log Volume Management

\`\`\`typescript
// Sampling: log 1% of successful requests, 100% of errors
const shouldLog = (level: LogLevel, duration: number) => {
  if (level === 'ERROR' || level === 'FATAL') return true;
  if (duration > 1000) return true; // Log slow requests
  if (Math.random() < 0.01) return true; // 1% sample
  return false;
};

// Rate limiting: prevent log spam
const logRateLimiter = new Map<string, number>();

const canLog = (key: string, maxPerSecond = 100) => {
  const now = Date.now();
  const count = logRateLimiter.get(key) || 0;
  
  if (count >= maxPerSecond) return false;
  
  logRateLimiter.set(key, count + 1);
  setTimeout(() => logRateLimiter.delete(key), 1000);
  
  return true;
};
\`\`\`

---

## Related Skills

- @database-optimization — Log query performance
- @error-handling-resilience — Log failures and recovery attempts
- @debug-issue — Use logs to investigate problems
- @regression-testing (QA) — Use observability for test validation

## References

- [12 Factor Apps: Logs](https://12factor.net/logs)
- [Google Cloud Logging Best Practices](https://cloud.google.com/architecture/devops-measurement-logging-patterns)
- [Datadog Logging Best Practices](https://docs.datadoghq.com/logs/)
- [OpenTelemetry Documentation](https://opentelemetry.io/)
`,
  "metrics-reporting": `---
name: metrics-reporting
description: KPI tracking, analytics reporting, burndown charts, DORA metrics, and team performance dashboards
---

# Metrics Reporting

## Overview

Establish and maintain a metrics-driven culture by tracking key performance indicators (KPIs), generating reports, and creating visibility into team velocity, quality, and business impact.

**Use this skill when:**
- Setting up team dashboards
- Creating KPI tracking systems
- Generating status reports for stakeholders
- Analyzing team velocity and capacity
- Measuring release quality and deployment frequency

## Core Metrics Framework

### DORA Metrics (DevOps Research & Assessment)

These four metrics correlate with organizational performance:

1. **Deployment Frequency**
   - How often code is deployed to production
   - Target: Multiple times per day (elite) to monthly (low)
   - Measured by: Commits merged to master / time period

2. **Lead Time for Changes**
   - Time from commit to production deployment
   - Target: <1 hour (elite) to >1 month (low)
   - Measured by: Avg days from merge to deploy tag

3. **Mean Time to Recovery (MTTR)**
   - Time to restore service after production incident
   - Target: <1 hour (elite) to >24 hours (low)
   - Measured by: Incident detection to resolution

4. **Change Failure Rate**
   - Percentage of deployments that cause incidents
   - Target: 0-15% (elite) to >46% (low)
   - Measured by: Failed deployments / total deployments

### Agile Team Metrics

1. **Velocity**
   - Story points completed per sprint
   - Use for: Capacity planning, forecasting
   - Tracked: Sprint dashboard, burndown chart

2. **Burn-down Chart**
   - Planned work vs. completed work over sprint
   - Visual tool for sprint progress
   - Y-axis: Story points remaining, X-axis: Sprint days

3. **Cycle Time**
   - Time from "In Progress" to "Done"
   - Helps identify bottlenecks
   - Target: <5 days (good), <2 days (excellent)

4. **Lead Time**
   - Time from "To Do" to "Done"
   - Includes backlog wait time
   - Higher than cycle time (includes waiting)

### Quality Metrics

1. **Test Coverage**
   - Percentage of code covered by tests
   - Target: >80% for critical paths
   - Tool: Istanbul, Nyc for JavaScript

2. **Bug Detection Rate**
   - Bugs found per release
   - Track: Pre-release vs. post-release
   - Goal: >90% found before release

3. **Code Review Defects**
   - Issues found during code review
   - Helps assess QA effectiveness
   - Target: <2% of changes have review issues

### Business Metrics

1. **Deployment Success Rate**
   - Successful deployments / total deployments
   - Target: >95%

2. **Incident Severity Distribution**
   - P1 (Critical), P2 (High), P3 (Medium), P4 (Low)
   - Track trends over time

3. **Technical Debt Ratio**
   - Time spent on debt work vs. feature work
   - Target: 20-30% on debt
   - Too low: Risk of system degradation
   - Too high: Slow feature delivery

## Dashboard Setup

### Essential Dashboard Components

**Dev Efficiency**
\`\`\`
┌─────────────────────────────────────┐
│ Deployment Frequency (7-day avg)    │
│ 2.3 deployments/day (↑ 15%)        │
├─────────────────────────────────────┤
│ Lead Time (median)                  │
│ 4.2 hours (↓ 20%)                  │
├─────────────────────────────────────┤
│ MTTR (last 30 days)                 │
│ 22 minutes (↓ 10%)                 │
├─────────────────────────────────────┤
│ Change Failure Rate                 │
│ 8.5% (↑ 2%)                        │
└─────────────────────────────────────┘
\`\`\`

**Team Velocity**
\`\`\`
Sprint | Week 1 | Week 2 | Week 3 | Avg
SP     |   32   |   41   |   38   | 37
\`\`\`

**Quality Gates**
\`\`\`
Test Coverage: 87% (Target: 85%) ✅
Critical Bugs: 2 (Target: <1) ⚠️
Code Review: 1.2 issues/PR (Target: <1) 🔴
\`\`\`

## Reporting Cadence

### Daily Standup Metric
- Sprint progress (% complete)
- At-risk items (red/yellow flags)
- Blocker summary

### Weekly Status Report
- Velocity on track?
- Key accomplishments
- Risks and mitigation
- Preview of next week

### Monthly Executive Report
- DORA metrics trend
- Team health score
- Business impact (features delivered, bugs fixed)
- Forecast for next month

### Quarterly Review
- OKR progress (% achieved)
- Key wins and learnings
- Process improvements
- Strategy adjustment

## Tools & Platforms

- **GitHub Insights**: Deployment frequency, PR metrics
- **JIRA Reports**: Velocity, burndown, burnup
- **Grafana**: Real-time dashboards
- **DataDog/New Relic**: Production metrics
- **Custom Dashboards**: Google Sheets, Tableau, Metabase

## Key Formulas

\`\`\`markdown
### Deployment Frequency
(Commits merged to master) / (Days in period)

### Lead Time
(Date deployed) - (Date merged)

### Cycle Time
(Date done) - (Date started)

### Change Failure Rate
(Failed deployments) / (Total deployments) * 100

### Velocity Average
(Sum of story points completed) / (Number of sprints)

### Test Coverage
(Lines covered by tests) / (Total lines) * 100

### Bug Density
(Bugs found) / (1000 lines of code)
\`\`\`

## Actionable Insights

When metrics are trending negatively:

1. **High lead time?**
   - Too much code review back-and-forth
   - Bottleneck in testing
   - Long deployment pipeline

2. **High MTTR?**
   - Monitoring gaps
   - Unclear incident response process
   - Slow root cause analysis

3. **High change failure rate?**
   - Insufficient testing
   - Unclear requirements
   - Too large deployments

4. **Low velocity?**
   - Team context-switching
   - Unclear requirements
   - Technical debt impact
   - External blockers

## Related Skills

- @sprint-planning - Set velocity targets
- @roadmap-planning - Align metrics with strategy
- @stakeholder-communication - Report metrics to leadership
- @test-automation - Improve coverage metrics
`,
  "mutation-testing": `---
name: mutation-testing
description: Mutation testing with Stryker, test quality validation, identifying weak tests, and ensuring tests catch real bugs
---

# Mutation Testing

## Overview

Validate test quality by introducing intentional bugs (mutations) and checking if tests catch them. This skill covers mutation testing tools, mutation operators, test effectiveness measurement, and improving test suites based on mutation results.

**Use this skill when:**
- Evaluating test suite quality
- Identifying weak/missing test cases
- Ensuring tests catch actual bugs
- Improving test effectiveness
- Validating coverage quality (not just metrics)

**Cross-functional pairing:** @engineer **doc-generation** — Well-documented code clarifies intent and edge cases, making it easier to write comprehensive mutation tests

---

## What is Mutation Testing?

### The Concept

\`\`\`
Original Code:
  function add(a, b) { return a + b; }

Mutation 1 (Arithmetic):
  function add(a, b) { return a - b; }  // Changed + to -

Mutation 2 (Return Value):
  function add(a, b) { return a; }      // Removed + b

Test Result:
  ✓ Test: add(1, 2) === 3              // Catches both mutations
  ✓ Mutation 1 kills: -1 ≠ 3
  ✓ Mutation 2 kills: 1 ≠ 3
\`\`\`

### Key Metrics

| Metric | Definition | Interpretation |
|--------|-----------|-----------------|
| **Killed Mutations** | Tests caught the bug | ✓ Good test |
| **Survived Mutations** | Tests missed the bug | ✗ Weak test |
| **Mutation Score** | % of mutations killed | Higher = better tests |

---

## Stryker Installation & Setup

### Installation

\`\`\`bash
npm install --save-dev @stryker-mutator/core \\
  @stryker-mutator/typescript-checker \\
  @stryker-mutator/jest-runner
\`\`\`

### Configuration

\`\`\`javascript
// stryker.config.mjs
export default {
  _comment: 'Mutation testing configuration',
  
  // Files to mutate
  mutate: ['src/**/*.ts', '!src/**/*.test.ts'],
  
  // Test configuration
  testRunner: 'jest',
  jest: {
    config: require('./jest.config.js'),
  },
  
  // Reporters
  reporters: ['html', 'json', 'dashboard'],
  htmlReporter: {
    baseDir: 'reports/mutation',
  },
  
  // Performance
  concurrency: 4,
  timeoutMS: 5000,
  
  // Mutation score threshold
  thresholds: {
    high: 80,    // Green: 80%+
    medium: 60,  // Yellow: 60-79%
    low: 40,     // Red: <60%
  },
};
\`\`\`

### Run Mutations

\`\`\`bash
# Run mutation tests
npm run stryker

# Output:
# ✓ 145 killed
# ✗ 23 survived
# ⊘ 5 no coverage
# Score: 86.3%
\`\`\`

---

## Mutation Operators

### Arithmetic Operators

\`\`\`typescript
// Original code
function multiply(a: number, b: number) {
  return a * b;
}

// Possible mutations
// a * b  →  a + b   (Arithmetic)
// a * b  →  a - b   (Arithmetic)
// a * b  →  a / b   (Arithmetic)
// a * b  →  a % b   (Arithmetic)

test('multiply(3, 4) equals 12', () => {
  expect(multiply(3, 4)).toBe(12);  // Kills all mutations ✓
});

test('multiply(2, 0) equals 0', () => {
  expect(multiply(2, 0)).toBe(0);   // Kills a - b mutation ✓
});
\`\`\`

### Logical Operators

\`\`\`typescript
// Original code
function isAdult(age: number) {
  return age >= 18;
}

// Possible mutations
// age >= 18  →  age > 18    (Boundary)
// age >= 18  →  age <= 18   (Logical)
// age >= 18  →  age < 18    (Logical)

test('age 18 is adult', () => {
  expect(isAdult(18)).toBe(true);   // Kills age > 18 mutation
});

test('age 17 is not adult', () => {
  expect(isAdult(17)).toBe(false);  // Kills age <= 18 mutation
});

test('age 100 is adult', () => {
  expect(isAdult(100)).toBe(true);  // Redundant, doesn't kill new mutations
});
\`\`\`

### Conditional Mutations

\`\`\`typescript
// Original code
function validate(input: string) {
  if (!input) return false;
  if (input.length < 3) return false;
  return true;
}

// Possible mutations
// if (!input)           →  if (input)        (Negate)
// if (input.length < 3) →  if (input.length > 3) (Invert)
// input.length < 3      →  input.length <= 3 (Boundary)
// return true           →  return false     (Return value)

test('empty string fails validation', () => {
  expect(validate('')).toBe(false);        // Kills: if (input)
});

test('short string fails validation', () => {
  expect(validate('ab')).toBe(false);      // Kills: input.length > 3
});

test('three character string passes', () => {
  expect(validate('abc')).toBe(true);      // Kills: return false
});

test('four character string passes', () => {
  expect(validate('abcd')).toBe(true);     // Redundant
});
\`\`\`

---

## Interpreting Mutation Results

### Mutation Report

\`\`\`html
<!-- reports/mutation/index.html -->

File: src/utils.ts
├─ Function: add
│  ├─ add(1, 1)  ✓ 3 killed / 3 mutations
│  └─ Score: 100%
│
├─ Function: divide
│  ├─ divide(10, 2)  ✓ 2 killed / 2 mutations
│  ├─ divide(0, 0)   ✗ 1 survived / 3 mutations
│  └─ Score: 66.7%
│
└─ Function: validate
   ├─ validate('')        ✓ 1 killed
   ├─ validate('short')   ✗ 1 survived
   └─ Score: 50%
\`\`\`

### Analyzing Survived Mutations

\`\`\`typescript
// Original code
function divide(a: number, b: number) {
  if (b === 0) return 0;
  return a / b;
}

// Mutation: b === 0  →  b === 1 (SURVIVED)
// Test doesn't catch this because we only test b === 0

// Fix: Add test for non-zero divisor
test('divide with zero divisor returns 0', () => {
  expect(divide(10, 0)).toBe(0);  // Catches b === 0 mutation
});

test('divide 10 by 2 equals 5', () => {
  expect(divide(10, 2)).toBe(5);  // Now catches b === 1 mutation ✓
});
\`\`\`

---

## Improving Test Quality with Mutations

### Pattern 1: Boundary Testing

\`\`\`typescript
// Weak test: Only happy path
test('age validation', () => {
  expect(isAdult(25)).toBe(true);  // Mutation: 25 ≥ 18 → 25 > 18 (SURVIVES)
});

// Strong test: Boundary cases
test('age 18 is minimum adult age', () => {
  expect(isAdult(18)).toBe(true);  // Catches 25 ≥ 18 → 25 > 18
});

test('age 17 is not adult', () => {
  expect(isAdult(17)).toBe(false); // Catches 25 ≥ 18 → 25 ≤ 18
});
\`\`\`

### Pattern 2: Error Path Testing

\`\`\`typescript
// Weak test: Only success path
async function fetchUser(id: string) {
  return await db.get(id);  // Mutation: await removed (SURVIVES if not tested)
}

test('fetch user by id', async () => {
  const user = await fetchUser('123');
  expect(user.name).toBe('John');  // Doesn't catch missing await
});

// Strong test: Include error scenarios
test('fetch user handles not found', async () => {
  db.get = jest.fn().mockRejectedValue(new Error('Not found'));
  
  await expect(fetchUser('invalid')).rejects.toThrow();
  // Catches mutations in error handling
});
\`\`\`

### Pattern 3: Type Safety

\`\`\`typescript
// Weak test: No type checking
function greet(name: string) {
  return \`Hello, \${name}!\`;
}

test('greet works', () => {
  expect(greet('John')).toContain('Hello');  // Mutation: \`Hello\` → \`Goodbye\` (SURVIVES)
});

// Strong test: Exact assertion
test('greet returns correct greeting', () => {
  expect(greet('John')).toBe('Hello, John!');  // Catches greeting mutation
});
\`\`\`

---

## Incremental Mutation Testing

### CI/CD Integration

\`\`\`yaml
# .github/workflows/mutation.yml
name: Mutation Tests

on:
  pull_request:
  push:
    branches: [master, develop]

jobs:
  mutation:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      
      - run: npm ci
      
      - name: Run mutation tests
        run: npm run stryker
        continue-on-error: true
      
      - name: Check mutation score
        run: |
          SCORE=\$(cat reports/mutation/mutation-score.txt)
          if (( \$(echo "\$SCORE < 70" | bc -l) )); then
            echo "Mutation score below 70%: \$SCORE%"
            exit 1
          fi
      
      - name: Upload mutation report
        uses: actions/upload-artifact@v3
        with:
          name: mutation-report
          path: reports/mutation/
\`\`\`

### Baseline Tracking

\`\`\`bash
# Store baseline mutation score
npm run stryker > mutation-baseline.txt

# Check improvement
npm run stryker > mutation-current.txt
BASELINE=\$(grep "Score:" mutation-baseline.txt | grep -oP '\\d+\\.\\d+')
CURRENT=\$(grep "Score:" mutation-current.txt | grep -oP '\\d+\\.\\d+')

echo "Baseline: \$BASELINE%"
echo "Current: \$CURRENT%"
echo "Improvement: \$(echo "\$CURRENT - \$BASELINE" | bc)%"
\`\`\`

---

## Mutation Testing Best Practices

### Do's

✅ **Run regularly** — Part of CI/CD pipeline  
✅ **Focus on critical code** — Start with high-risk functions  
✅ **Analyze survived mutations** — Understand test gaps  
✅ **Improve iteratively** — Fix a few weak tests per sprint  
✅ **Track trends** — Monitor mutation score over time

### Don'ts

❌ **Aim for 100%** — Diminishing returns above 80%  
❌ **Mutate everything** — Focus on critical paths first  
❌ **Ignore survived mutations** — They reveal real bugs  
❌ **Write mutations for mutations** — Test behavior, not metrics  
❌ **Block on first run** — Establish baseline gradually

---

## Mutation Score Interpretation

| Score | Interpretation | Action |
|-------|----------------|--------|
| 80%+ | Excellent tests | Maintain quality |
| 70-79% | Good tests | Address weak spots |
| 60-69% | Acceptable tests | Plan improvements |
| <60% | Poor tests | Significant work needed |

---

## Common Pitfalls

| Pitfall | Risk | Solution |
|---------|------|----------|
| **Over-testing** | Slow tests, maintenance burden | Test behavior, not implementation |
| **Weak assertions** | Mutations survive | Use exact assertions (\`toBe\` vs \`toBeDefined\`) |
| **Missing edge cases** | Boundary mutations survive | Test boundaries explicitly |
| **Flaky tests** | Mutation results unreliable | Fix flaky tests before mutation testing |
| **No baseline** | Can't track progress | Establish baseline first sprint |

---

## Mutation Testing Checklist

- [ ] Stryker installed and configured
- [ ] Baseline mutation score established
- [ ] CI/CD runs mutation tests
- [ ] Mutation score threshold set (70%+)
- [ ] Team trained on interpreting results
- [ ] Survived mutations analyzed weekly
- [ ] Test improvements tracked
- [ ] Critical code paths prioritized
- [ ] Mutation reports accessible
- [ ] Trends monitored (trending up?)

---

## Related Skills

- @test-coverage-analysis - Coverage metrics vs. mutation quality
- @doc-generation - Documentation clarifies edge cases for tests
- @regression-testing - Regression tests should have high mutation score
- @test-automation - Mutation tests run in CI/CD pipeline
`,
  "performance-profiling": `---
name: performance-profiling
description: CPU and memory profiling, Core Web Vitals optimization, bundle analysis, and performance budgets
---

# Performance Profiling

## Overview

Identify and eliminate performance bottlenecks using profiling tools, metrics, and systematic optimization. This skill covers both frontend (Core Web Vitals) and backend (CPU/memory) profiling.

**Use this skill when:**
- Investigating slow page loads
- Optimizing API response times
- Reducing memory consumption
- Analyzing bundle size
- Setting performance budgets

## Core Web Vitals (Frontend)

Google's metrics for user experience. These directly impact SEO.

### 1. Largest Contentful Paint (LCP)
- **What:** Time until largest visible element appears
- **Target:** <2.5 seconds
- **Causes:** Slow server response, large images, render-blocking JS

\`\`\`bash
# Measure in Chrome DevTools
# Performance tab → Metrics → Largest Contentful Paint
\`\`\`

**Optimization:**
- Preload critical resources: \`<link rel="preload" href="/image.jpg">\`
- Optimize images (WebP, lazy loading)
- Minimize CSS/JS blocking rendering
- Use CDN for content delivery

### 2. First Input Delay (FID) / Interaction to Next Paint (INP)
- **What:** Time browser responds to user interaction
- **Target:** <100ms (FID) or <200ms (INP)
- **Causes:** Heavy JavaScript, long tasks

\`\`\`javascript
// Measure FID
const observer = new PerformanceObserver((list) => {
  for (const entry of list.getEntries()) {
    console.log('FID:', entry.processingDuration);
  }
});
observer.observe({ entryTypes: ['first-input'] });
\`\`\`

**Optimization:**
- Break long tasks into chunks: \`await new Promise(r => setTimeout(r, 0))\`
- Defer non-critical JavaScript
- Use Web Workers for heavy computation
- Code splitting and lazy loading

### 3. Cumulative Layout Shift (CLS)
- **What:** Unexpected layout changes after page load
- **Target:** <0.1
- **Causes:** Unsized images, ads, late-loaded fonts

\`\`\`css
/* Reserve space for images */
img {
  width: 100%;
  height: auto;
  aspect-ratio: 16 / 9;
}
\`\`\`

**Optimization:**
- Set explicit dimensions for images/videos
- Avoid inserting content above existing content
- Use \`font-display: swap\` for custom fonts
- Reserve space for ads and iframes

## Backend Performance Profiling

### Node.js CPU Profiling

**Using Chrome DevTools:**
\`\`\`bash
# Start Node with inspector
node --inspect app.js

# Open in Chrome: chrome://inspect
# Profiler tab → Start recording → 30s later → Stop
\`\`\`

**Using clinic.js (recommended):**
\`\`\`bash
npm install -g clinic
clinic doctor -- node app.js
# Navigate app for 30s
# Generates detailed report
\`\`\`

**Reading CPU Profiles:**
- Call tree shows which functions consume CPU
- Flame graphs show call depth
- Time spent vs. time called

### Memory Profiling

**Heap Snapshots (Chrome DevTools):**
\`\`\`javascript
// Take snapshot at suspicious point
console.profile('Memory');
// ... do work ...
console.profileEnd('Memory');
\`\`\`

**Using clinic.js:**
\`\`\`bash
clinic bubbleprof -- node app.js
# Shows event loop delays and memory issues
\`\`\`

**Common Issues:**
- Memory leaks: Listeners not removed, circular references
- Unbounded caches: Grow without limit
- Large data structures: Keep unnecessary data

### Identifying Bottlenecks

\`\`\`javascript
// Simple performance measurement
const start = performance.now();
expensiveOperation();
const end = performance.now();
console.log(\`Operation took \${end - start}ms\`);

// More detailed timing
const perf = performance.getEntriesByType('measure');
perf.forEach(entry => {
  console.log(\`\${entry.name}: \${entry.duration.toFixed(2)}ms\`);
});
\`\`\`

## Bundle Analysis

### Identifying Large Bundles

\`\`\`bash
# Webpack Bundle Analyzer
npm install --save-dev webpack-bundle-analyzer

# In webpack.config.js
const BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin;
plugins: [new BundleAnalyzerPlugin()]

npm run build  # Generates report
\`\`\`

**What to look for:**
- Duplicate dependencies
- Unnecessary large libraries
- Code not tree-shaken
- Vendor libraries included multiple times

### Optimization Techniques

\`\`\`javascript
// 1. Code splitting by route
const Home = React.lazy(() => import('./pages/Home'));
const Admin = React.lazy(() => import('./pages/Admin'));

// 2. Dynamic imports for heavy libraries
const editor = await import('@monaco-editor/react');

// 3. Replace heavy libraries
// moment.js (67KB) → date-fns (13KB)
// lodash (70KB) → lodash-es (24KB with tree-shaking)

// 4. Compress images
// PNG → WebP (30-40% smaller)
// Use responsive images: srcset
\`\`\`

## Performance Budgets

Enforce performance limits in CI/CD:

\`\`\`json
{
  "bundles": [
    {
      "name": "main",
      "maxSize": "250 KB"
    },
    {
      "name": "vendor",
      "maxSize": "150 KB"
    }
  ],
  "metrics": [
    {
      "name": "LCP",
      "threshold": 2500  // milliseconds
    },
    {
      "name": "FID",
      "threshold": 100
    }
  ]
}
\`\`\`

## Profiling Workflow

### 1. Baseline Measurement
\`\`\`bash
# Measure before optimization
lighthouse https://example.com --output=json > baseline.json
\`\`\`

### 2. Profile & Identify Issues
\`\`\`bash
# Profile specific scenario
clinic doctor -- node app.js

# Record timeline in DevTools
# Check network tab for slow assets
\`\`\`

### 3. Apply Optimization
- Make one change at a time
- Document hypothesis
- Implement fix

### 4. Measure Again
\`\`\`bash
# Compare against baseline
lighthouse https://example.com --output=json > after.json
# Compare results
\`\`\`

### 5. Document
- What was slow?
- Why was it slow?
- How was it optimized?
- Impact metrics

## Tools & Services

| Tool | Purpose | Price |
|------|---------|-------|
| Chrome DevTools | CPU/memory profiling, timeline | Free |
| Lighthouse | Web vitals scoring | Free |
| WebPageTest | Detailed performance analysis | Free |
| clinic.js | Node profiling | Free |
| Datadog/New Relic | Production monitoring | Paid |
| Speedcurve | Performance tracking | Paid |
| Sentry | Error + performance monitoring | Free/Paid |

## Common Performance Anti-patterns

**❌ Anti-patterns:**
- Large synchronous loops in event handlers
- Memory leaks from unremoved listeners
- Synchronous operations in critical paths
- Loading all data upfront (no pagination)
- Not compressing images/assets

**✅ Best practices:**
- Async/await for I/O operations
- Cleanup listeners in useEffect dependencies
- Lazy load below-the-fold content
- Paginate or virtualize large lists
- Compress and optimize all assets

## Related Skills

- @frontend-nextjs - Implement performance optimizations
- @backend-convex - Profile backend queries
- @test-automation - Measure performance in tests
- @security-hardening - Optimize while maintaining security
`,
  "performance-testing": `---
name: performance-testing
description: Load testing, stress testing, spike testing, and performance metrics with k6 and Apache JMeter
---

# Performance Testing

## Overview

Validate system behavior under various load conditions using load testing, stress testing, and spike testing. This skill covers test planning, baseline establishment, and capacity planning.

**Use this skill when:**
- Testing application before production release
- Estimating system capacity
- Identifying performance bottlenecks
- Planning for scaling
- Verifying performance improvements

## Performance Testing Types

### 1. Load Testing
- **Definition:** Simulate expected load (normal usage)
- **Goal:** Verify system meets performance requirements
- **Example:** 100 users over 5 minutes
- **Metrics to watch:**
  - Response time (p50, p95, p99)
  - Throughput (requests/second)
  - Error rate
  - Resource utilization (CPU, memory)

### 2. Stress Testing
- **Definition:** Increase load until system fails
- **Goal:** Find breaking point and behavior under stress
- **Example:** Gradually increase users to 10,000+
- **Key question:** What happens when limits are exceeded?

### 3. Spike Testing
- **Definition:** Sudden increase in load
- **Goal:** Verify system can handle traffic spikes
- **Example:** 100 → 5,000 users instantly
- **Watch for:** Cascading failures, stuck processes

### 4. Soak Testing
- **Definition:** Run normal load for extended period
- **Goal:** Find memory leaks and degradation over time
- **Duration:** 24-48 hours
- **Watch for:** Gradual slowdown, memory creep

## Load Testing with k6

**Installation:**
\`\`\`bash
npm install --save-dev k6
\`\`\`

**Basic Load Test:**
\`\`\`javascript
// load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 100 },   // Ramp up to 100 users
    { duration: '5m', target: 100 },   // Stay at 100 users
    { duration: '2m', target: 0 },     // Ramp down to 0
  ],
  thresholds: {
    http_req_duration: ['p(95)<500', 'p(99)<1000'],  // 95% under 500ms
    http_req_failed: ['rate<0.1'],                    // <10% errors
  },
};

export default function () {
  const res = http.get('https://api.example.com/users');
  
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
    'has user data': (r) => r.body.includes('id'),
  });
  
  sleep(1);
}
\`\`\`

**Run Test:**
\`\`\`bash
k6 run load-test.js
\`\`\`

**Advanced: Multiple Endpoints**
\`\`\`javascript
export const options = {
  stages: [
    { duration: '1m', target: 50 },
    { duration: '5m', target: 100 },
    { duration: '2m', target: 0 },
  ],
};

export default function () {
  // Simulate user workflow
  const loginRes = http.post('https://api.example.com/login', {
    email: 'test@example.com',
    password: 'password123',
  });
  
  const token = loginRes.json('token');
  
  const headers = { 'Authorization': \`Bearer \${token}\` };
  
  http.get('https://api.example.com/dashboard', { headers });
  http.get('https://api.example.com/analytics', { headers });
  http.post('https://api.example.com/export', {}, { headers });
  
  sleep(1);
}
\`\`\`

## Load Testing with Apache JMeter

**Test Plan Structure:**
\`\`\`
Test Plan
├─ Thread Group (100 users, 5 min)
│  ├─ HTTP Request (GET /api/users)
│  ├─ HTTP Request (GET /api/users/1)
│  └─ Assertions (response time < 500ms)
├─ Listeners
│  ├─ View Results Tree
│  └─ Aggregate Report
\`\`\`

**Aggregate Report Example:**
\`\`\`
Label          Samples  Average  Min    Max   Std.Dev  Error%  Throughput
GET /api/users 1000     245ms    50ms   800ms 120ms    0.2%    3.3/sec
All            1000     245ms    50ms   800ms 120ms    0.2%    3.3/sec
\`\`\`

## Performance Metrics

### Key Metrics

| Metric | Target | Warning | Critical |
|--------|--------|---------|----------|
| Response Time (p95) | <500ms | <1000ms | >1000ms |
| Response Time (p99) | <1000ms | <2000ms | >2000ms |
| Error Rate | <0.1% | <1% | >1% |
| Throughput | Meets SLA | 10% below | >20% below |
| CPU Usage | <70% | <85% | >90% |
| Memory Usage | <70% | <85% | >90% |

### How to Read Results

\`\`\`
Starting 100 users...
0s   - Request initiated
100s - 100 users ramped up
    p50 (median): 245ms
    p95: 485ms (95% of requests < 485ms)
    p99: 950ms (99% of requests < 950ms)
500s - System under sustained load
    Still healthy? Memory stable? CPU normal?
600s - Begin ramp down
\`\`\`

## Identifying Bottlenecks

**When Response Time Increases:**

1. **Database Queries**
   \`\`\`sql
   -- Slow query analysis
   EXPLAIN ANALYZE SELECT * FROM users WHERE status = 'active';
   -- Add indexes if needed
   CREATE INDEX idx_users_status ON users(status);
   \`\`\`

2. **CPU Bottleneck**
   - Large computations
   - Inefficient algorithms
   - Too much logging

3. **Memory Issues**
   - Memory leaks (heap growing)
   - Large data structures
   - Cache unbounded growth

4. **I/O Wait**
   - Disk reads/writes
   - Network latency
   - Database locks

## Capacity Planning

**From Load Test Results:**

\`\`\`
Average user takes 1KB of memory
Max users = 8GB RAM / 1KB per user = 8,000,000 users

Average request takes 10ms
Database can handle 100 queries/sec = 10,000 requests/sec
= 100 concurrent users at 100req/user-session

Multiply by safety factor (2-3x):
Capacity = 200-300 concurrent users
\`\`\`

## Pre-Release Testing Checklist

- [ ] Baseline test established (normal load)
- [ ] Sustained load test (5+ min) successful
- [ ] Spike test (sudden traffic burst) successful
- [ ] Soak test (long duration) shows no memory leaks
- [ ] Database connections not exhausted
- [ ] Cache hit rates acceptable (>90%)
- [ ] Error rate below SLA (<0.1%)
- [ ] All response time percentiles met
- [ ] Resource utilization reasonable (CPU <70%, RAM <70%)
- [ ] Capacity plan documented
- [ ] Scaling strategy defined

## Common Issues & Solutions

| Issue | Cause | Solution |
|-------|-------|----------|
| High response time | Slow DB queries | Add indexes, optimize queries |
| Memory grows unbounded | Memory leak | Find unclosed connections/listeners |
| CPU spikes under load | Inefficient algorithm | Profile and refactor code |
| Connection pool exhausted | Too many simultaneous requests | Increase pool size or optimize |
| Cache misses | Poor cache strategy | Review cache keys and TTL |
| Timeouts | Downstream service slow | Optimize dependencies or increase timeout |

## Related Skills

- @test-automation - Automate performance tests in CI
- @backend-convex - Optimize database queries
- @frontend-nextjs - Profile frontend performance
- @metrics-reporting - Track performance over time
`,
  "plan-feature": `---
name: plan-feature
description: Setup & Plan a Feature (Cursor Plan Mode)
disable-model-invocation: true
---

# Setup & Plan a Feature (Cursor Plan Mode)

## Overview

Systematically set up a new feature from initial planning through to a detailed implementation plan. You are in **planning mode**: do not write or change any code, only plan. Do not paste full implementations; only short code snippets or signatures if absolutely needed to clarify the plan.

The plan must be detailed enough that:

- If we give it to **100 different engineers**, at least **85%** of the resulting code would be very similar.
- A **junior engineer** can implement the feature by following the plan step by step.
- Running command .cursor/commands/code-review-checklist.md agains the plan you gonna write should not return any issues or warnings.

---

## Phase 0: Setup (before writing the plan)

1. **Define requirements**
   - Clarify feature scope and goals with the user (or from the description below).
   - Identify user stories and acceptance criteria.
   - Note any technical approach constraints.

2. **Scope the repo**
   - Identify which **apps/packages** in this repo are affected (e.g. \`apps/web\`, \`packages/backend\`, \`packages/ui\`).
   - Note any **key assumptions** and mark them clearly (e.g. "Assumption A: …") so they can be confirmed later.

3. **Feature setup checklist** (confirm before proceeding)
   - [ ] Requirements / scope documented
   - [ ] User stories or acceptance criteria clear
   - [ ] Feature branch created (if applicable)
   - [ ] Development environment ready

---

## Phase 1: Understand the task

- Read the user's description below this command carefully.
- Skim the relevant files in this repo:
  - Routes / pages
  - Components
  - Hooks / state management
  - API handlers / services (e.g. Convex queries, mutations, actions)
  - Schemas / models / types
  - Config files and environment usage
  - Existing tests related to this area
- Use **project-wide search** and **symbol navigation** to understand how similar features are implemented today.
- Before asking the user anything, **thoroughly analyze the codebase and existing documentation** to try to answer your own questions:
  - Reuse existing patterns, utilities, hooks, and types whenever possible.
  - Only ask clarifying questions that you **cannot reasonably resolve yourself** after checking the codebase and docs.
- If anything is still unclear after that, ask up to **5 short clarifying questions** before writing the final plan.

---

## Phase 2: Write a Markdown plan with these sections

### 1. Context & goal

- One short paragraph on what we are building and why.
- Key constraints (tech stack, performance, security, backwards compatibility, UX).

### 2. Codebase research summary

- List the **main files and modules you inspected**, with paths (e.g. \`apps/web/src/app/(dashboard)/[accountSlug]/tasks/page.tsx\`).
- Briefly summarize what you learned:
  - Existing patterns you will follow.
  - Existing APIs, components, hooks, or utilities to reuse.
  - Any important types or schemas that matter for this feature.

### 3. High-level design

- Architecture summary across layers (frontend, backend, shared libraries).
- Main data flows and where they start/end (e.g. "User action → React component → hook → Convex mutation → DB → response → UI update").
- Mention important existing functions, components, hooks, and types by their **exact names** where relevant.
- Explain how the new feature fits into the existing architecture.

### 4. File & module changes

- List **existing files to touch** with their paths.
- List **new files to create** with their paths.
- For each file, write 1–3 bullets on what will change, with enough detail that another engineer can implement it without guessing, e.g.:
  - New props, fields, or params (with types).
  - New API endpoints or Convex functions (method/name, input/output shape).
  - New state, hooks, or context usage.
  - New utility functions or modules.

### 5. Step-by-step tasks

- Write a **numbered list** of small, atomic steps.
- Each step should be "doable in one focused commit".
- Steps must mention concrete files, functions, and components to edit or create.
- Include any required:
  - Migrations
  - Feature flags
  - Configuration or environment variable changes
- Make the steps explicit enough that a **junior engineer** can follow them one by one without making design decisions on their own.

### 6. Edge cases & risks

- Edge cases to handle (validation, empty states, error handling, race conditions, permissions, auth, rate limits, etc.).
- Potential breaking changes or risky areas in the codebase:
  - Explain why they are risky.
  - Suggest mitigation (feature flags, extra tests, monitoring, fallbacks).

### 7. Testing strategy

- What to cover with **unit tests**: modules, pure logic, input validation, branching logic.
- What to cover with **integration/e2e tests**: critical flows, API + UI integration, cross-service behavior.
- Manual QA checklist: happy path and key edge cases as bullet points (e.g. "Create X…", "Update Y…", "Error when Z…").

### 8. Rollout / migration (if relevant)

- How to deploy safely: feature flags, gradual rollout, kill switch, monitoring dashboards.
- How to migrate existing data or users: one-off scripts, background jobs, or lazy migration.
- Any observability or logging changes: new logs, metrics, or traces to add.

### 9. TODO checklist

- At the end of the plan, create a **detailed TODO list** using Markdown checkboxes (\`- [ ]\`).
- This TODO list should contain **all concrete steps** needed to complete the implementation, from first code change to final deployment and QA.
- Group TODOs when useful, e.g. **Backend**, **Frontend**, **Tests**, **Infra / DevOps**.
- Each TODO item should be clear, small, and directly actionable.

---

## Phase 3: Output rules

- Use clean Markdown headings and bullet points.
- Keep sentences short and concrete.
- Avoid vague statements like "update things as needed"; always be specific about **what**, **where**, and **how**.
- Stay in planning mode only; do not modify code or open pull requests in this step.
`,
  "pr-review-comments": `---
name: pr-review-comments
description: PR Review Comments
disable-model-invocation: true
---

# PR Review Comments

## Goal

Generate **copy/paste-ready pull request review comments** for the current branch, with clear severity and precise code
anchors so the comments can be posted directly on GitHub.

## Inputs

- Prefer the **current git branch** diff against \`origin/dev\` unless the user provides a PR base branch.
- If the user provides **manual testing notes / logs**, incorporate them as additional comments and map them to likely
  code locations.

## What to do

1. **Collect context**
   - Determine current branch name and whether the working tree is clean.
   - Identify base branch (default to \`origin/dev\`) and list changed files (\`git diff --name-status\`).
   - Skim the highest-impact files (routes, server actions, validation, shared components).
2. **Find reviewable risks**
   - Security/authZ/authN gaps (server-side enforcement vs UI-only gating).
   - Data mapping correctness (form → API, API → UI, empty/null semantics).
   - Error handling and user-facing messaging (including i18n).
   - Type safety pitfalls (\`any\`, mismatched return shapes).
   - UX issues noted in testing (multi-select, multi-value inputs, loading states, navigation).
   - Performance/regression risks (unnecessary re-renders, sequential server calls).
3. **Produce PR review comments**
   - Output **multiple separate comments** (not one blob), each scoped to one issue.
   - For each comment, include **exact anchor(s)** so the reviewer can place it accurately in the diff.

## Output format (strict)

Return a list of comments using this format exactly:

- **[Blocking|Non-blocking] <Short title>**
  - **Where**: \`<path>\` → \`<function/component/section>\`
  - **Comment to paste**:
    > <The exact PR comment text as you'd write it on GitHub.>
  - **Why**: <One sentence, user impact or maintenance risk.>
  - **Suggested fix**: <One sentence, specific action.>

## Constraints

- Write in **English**.
- Prefer the repository's conventions and existing utilities.
- Do **not** propose large refactors unless necessary; prioritize high-signal, actionable comments.
- If something is unclear, ask targeted clarifying questions instead of guessing.
`,
  "pr-review": `---
name: requesting-code-review
description: Use when completing tasks, implementing major features, or before merging to verify work meets requirements
---

# Requesting Code Review

Dispatch superpowers:code-reviewer subagent to catch issues before they cascade.

**Core principle:** Review early, review often.

## When to Request Review

**Mandatory:**
- After each task in subagent-driven development
- After completing major feature
- Before merge to dev

**Optional but valuable:**
- When stuck (fresh perspective)
- Before refactoring (baseline check)
- After fixing complex bug

## How to Request

**1. Get git SHAs:**
\`\`\`bash
BASE_SHA=\$(git rev-parse HEAD~1)  # or origin/dev
HEAD_SHA=\$(git rev-parse HEAD)
\`\`\`

**2. Dispatch code-reviewer subagent:**

Use Task tool with superpowers:code-reviewer type, fill template at \`code-reviewer.md\`

**Placeholders:**
- \`{WHAT_WAS_IMPLEMENTED}\` - What you just built
- \`{PLAN_OR_REQUIREMENTS}\` - What it should do
- \`{BASE_SHA}\` - Starting commit
- \`{HEAD_SHA}\` - Ending commit
- \`{DESCRIPTION}\` - Brief summary

**3. Act on feedback:**
- Fix Critical issues immediately
- Fix Important issues before proceeding
- Note Minor issues for later
- Push back if reviewer is wrong (with reasoning)

## Example

\`\`\`
[Just completed Task 2: Add verification function]

You: Let me request code review before proceeding.

BASE_SHA=\$(git log --oneline | grep "Task 1" | head -1 | awk '{print \$1}')
HEAD_SHA=\$(git rev-parse HEAD)

[Dispatch superpowers:code-reviewer subagent]
  WHAT_WAS_IMPLEMENTED: Verification and repair functions for conversation index
  PLAN_OR_REQUIREMENTS: Task 2 from docs/plans/deployment-plan.md
  BASE_SHA: a7981ec
  HEAD_SHA: 3df7661
  DESCRIPTION: Added verifyIndex() and repairIndex() with 4 issue types

[Subagent returns]:
  Strengths: Clean architecture, real tests
  Issues:
    Important: Missing progress indicators
    Minor: Magic number (100) for reporting interval
  Assessment: Ready to proceed

You: [Fix progress indicators]
[Continue to Task 3]
\`\`\`

## Integration with Workflows

**Subagent-Driven Development:**
- Review after EACH task
- Catch issues before they compound
- Fix before moving to next task

**Executing Plans:**
- Review after each batch (3 tasks)
- Get feedback, apply, continue

**Ad-Hoc Development:**
- Review before merge
- Review when stuck

## Red Flags

**Never:**
- Skip review because "it's simple"
- Ignore Critical issues
- Proceed with unfixed Important issues
- Argue with valid technical feedback

**If reviewer wrong:**
- Push back with technical reasoning
- Show code/tests that prove it works
- Request clarification

See template at: requesting-code-review/code-reviewer.md
`,
  "production-ready-refactor": `---
name: production-ready-refactor
description: Production-Ready Refactor
disable-model-invocation: true
---

# Production-Ready Refactor

You are refactoring an existing implementation to production-ready quality.

Follow this workflow:

## 1) Understand the current behavior

- Read the relevant code paths end-to-end.
- Identify integration points, config, and tests that touch this area.
- Summarize intended behavior and any gaps/risks.

## 2) Reuse before creating

- Search for existing utilities, hooks, types, and patterns in the codebase.
- Extend existing code where possible; avoid new files unless necessary.
- Keep imports at the top of the file.
- Follow DRY and KISS: remove duplication, keep functions focused and small.

## 3) Refactor to match project standards

- Match existing file organization, naming conventions, and style.
- Use \`@\` imports, established helpers, and shared types.
- Add JSDoc for exported functions/components/hooks.
- Add comments only when they explain non-obvious intent or constraints.

## 4) Production readiness checks

- Handle edge cases and error paths explicitly.
- Validate configuration/environment usage and update \`.env.example\` + \`Env\` when needed.
- Ensure logging and error messages are actionable.
- Avoid breaking public URLs or APIs; add redirects/rewrites if required.

## 5) Tests & verification

- Add or update tests for critical logic and regressions.
- Run \`pnpm tsc --noEmit\` and \`pnpm lint\`.
- Run \`pnpm build\` if the change impacts build-time behavior.

## 6) Final response

- Provide a concise change summary.
- List tests run and their results.
- Call out any remaining risks, manual QA steps, or follow-ups.
`,
  "regression-testing": `---
name: regression-testing
description: Automated regression test suites, snapshot testing, baseline comparisons, and CI/CD integration for preventing regressions
---

# Regression Testing

## Overview

Detect unintended changes in existing functionality through automated regression testing. This skill covers test automation strategies, snapshot testing, baseline comparisons, and CI/CD integration to catch regressions before production.

**Use this skill when:**
- Adding new features to prevent breaking existing behavior
- Refactoring code with confidence
- Testing UI changes (visual regressions)
- Verifying API responses remain unchanged
- Preventing performance regressions

**Cross-functional pairing:** @engineer **logging-observability** — Observability data helps validate test behavior and catch production regressions across deployments

---

## Regression Testing Strategies

### Strategy 1: Snapshot Testing

**What it does:** Captures expected output and detects changes

\`\`\`typescript
// Example: UI component snapshot
import { render } from '@testing-library/react';
import { UserCard } from './UserCard';

test('user card renders correctly', () => {
  const { container } = render(
    <UserCard user={{ name: 'John', email: 'john@example.com' }} />
  );
  
  expect(container.firstChild).toMatchSnapshot();
});

// Generated snapshot (stored in __snapshots__/UserCard.test.ts.snap):
/*
exports[\`user card renders correctly 1\`] = \`
<div>
  <h2>John</h2>
  <p>john@example.com</p>
</div>
\`;
*/
\`\`\`

### Strategy 2: API Response Baseline Testing

\`\`\`typescript
// Capture API response and detect changes
import { apiClient } from './api';

test('GET /users/123 returns expected schema', async () => {
  const response = await apiClient.get('/users/123');
  
  expect(response).toMatchSnapshot();
});

// Expected baseline:
/*
{
  id: '123',
  name: 'John Doe',
  email: 'john@example.com',
  createdAt: '2026-01-01T00:00:00Z',
  role: 'member'
}
*/
\`\`\`

### Strategy 3: Regression Suite (Comprehensive)

\`\`\`typescript
// Automated test suite to prevent regressions
describe('User Management Regression Suite', () => {
  test('create user creates with correct defaults', async () => {
    const user = await createUser({ name: 'Jane' });
    
    expect(user).toEqual({
      name: 'Jane',
      email: expect.any(String),
      createdAt: expect.any(Date),
      role: 'member',  // Default role
    });
  });

  test('update user preserves immutable fields', async () => {
    const user = await createUser({ name: 'Jane' });
    const original = { ...user };
    
    await updateUser(user.id, { name: 'Janet' });
    const updated = await getUser(user.id);
    
    expect(updated.createdAt).toEqual(original.createdAt);
    expect(updated.id).toEqual(original.id);
  });

  test('delete user removes from database', async () => {
    const user = await createUser({ name: 'Jane' });
    await deleteUser(user.id);
    
    const retrieved = await getUser(user.id);
    expect(retrieved).toBeNull();
  });
});
\`\`\`

---

## Snapshot Testing Best Practices

### When to Use Snapshots

✅ **Good for:**
- UI components (structure, styling)
- API responses (structure, fields)
- Error messages
- Generated output

❌ **Avoid for:**
- Dynamic data (timestamps, IDs)
- Performance metrics
- Flaky assertions

### Handling Dynamic Data

\`\`\`typescript
// ❌ Bad: Snapshots fail due to timestamp
test('user created with timestamp', () => {
  const user = createUser('John');
  expect(user).toMatchSnapshot();
  // Fails every time due to createdAt
});

// ✅ Good: Use property matchers
test('user created with timestamp', () => {
  const user = createUser('John');
  expect(user).toMatchSnapshot({
    createdAt: expect.any(String),
    id: expect.any(String),
  });
});
\`\`\`

### Updating Snapshots

\`\`\`bash
# Run tests with snapshot update flag
npm test -- -u

# Be careful: Review changes before committing
git diff __snapshots__/

# Good practice: Update one at a time
npm test -- -u UserCard.test.ts
\`\`\`

---

## Baseline Comparison Testing

### Establishing Baselines

\`\`\`typescript
// Baseline: Expected performance/behavior
const performanceBaseline = {
  responseTime: 200,      // ms
  memoryUsage: 50,        // MB
  errorRate: 0.001,       // 0.1%
};

test('API performance within baseline', async () => {
  const start = performance.now();
  const response = await apiClient.get('/users');
  const duration = performance.now() - start;
  
  expect(duration).toBeLessThan(performanceBaseline.responseTime);
  expect(response.statusCode).toBe(200);
});
\`\`\`

### Detecting Regressions

\`\`\`typescript
// Compare current metrics to baseline
test('memory usage not regressed', () => {
  const before = process.memoryUsage().heapUsed / 1024 / 1024;
  
  // Run operation
  processLargeDataset();
  
  const after = process.memoryUsage().heapUsed / 1024 / 1024;
  const increase = after - before;
  
  // Flag regression if memory usage increased significantly
  expect(increase).toBeLessThan(performanceBaseline.memoryUsage * 1.2);
});
\`\`\`

---

## Visual Regression Testing

### Screenshot Comparison

\`\`\`typescript
import { test, expect } from '@playwright/test';

test('button styling unchanged', async ({ page }) => {
  await page.goto('http://localhost:3000/button');
  
  const button = page.locator('button');
  
  // Capture and compare screenshot
  await expect(button).toHaveScreenshot('button.png');
});

// On failure, generates diff:
// ✗ button styling unchanged
//   Expected: button.png
//   Actual:   button.png (different)
//   Diff:     button.png.diff
\`\`\`

### Handling Dynamic Changes

\`\`\`typescript
// Ignore dynamic areas in screenshots
await expect(button).toHaveScreenshot({
  maxDiffPixels: 10,  // Allow small variations
  mask: [
    page.locator('.timestamp'),  // Ignore timestamp
    page.locator('.id'),          // Ignore ID
  ],
});
\`\`\`

---

## CI/CD Integration

### GitHub Actions: Automated Regression Testing

\`\`\`yaml
# .github/workflows/regression-tests.yml
name: Regression Tests

on:
  pull_request:
  push:
    branches: [master, develop]

jobs:
  regression:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '22'
      
      - run: npm ci
      - run: npm run test:regression
      
      - name: Upload test results
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: regression-results
          path: ./test-results/
      
      - name: Comment on PR with results
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('./test-results/summary.json', 'utf8'));
            
            const comment = \`
            ## Regression Test Results
            - Passed: \${results.passed}
            - Failed: \${results.failed}
            - Skipped: \${results.skipped}
            \`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
\`\`\`

### Turbo Cache for Regression Tests

\`\`\`json
{
  "pipeline": {
    "test:regression": {
      "outputs": ["coverage/**", "test-results/**"],
      "cache": true,
      "dependsOn": ["^build"]
    }
  }
}
\`\`\`

---

## Snapshot Management

### Organizing Snapshots

\`\`\`
src/
├── components/
│   ├── Button.tsx
│   ├── Button.test.ts
│   └── __snapshots__/
│       └── Button.test.ts.snap
└── utils/
    ├── format.ts
    ├── format.test.ts
    └── __snapshots__/
        └── format.test.ts.snap
\`\`\`

### Reviewing Snapshot Changes

\`\`\`bash
# Before committing snapshots:
git diff __snapshots__/

# Example output:
# - <h2>John Doe</h2>
# + <h2>Jane Doe</h2>

# Verify intentional changes
git add __snapshots__/
\`\`\`

---

## Regression Testing Checklist

- [ ] Regression test suite defined for core flows
- [ ] Snapshots captured for UI/API responses
- [ ] Baseline metrics established (performance, memory)
- [ ] CI/CD automatically runs regression tests
- [ ] Developers trained on snapshot updates
- [ ] Screenshot tests for visual regressions (optional)
- [ ] Test results reported in PR comments
- [ ] Flaky tests identified and fixed
- [ ] Coverage maintained for regression tests
- [ ] Monthly review of regression metrics

---

## Common Pitfalls

| Pitfall | Risk | Solution |
|---------|------|----------|
| **Updating snapshots blindly** | Missing regressions | Review diffs carefully |
| **Too many snapshots** | Maintenance burden | Test behavior, not snapshots |
| **Ignoring flaky tests** | False confidence | Fix or skip unstable tests |
| **No CI integration** | Regressions reach prod | Automate in GitHub Actions |
| **Outdated baselines** | Detecting wrong regressions | Update baselines quarterly |

---

## Related Skills

- @test-coverage-analysis - Measure coverage in regression tests
- @mutation-testing - Validate regression tests catch actual bugs
- @contract-testing-openapi - Regression testing for API contracts
- @test-automation - CI/CD integration for regression suites
`,
  "release-management": `---
name: release-management
description: Release checklists, changelogs, and versioning. Align with the squad lead and any existing release process.
---

# Release management

Use this skill for release checklists, changelogs, and versioning. Align with the squad lead and any existing release process.

## When to use

- Preparing or executing a release (app, package, or runtime).
- Writing or updating changelogs and release notes.
- Deciding version bumps (semver: major/minor/patch) and release cadence.
- Coordinating with the squad lead on timing, scope, and rollback.

## Release checklist (outline)

1. **Pre-release**
   - Confirm all release-blocking work is done (tests, docs, migrations if any).
   - Update version in the right place(s) (e.g. \`package.json\`, app config).
   - Draft or update changelog/release notes for the version.
   - Get squad lead sign-off if required.

2. **Cut release**
   - Tag or cut the release (e.g. Git tag, GitHub release, package publish).
   - Document the exact artifact or commit for the release.

3. **Post-release**
   - Announce or notify as per process.
   - Update any “latest” or “current” references.
   - Note any follow-ups (patches, docs, rollback steps).

## Changelog and versioning

- Prefer a single source of truth (e.g. \`CHANGELOG.md\` or GitHub Releases) with a consistent format (e.g. “Added / Changed / Fixed” or keep-a-changelog).
- Use semantic versioning (semver) unless the project specifies otherwise: major for breaking changes, minor for new features, patch for fixes.
- Tie each changelog entry to a version and date; link to commits or PRs where helpful.

## Collaboration

- Align with the squad lead on what counts as release-blocking and who approves releases.
- Reuse existing templates or runbooks if the project has them; otherwise propose a minimal checklist and iterate.
`,
  "repo-architecture": `---
name: c4-architecture
description: Generate architecture documentation using C4 model Mermaid diagrams. Use when asked to create architecture diagrams, document system architecture, visualize software structure, create C4 diagrams, or generate context/container/component/deployment diagrams. Triggers include "architecture diagram", "C4 diagram", "system context", "container diagram", "component diagram", "deployment diagram", "document architecture", "visualize architecture".
---

# C4 Architecture Documentation

Generate software architecture documentation using C4 model diagrams in Mermaid syntax.

## Workflow

1. **Understand scope** - Determine which C4 level(s) are needed based on audience
2. **Analyze codebase** - Explore the system to identify components, containers, and relationships
3. **Generate diagrams** - Create Mermaid C4 diagrams at appropriate abstraction levels
4. **Document** - Write diagrams to markdown files with explanatory context

## C4 Diagram Levels

Select the appropriate level based on the documentation need:

| Level | Diagram Type | Audience | Shows | When to Create |
|-------|-------------|----------|-------|----------------|
| 1 | **C4Context** | Everyone | System + external actors | Always (required) |
| 2 | **C4Container** | Technical | Apps, databases, services | Always (required) |
| 3 | **C4Component** | Developers | Internal components | Only if adds value |
| 4 | **C4Deployment** | DevOps | Infrastructure nodes | For production systems |
| - | **C4Dynamic** | Technical | Request flows (numbered) | For complex workflows |

**Key Insight:** "Context + Container diagrams are sufficient for most software development teams." Only create Component/Code diagrams when they genuinely add value.

## Quick Start Examples

### System Context (Level 1)
\`\`\`mermaid
C4Context
  title System Context - Workout Tracker

  Person(user, "User", "Tracks workouts and exercises")
  System(app, "Workout Tracker", "Vue PWA for tracking strength and CrossFit workouts")
  System_Ext(browser, "Web Browser", "Stores data in IndexedDB")

  Rel(user, app, "Uses")
  Rel(app, browser, "Persists data to", "IndexedDB")
\`\`\`

### Container Diagram (Level 2)
\`\`\`mermaid
C4Container
  title Container Diagram - Workout Tracker

  Person(user, "User", "Tracks workouts")

  Container_Boundary(app, "Workout Tracker PWA") {
    Container(spa, "SPA", "Vue 3, TypeScript", "Single-page application")
    Container(pinia, "State Management", "Pinia", "Manages application state")
    ContainerDb(indexeddb, "IndexedDB", "Dexie", "Local workout storage")
  }

  Rel(user, spa, "Uses")
  Rel(spa, pinia, "Reads/writes state")
  Rel(pinia, indexeddb, "Persists", "Dexie ORM")
\`\`\`

### Component Diagram (Level 3)
\`\`\`mermaid
C4Component
  title Component Diagram - Workout Feature

  Container(views, "Views", "Vue Router pages")

  Container_Boundary(workout, "Workout Feature") {
    Component(useWorkout, "useWorkout", "Composable", "Workout execution state")
    Component(useTimer, "useTimer", "Composable", "Timer state machine")
    Component(workoutRepo, "WorkoutRepository", "Dexie", "Workout persistence")
  }

  Rel(views, useWorkout, "Uses")
  Rel(useWorkout, useTimer, "Controls")
  Rel(useWorkout, workoutRepo, "Saves to")
\`\`\`

### Dynamic Diagram (Request Flow)
\`\`\`mermaid
C4Dynamic
  title Dynamic Diagram - User Sign In Flow

  ContainerDb(db, "Database", "PostgreSQL", "User credentials")
  Container(spa, "Single-Page App", "React", "Banking UI")

  Container_Boundary(api, "API Application") {
    Component(signIn, "Sign In Controller", "Express", "Auth endpoint")
    Component(security, "Security Service", "JWT", "Validates credentials")
  }

  Rel(spa, signIn, "1. Submit credentials", "JSON/HTTPS")
  Rel(signIn, security, "2. Validate")
  Rel(security, db, "3. Query user", "SQL")

  UpdateRelStyle(spa, signIn, \$textColor="blue", \$offsetY="-30")
\`\`\`

### Deployment Diagram
\`\`\`mermaid
C4Deployment
  title Deployment Diagram - Production

  Deployment_Node(browser, "Customer Browser", "Chrome/Firefox") {
    Container(spa, "SPA", "React", "Web application")
  }

  Deployment_Node(aws, "AWS Cloud", "us-east-1") {
    Deployment_Node(ecs, "ECS Cluster", "Fargate") {
      Container(api, "API Service", "Node.js", "REST API")
    }
    Deployment_Node(rds, "RDS", "db.r5.large") {
      ContainerDb(db, "Database", "PostgreSQL", "Application data")
    }
  }

  Rel(spa, api, "API calls", "HTTPS")
  Rel(api, db, "Reads/writes", "JDBC")
\`\`\`

## Element Syntax

### People and Systems
\`\`\`
Person(alias, "Label", "Description")
Person_Ext(alias, "Label", "Description")       # External person
System(alias, "Label", "Description")
System_Ext(alias, "Label", "Description")       # External system
SystemDb(alias, "Label", "Description")         # Database system
SystemQueue(alias, "Label", "Description")      # Queue system
\`\`\`

### Containers
\`\`\`
Container(alias, "Label", "Technology", "Description")
Container_Ext(alias, "Label", "Technology", "Description")
ContainerDb(alias, "Label", "Technology", "Description")
ContainerQueue(alias, "Label", "Technology", "Description")
\`\`\`

### Components
\`\`\`
Component(alias, "Label", "Technology", "Description")
Component_Ext(alias, "Label", "Technology", "Description")
ComponentDb(alias, "Label", "Technology", "Description")
\`\`\`

### Boundaries
\`\`\`
Enterprise_Boundary(alias, "Label") { ... }
System_Boundary(alias, "Label") { ... }
Container_Boundary(alias, "Label") { ... }
Boundary(alias, "Label", "type") { ... }
\`\`\`

### Relationships
\`\`\`
Rel(from, to, "Label")
Rel(from, to, "Label", "Technology")
BiRel(from, to, "Label")                        # Bidirectional
Rel_U(from, to, "Label")                        # Upward
Rel_D(from, to, "Label")                        # Downward
Rel_L(from, to, "Label")                        # Leftward
Rel_R(from, to, "Label")                        # Rightward
\`\`\`

### Deployment Nodes
\`\`\`
Deployment_Node(alias, "Label", "Type", "Description") { ... }
Node(alias, "Label", "Type", "Description") { ... }  # Shorthand
\`\`\`

## Styling and Layout

### Layout Configuration
\`\`\`
UpdateLayoutConfig(\$c4ShapeInRow="3", \$c4BoundaryInRow="1")
\`\`\`
- \`\$c4ShapeInRow\` - Number of shapes per row (default: 4)
- \`\$c4BoundaryInRow\` - Number of boundaries per row (default: 2)

### Element Styling
\`\`\`
UpdateElementStyle(alias, \$fontColor="red", \$bgColor="grey", \$borderColor="red")
\`\`\`

### Relationship Styling
\`\`\`
UpdateRelStyle(from, to, \$textColor="blue", \$lineColor="blue", \$offsetX="5", \$offsetY="-10")
\`\`\`
Use \`\$offsetX\` and \`\$offsetY\` to fix overlapping relationship labels.

## Best Practices

### Essential Rules

1. **Every element must have**: Name, Type, Technology (where applicable), and Description
2. **Use unidirectional arrows only** - Bidirectional arrows create ambiguity
3. **Label arrows with action verbs** - "Sends email using", "Reads from", not just "uses"
4. **Include technology labels** - "JSON/HTTPS", "JDBC", "gRPC"
5. **Stay under 20 elements per diagram** - Split complex systems into multiple diagrams

### Clarity Guidelines

1. **Start at Level 1** - Context diagrams help frame the system scope
2. **One diagram per file** - Keep diagrams focused on a single abstraction level
3. **Meaningful aliases** - Use descriptive aliases (e.g., \`orderService\` not \`s1\`)
4. **Concise descriptions** - Keep descriptions under 50 characters when possible
5. **Always include a title** - "System Context diagram for [System Name]"

### What to Avoid

See [references/common-mistakes.md](references/common-mistakes.md) for detailed anti-patterns:
- Confusing containers (deployable) vs components (non-deployable)
- Modeling shared libraries as containers
- Showing message brokers as single containers instead of individual topics
- Adding undefined abstraction levels like "subcomponents"
- Removing type labels to "simplify" diagrams

## Microservices Guidelines

### Single Team Ownership
Model each microservice as a **container** (or container group):
\`\`\`mermaid
C4Container
  title Microservices - Single Team

  System_Boundary(platform, "E-commerce Platform") {
    Container(orderApi, "Order Service", "Spring Boot", "Order processing")
    ContainerDb(orderDb, "Order DB", "PostgreSQL", "Order data")
    Container(inventoryApi, "Inventory Service", "Node.js", "Stock management")
    ContainerDb(inventoryDb, "Inventory DB", "MongoDB", "Stock data")
  }
\`\`\`

### Multi-Team Ownership
Promote microservices to **software systems** when owned by separate teams:
\`\`\`mermaid
C4Context
  title Microservices - Multi-Team

  Person(customer, "Customer", "Places orders")
  System(orderSystem, "Order System", "Team Alpha")
  System(inventorySystem, "Inventory System", "Team Beta")
  System(paymentSystem, "Payment System", "Team Gamma")

  Rel(customer, orderSystem, "Places orders")
  Rel(orderSystem, inventorySystem, "Checks stock")
  Rel(orderSystem, paymentSystem, "Processes payment")
\`\`\`

### Event-Driven Architecture
Show individual topics/queues as containers, NOT a single "Kafka" box:
\`\`\`mermaid
C4Container
  title Event-Driven Architecture

  Container(orderService, "Order Service", "Java", "Creates orders")
  Container(stockService, "Stock Service", "Java", "Manages inventory")
  ContainerQueue(orderTopic, "order.created", "Kafka", "Order events")
  ContainerQueue(stockTopic, "stock.reserved", "Kafka", "Stock events")

  Rel(orderService, orderTopic, "Publishes to")
  Rel(stockService, orderTopic, "Subscribes to")
  Rel(stockService, stockTopic, "Publishes to")
  Rel(orderService, stockTopic, "Subscribes to")
\`\`\`

## Output Location

Write architecture documentation to \`docs/architecture/\` with naming convention:
- \`c4-context.md\` - System context diagram
- \`c4-containers.md\` - Container diagram
- \`c4-components-{feature}.md\` - Component diagrams per feature
- \`c4-deployment.md\` - Deployment diagram
- \`c4-dynamic-{flow}.md\` - Dynamic diagrams for specific flows

## Audience-Appropriate Detail

| Audience | Recommended Diagrams |
|----------|---------------------|
| Executives | System Context only |
| Product Managers | Context + Container |
| Architects | Context + Container + key Components |
| Developers | All levels as needed |
| DevOps | Container + Deployment |

## References

- [references/c4-syntax.md](references/c4-syntax.md) - Complete Mermaid C4 syntax
- [references/common-mistakes.md](references/common-mistakes.md) - Anti-patterns to avoid
- [references/advanced-patterns.md](references/advanced-patterns.md) - Microservices, event-driven, deployment
`,
  "risk-management": `---
name: risk-management
description: Risk identification, mitigation planning, dependency tracking, contingency planning, and risk monitoring throughout development
---

# Risk Management

## Overview

Identify, assess, and mitigate risks to project success. This skill enables proactive risk management, reducing surprises and enabling contingency planning.

**Use this skill when:**
- Planning sprints (identify potential blockers)
- Starting new epics (assess technical risk)
- Managing dependencies (track external blockers)
- Monitoring project health (catch issues early)
- Planning releases (prepare for worst-case scenarios)

## Risk Identification Framework

### Risk Categories

#### Technical Risks
- **New technology:** Unfamiliar stack, learning curve
- **Architecture decisions:** Wrong technology choice, scalability issues
- **Performance:** Database queries too slow, memory leaks
- **Integration:** Third-party API reliability, version compatibility
- **Security:** Vulnerability exposure, compliance risk

#### Resource Risks
- **Team availability:** Key person leaving, unexpected absences
- **Skill gaps:** Nobody knows required technology
- **Capacity:** Underestimated scope, team overcommitted
- **Dependency:** Waiting on another team's work

#### Business Risks
- **Scope creep:** Requirements unclear, stakeholder changes
- **Priorities shift:** Business priorities change mid-sprint
- **Market change:** Competitive pressure, customer needs shift
- **Timeline pressure:** Hard deadline, unrealistic schedule

### Risk Register Template

\`\`\`markdown
## Risk Register

### Risk 1: Database Query Performance

**Category:** Technical
**Probability:** Medium (50%)
**Impact:** High (would delay release 2+ weeks)
**Severity:** High (50% × High)

**Description:** Query optimization for 1M+ user records not yet tested at scale

**Mitigation Strategy:**
- Week 1: Load test with production-like data
- Week 2: Profile slow queries with APM tools
- Week 3: Implement indexing strategy
- Fallback: Cache frequently-accessed data

**Owner:** Senior database engineer
**Review date:** End of sprint 1
**Status:** Identified, mitigation in progress

---

### Risk 2: Third-party API Reliability

**Category:** Integration
**Probability:** Low (20%)
**Impact:** High (feature doesn't work)
**Severity:** Medium (20% × High)

**Description:** Payment processor API has 99.5% uptime SLA, no fallback

**Mitigation Strategy:**
- Implement retry logic with exponential backoff
- Use local fallback queue if API fails
- Monitor API health continuously
- Test failure scenarios in staging

**Fallback Plan:**
- If API unavailable, queue transactions locally
- Retry after recovery
- Notify ops team for investigation

**Owner:** Backend engineer
**Review date:** Before release
**Status:** Mitigation in progress

---

### Risk 3: Scope Creep

**Category:** Business
**Probability:** High (70%)
**Impact:** Medium (delays sprint, rework)
**Severity:** High (70% × Medium)

**Description:** Stakeholders often request "small changes" mid-sprint

**Mitigation Strategy:**
- Freeze requirements 2 days before sprint start
- Require scope change approval (PM + tech lead)
- Track change requests in separate backlog
- Communicate impact of changes upfront

**Owner:** Product Manager
**Review date:** Before each sprint
**Status:** Prevention strategy implemented
\`\`\`

## Risk Assessment Matrix

### Probability × Impact Grid

\`\`\`
                IMPACT
           Low    Medium   High
P    High   🟡      🔴      🔴
R    Med    🟢      🟡      🔴
O    Low    🟢      🟢      🟡
B
A
B
I
L
I
T
Y

🟢 Green (Low risk): Monitor only
🟡 Yellow (Medium risk): Active mitigation required
🔴 Red (High risk): Must resolve before proceeding
\`\`\`

### Example Assessment

\`\`\`
Risk: Database query performance
Probability: Medium (50%) - not tested at scale yet
Impact: High - would delay release 2+ weeks
Severity: High (🔴) - requires active mitigation

Risk: Key developer vacation
Probability: Known (100%) - scheduled time off
Impact: Medium - 1 feature delayed but team can compensate
Severity: Medium (🟡) - manageable with planning

Risk: Competitor releases similar feature
Probability: Low (20%) - unlikely this month
Impact: Low - market still has room for multiple solutions
Severity: Low (🟢) - monitor, not urgent
\`\`\`

## Dependency Tracking

### Dependency Types

#### Intra-Team Dependencies
\`\`\`
Story 2: "Setup database" (Blocks Story 3, 4)
    ↓
Story 3: "User authentication" (Depends on database)
    ↓
Story 4: "Authorization system" (Depends on database)
\`\`\`

**Management:**
- Identify blocking stories early
- Schedule dependent work in sequence
- Build dependencies first
- Communicate dependencies in sprint planning

#### Inter-Team Dependencies
\`\`\`
Mobile Team: "iOS app" (Depends on API)
    ↓
API Team: "User endpoints" (Blocks mobile team)
\`\`\`

**Management:**
- Establish API contracts early (OpenAPI)
- Use mocks/stubs for parallel work
- Weekly sync on integration schedule
- Plan ahead for blockers

#### Third-Party Dependencies
\`\`\`
Our Team: "Payment feature" (Depends on Stripe API)
    ↓
Stripe: "Account setup, API access"
\`\`\`

**Management:**
- Get accounts/access early
- Test integration in staging
- Have fallback plan (different provider)
- Monitor third-party service status

### Dependency Risk Register

\`\`\`markdown
## External Dependencies

### Stripe Payment API

**Dependency Type:** Third-party service
**Criticality:** High (payment processing)
**Probability of Delay:** Low (20%)
**Mitigation:**
- Established account and test keys in week 1
- Integration tested in staging by week 2
- Fallback: Use alternative provider (Square) if needed
- Monitor API status dashboard

**Owner:** Backend lead
**Status:** On track (account approved, sandbox ready)

---

### Backend Team: User Service

**Dependency Type:** Intra-team (blocking)
**Criticality:** High (frontend depends on it)
**Timeline:** Needed by end of sprint 1
**Mitigation:**
- User Service story: 13 points, priority Must-Have
- Frontend mocks endpoints by sprint 1 start
- API contract defined in week 1
- Integration test suite ready by week 2

**Owner:** Backend lead
**Status:** Planned, no delays expected
\`\`\`

## Contingency Planning

### "What If" Scenarios

\`\`\`
Scenario: Senior database engineer gets sick for 2 weeks

Impact:
- Database optimization delayed
- Performance testing at risk
- Could miss release date

Contingency Plan:
- Have mid-level engineer as backup (pair programming now)
- Document all decisions in wiki
- Contact external consultant if needed
- Shift performance testing to sprint 3

Trigger: If engineer is out >3 days, activate plan

---

Scenario: Third-party API changes pricing mid-project

Impact:
- Cost increases, business impact
- Might need to switch providers
- Code changes required

Contingency Plan:
- Review pricing terms before integration
- Evaluate alternatives (Square, PayPal) in parallel
- Keep abstraction layer for payment provider
- Alert business team immediately if changes occur

Trigger: Any change in payment terms/availability
\`\`\`

## Risk Monitoring

### Weekly Risk Review

**Duration:** 15 minutes
**Participants:** PM, tech lead
**Cadence:** Every Friday

**Checklist:**
- [ ] Any new risks identified?
- [ ] Any risks escalated in severity?
- [ ] Are mitigations on track?
- [ ] Should any risks be added to sprint?
- [ ] Any dependencies becoming critical?

### Sprint Planning Risk Check

**Before committing to sprint:**

\`\`\`
Risk Review Checklist:

□ Database risks: Performance testing complete?
□ Third-party risks: APIs working in sandbox?
□ Resource risks: Team available? No conflicts?
□ Scope risks: Requirements frozen and clear?
□ Integration risks: Dependency owners on same timeline?
□ External risks: Any planned outages/changes?

APPROVAL: Tech lead signs off on risk mitigation plan
\`\`\`

### Release Gate Risk Assessment

**Before shipping to production:**

\`\`\`
Final Risk Assessment:

Risk Level: Low / Medium / High

Outstanding risks:
1. [List any remaining risks]

Mitigation status:
- [Mitigation 1]: Implemented ✅
- [Mitigation 2]: Fallback ready ✅
- [Mitigation 3]: Monitoring active ✅

Contingency plan: [1-2 sentence fallback plan]

Approval: PM + Tech Lead + QA confirm ready to ship
\`\`\`

## Risk Management Best Practices

### Do's ✅
- Identify risks early (planning stage, not execution)
- Be specific (not "project is risky" but "third-party API reliability")
- Assign owners (who's responsible for mitigation)
- Update risk register weekly
- Escalate early when risks materialize
- Have concrete contingency plans
- Test fallback plans before needed
- Communicate risks to stakeholders

### Don'ts ❌
- Ignore risks hoping they disappear
- Assume worst-case will happen (waste resources)
- Over-engineer solutions for low-probability risks
- Hide risks from stakeholders
- Fail to update risk status
- Plan contingencies without triggers
- Make contingencies too theoretical (test them!)

## Related Skills

- @backlog-refinement - Identify risks in story definition
- @capacity-planning - Risk from underestimation or resource constraints
- @metrics-reporting - Track risk KPIs and early warning signals
- @sprint-planning - Execute risk mitigations in sprints
`,
  "roadmap-planning": `---
name: roadmap-planning
description: Strategic roadmap creation using OKR methodology, quarterly planning, and feature prioritization
---

# Roadmap Planning

## Overview

Create strategic product roadmaps aligned with business objectives using OKR (Objectives and Key Results) methodology. This skill guides quarterly planning, feature prioritization, and long-term vision articulation.

**Use this skill when:**
- Creating quarterly product roadmaps
- Setting product strategy and direction
- Prioritizing features across teams
- Communicating strategy to stakeholders
- Planning major releases or milestones

## Core Methodology: OKR Framework

### Objectives
- Qualitative goals that describe what you want to achieve
- Inspirational and motivational
- Time-bound (typically quarterly)
- Example: "Become the most reliable backend for mission-critical systems"

### Key Results
- Measurable outcomes (0-1.0 scale)
- Specific and quantified
- 3-5 per objective
- Example: "Reduce P95 latency from 500ms to 100ms" (0.5 achieved at 300ms)

## Roadmap Creation Process

### Phase 1: Strategy Definition
1. **Gather Business Context**
   - Review last quarter's results
   - Identify market opportunities
   - Understand team capacity
   - Survey customer feedback and requests

2. **Define Quarterly Objectives (3-5)**
   - Keep to max 5 major objectives
   - Use action-oriented language
   - Make them inspirational but achievable

3. **Create Key Results (3-5 per objective)**
   - Quantifiable and measurable
   - Use SMART criteria
   - Link to business metrics

### Phase 2: Feature Breakdown
1. **Map Features to OKRs**
   - Which features directly support each KR?
   - What are dependencies?
   - What are high-risk items?

2. **Prioritization Matrix**
   - Impact (high/medium/low)
   - Effort (small/medium/large)
   - Risk (low/medium/high)
   - Dependencies (blocking/none)

3. **Create Phased Timeline**
   - Week 1-2: Foundation features
   - Week 3-6: Core implementation
   - Week 7-10: Polish and integration
   - Week 11-12: Testing and buffer

### Phase 3: Stakeholder Communication

1. **Executive Summary Deck**
   - Vision and strategy
   - Quarterly objectives
   - Key results with targets
   - High-level timeline
   - Risk mitigation plan

2. **Detailed Technical Roadmap**
   - Feature breakdown
   - Engineering effort estimates
   - Dependency map
   - Team assignments
   - Milestone gates

3. **Communication Plan**
   - All-hands presentation
   - Team syncs
   - Customer communication
   - Status update frequency

## Tools & References

- **OKR Framework**: https://en.wikipedia.org/wiki/Objectives_and_key_results
- **DORA Metrics**: Track deployment frequency, lead time, MTTR, change failure rate
- **Roadmap Tools**: JIRA, Monday.com, Fibonacci/Roadmunk
- **Prioritization**: MoSCoW method (Must, Should, Could, Won't have)

## Example Roadmap Structure

\`\`\`markdown
# Q1 2026 Product Roadmap

## Strategic Objectives
- **Objective 1:** Improve system reliability to enterprise grade
  - KR1: Achieve 99.99% uptime (currently 99.5%)
  - KR2: Reduce P95 latency to <100ms (currently 500ms)
  - KR3: Pass SOC 2 Type II audit

- **Objective 2:** Expand platform capabilities for scale
  - KR1: Support 10x concurrent users
  - KR2: Launch multi-tenancy features
  - KR3: Integrate 5 new data connectors

- **Objective 3:** Strengthen product-market fit
  - KR1: Grow NPS to 60+ (currently 45)
  - KR2: Reduce churn to <2% (currently 5%)
  - KR3: Achieve 50+ enterprise customers (currently 15)

## Featured Phases

### Phase 1: Foundation (Weeks 1-4)
- [ ] Database sharding implementation
- [ ] Cache layer optimization
- [ ] API rate limiting
- [ ] Security audit and hardening

### Phase 2: Expansion (Weeks 5-8)
- [ ] Multi-tenancy support
- [ ] Advanced analytics dashboard
- [ ] Data export capabilities
- [ ] API versioning strategy

### Phase 3: Polish (Weeks 9-12)
- [ ] Performance optimization
- [ ] Documentation updates
- [ ] QA and testing cycle
- [ ] Release preparation
\`\`\`

## Review & Refinement

1. **Weekly Standup Review**
   - Are we on track against KRs?
   - Any blockers or risks emerging?
   - Adjustments needed?

2. **Mid-Quarter Check-in**
   - Progress on KRs (should be 50%)
   - Confidence levels
   - Scope adjustment if needed

3. **End-of-Quarter Review**
   - Final KR scores
   - What worked well?
   - What to improve next quarter?
   - Retrospective insights

## Related Skills

- @sprint-planning - Tactical sprint execution
- @metrics-reporting - Track progress against OKRs
- @stakeholder-communication - Keep teams aligned
- @capacity-planning - Resource allocation for roadmap execution
`,
  "run-tests-and-fix": `---
name: run-tests-and-fix
description: Run Tests and Fix Failures
disable-model-invocation: true
---

# Run Tests and Fix Failures

## Overview

Execute the full test suite and systematically fix any failures, ensuring code quality and functionality.

## Steps

1. **Run test suite**
   - Execute all tests in the project
   - Capture output and identify failures
   - Check both unit and integration tests

2. **Analyze failures**
   - Categorize by type: flaky, broken, new failures
   - Prioritize fixes based on impact
   - Check if failures are related to recent changes

3. **Fix issues systematically**
   - Start with the most critical failures
   - Fix one issue at a time
   - Re-run tests after each fix

## Test recovery checklist

- [ ] Full test suite executed
- [ ] Failures categorized and tracked
- [ ] Root causes resolved
- [ ] Tests re-run with passing results
- [ ] Follow-up improvements noted
`,
  "security-audit-copy": `---
name: security-audit-copy
description: Security Audit
disable-model-invocation: true
---

# Security Audit

## Overview

Comprehensive security review to identify and fix vulnerabilities in the
codebase.

## Steps

1. **Dependency audit**
   - Check for known vulnerabilities
   - Update outdated packages
   - Review third-party dependencies
2. **Code security review**
   - Check for common vulnerabilities
   - Review authentication/authorization
   - Audit data handling practices
3. **Infrastructure security**
   - Review environment variables
   - Check access controls
   - Audit network security

## Security Checklist

- [ ] Dependencies updated and secure
- [ ] No hardcoded secrets
- [ ] Input validation implemented
- [ ] Authentication secure
- [ ] Authorization properly configured
`,
  "security-audit": `---
name: security-audit
description: Security Audit
disable-model-invocation: true
---

# Security Audit

## Overview

Perform a comprehensive security review of the codebase: identify vulnerabilities, then provide specific remediation steps with code examples for each issue. Cover dependencies, code patterns, data handling, and infrastructure.

## Steps

1. **Dependency audit**
   - Check for known vulnerabilities (e.g. \`npm audit\`)
   - Update outdated packages
   - Review third-party dependencies

2. **Authentication & authorization**
   - Verify proper authentication mechanisms
   - Check authorization controls and permission systems (e.g. Convex auth guards, membership checks)
   - Review session management and token handling
   - Ensure secure password policies and storage (if applicable)

3. **Input validation & sanitization**
   - Identify SQL injection and other injection vulnerabilities
   - Check for XSS and CSRF attack vectors
   - Validate all user inputs and API parameters
   - Review file upload and processing security

4. **Data protection**
   - Ensure sensitive data encryption at rest and in transit
   - Check for data exposure in logs and error messages
   - Review API responses for information leakage
   - Verify proper secrets management; no hardcoded secrets

5. **Infrastructure security**
   - Review environment variables and configuration security
   - Check HTTPS configuration and certificate validation
   - Analyze CORS policies and security headers
   - Audit network and access controls

## Security checklist

- [ ] Dependencies updated and free of known vulnerabilities
- [ ] No hardcoded secrets; proper secrets management
- [ ] Input validation and sanitization implemented
- [ ] Authentication mechanisms verified
- [ ] Authorization and permission systems checked
- [ ] Session management and token handling reviewed
- [ ] Sensitive data encrypted at rest and in transit
- [ ] No sensitive data in logs or error messages
- [ ] CORS and security headers reviewed
- [ ] Environment and configuration security reviewed
`,
  "security-hardening": `---
name: security-hardening
description: OWASP security patterns, input validation, CSRF/XSS prevention, authentication, and secure defaults
---

# Security Hardening

## Overview

Build secure systems by implementing OWASP best practices, input validation, authentication, and authorization patterns. This skill covers defense-in-depth strategies and secure coding practices.

**Use this skill when:**
- Building APIs and web applications
- Implementing user authentication
- Handling sensitive data
- Designing authorization logic
- Reviewing code for security vulnerabilities

## OWASP Top 10 (2023)

### 1. Broken Access Control

**Risk:** Users access resources they shouldn't (horizontal/vertical escalation)

**Prevention:**
\`\`\`typescript
// ❌ Wrong - trusts client
GET /api/users/123
// Client can change ID and access other users

// ✅ Right - verify ownership
async function getUserData(userId: string, requestingUser: string) {
  if (userId !== requestingUser) {
    throw new UnauthorizedError('Cannot access other user data');
  }
  return getUser(userId);
}
\`\`\`

### 2. Cryptographic Failures

**Risk:** Exposure of sensitive data (passwords, tokens, API keys)

**Prevention:**
\`\`\`typescript
// ❌ Wrong - hardcoded secrets
const apiKey = "sk_live_abc123def456";

// ✅ Right - environment variables
const apiKey = process.env.STRIPE_API_KEY;

// Hash passwords, never store plaintext
import bcrypt from 'bcrypt';
const hash = await bcrypt.hash(password, 10);
const isValid = await bcrypt.compare(password, hash);

// Use HTTPS only (no HTTP)
// Encrypt data at rest in databases
\`\`\`

### 3. Injection

**Risk:** Attacker injects malicious code (SQL, NoSQL, command injection)

**Prevention:**
\`\`\`typescript
// ❌ Wrong - string concatenation
const query = \`SELECT * FROM users WHERE id = \${userId}\`;

// ✅ Right - parameterized queries
const user = db.query('SELECT * FROM users WHERE id = ?', [userId]);

// ❌ Wrong - eval with user input
eval(userInput);

// ✅ Right - use template engines safely
const template = Handlebars.compile(templateString);
const output = template(safeData);

// Validate and sanitize all inputs
import validator from 'validator';
const email = validator.normalizeEmail(userInput);
\`\`\`

### 4. Insecure Design

**Risk:** Missing security requirements in architecture

**Prevention:**
- Implement authentication/authorization upfront
- Use role-based access control (RBAC)
- Encrypt sensitive data
- Log security events
- Rate limiting on sensitive endpoints

### 5. Security Misconfiguration

**Risk:** Default credentials, unnecessary services, outdated dependencies

**Prevention:**
\`\`\`bash
# ✅ Keep dependencies updated
npm audit
npm update

# ❌ Don't expose debug info in production
console.error(error);  // May leak stack traces

# ✅ Custom error messages
return { error: 'Invalid credentials' };  // No details

# Disable X-Powered-By header
app.disable('x-powered-by');

# Use Content Security Policy
app.use((req, res, next) => {
  res.setHeader("Content-Security-Policy", "default-src 'self'");
  next();
});
\`\`\`

### 6. Vulnerable & Outdated Components

**Risk:** Using libraries with known vulnerabilities

**Prevention:**
\`\`\`bash
# Regular scanning
npm audit
npm audit fix

# Check before adding dependencies
npx snyk test

# Pin versions
npm install --save-exact lodash@4.17.21

# Remove unused dependencies
npm prune
\`\`\`

### 7. Authentication Failures

**Risk:** Weak password policies, session management issues

**Prevention:**
\`\`\`typescript
// Strong password requirements
const passwordRegex = /^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@\$!%*?&])[A-Za-z\\d@\$!%*?&]{12,}\$/;
if (!passwordRegex.test(password)) {
  throw new Error('Password must be 12+ chars with uppercase, lowercase, number, symbol');
}

// Secure session management
// Use secure cookies
response.setHeader('Set-Cookie', [
  'sessionId=abc123; HttpOnly; Secure; SameSite=Strict; Path=/',
]);

// Implement MFA for critical operations
// Session timeout for inactivity
// Never expose session IDs in URLs
\`\`\`

### 8. Software and Data Integrity Failures

**Risk:** Untrusted updates, vulnerable dependencies

**Prevention:**
- Verify signatures of software updates
- Use HTTPS for all downloads
- Pin dependency versions
- Code signing for releases

### 9. Logging & Monitoring Failures

**Risk:** Not detecting security incidents

**Prevention:**
\`\`\`typescript
// Log security events
logger.info('Failed login attempt', {
  email: userEmail,
  ip: request.ip,
  timestamp: new Date(),
});

// Monitor for suspicious patterns
// Alert on multiple failed auth attempts
// Track sensitive data access
\`\`\`

### 10. SSRF (Server-Side Request Forgery)

**Risk:** Attacker makes server perform unintended requests

**Prevention:**
\`\`\`typescript
// ❌ Wrong - trusts user URL
const response = await fetch(userProvidedUrl);

// ✅ Right - whitelist domains
const allowedDomains = ['api.example.com', 'data.example.com'];
const url = new URL(userProvidedUrl);
if (!allowedDomains.includes(url.hostname)) {
  throw new Error('URL not allowed');
}
const response = await fetch(userProvidedUrl);
\`\`\`

## Common Vulnerabilities

### Cross-Site Scripting (XSS)

**Stored XSS Example:**
\`\`\`typescript
// ❌ Wrong - stored user input rendered as HTML
const userComment = "<img src=x onerror='alert(1)'>";
res.send(\`<p>\${userComment}</p>\`);

// ✅ Right - escape HTML
const escaped = sanitizeHtml(userComment);
res.send(\`<p>\${escaped}</p>\`);

// Or use template engines with auto-escaping
res.render('comment', { comment: userComment });
\`\`\`

### Cross-Site Request Forgery (CSRF)

**Prevention:**
\`\`\`typescript
// CSRF token in forms
<form method="POST" action="/update-email">
  <input type="hidden" name="csrfToken" value="<%= csrfToken %>">
  <input type="email" name="email">
</form>

// Verify token on submission
app.post('/update-email', (req, res) => {
  if (!verifyCsrfToken(req.body.csrfToken, req.session)) {
    return res.status(403).send('Invalid CSRF token');
  }
  // Process request
});

// SameSite cookies as defense layer
res.setHeader('Set-Cookie', 'sessionId=abc; SameSite=Strict');
\`\`\`

### Broken Authentication

\`\`\`typescript
// ✅ Good password handling
const hash = await bcrypt.hash(password, 10);
await db.users.update({ id: userId }, { passwordHash: hash });

// ✅ Session security
const sessionToken = crypto.randomBytes(32).toString('hex');
await db.sessions.create({ token: sessionToken, userId, expiresAt: futureDate });

// ✅ Never expose sensitive data
return { id: user.id, email: user.email };  // No password hash!

// Implement rate limiting on login
limiter.limit('login', userEmail, 5);  // Max 5 attempts per hour
\`\`\`

## Input Validation Strategy

\`\`\`typescript
// 1. Whitelist allowed values
const allowedRoles = ['admin', 'user', 'guest'];
if (!allowedRoles.includes(userRole)) {
  throw new Error('Invalid role');
}

// 2. Validate data types
if (typeof age !== 'number' || age < 0 || age > 150) {
  throw new Error('Invalid age');
}

// 3. Limit string length
if (email.length > 255) {
  throw new Error('Email too long');
}

// 4. Use schema validation
import { z } from 'zod';
const userSchema = z.object({
  email: z.string().email(),
  age: z.number().min(0).max(150),
  role: z.enum(['admin', 'user', 'guest']),
});
const validated = userSchema.parse(userInput);
\`\`\`

## Security Checklist

- [ ] All data inputs validated and sanitized
- [ ] Sensitive data encrypted (passwords, API keys, PII)
- [ ] HTTPS enforced, no HTTP
- [ ] CORS properly configured
- [ ] Rate limiting on sensitive endpoints
- [ ] Authentication and authorization implemented
- [ ] Security headers set (CSP, X-Frame-Options, etc.)
- [ ] Error messages don't leak sensitive info
- [ ] Dependencies scanned for vulnerabilities
- [ ] Security logs captured and monitored
- [ ] Secrets not in version control (.env in .gitignore)
- [ ] CSRF protection enabled
- [ ] XSS protection (template auto-escape or sanitization)
- [ ] SQL injection prevention (parameterized queries)

## Related Skills

- @backend-convex - Implement secure Convex queries
- @api-design - Design secure APIs
- @test-automation - Test security with automated tests
- @production-ready-refactor - Refactor for security
`,
  "sprint-planning": `---
name: writing-plans
description: Use when you have a spec or requirements for a multi-step task, before touching code
---

# Writing Plans

## Overview

Write comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.

Assume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.

**Announce at start:** "I'm using the writing-plans skill to create the implementation plan."

**Context:** This should be run in a dedicated worktree (created by brainstorming skill).

**Save plans to:** \`docs/plans/YYYY-MM-DD-<feature-name>.md\`

## Bite-Sized Task Granularity

**Each step is one action (2-5 minutes):**
- "Write the failing test" - step
- "Run it to make sure it fails" - step
- "Implement the minimal code to make the test pass" - step
- "Run the tests and make sure they pass" - step
- "Commit" - step

## Plan Document Header

**Every plan MUST start with this header:**

\`\`\`markdown
# [Feature Name] Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** [One sentence describing what this builds]

**Architecture:** [2-3 sentences about approach]

**Tech Stack:** [Key technologies/libraries]

---
\`\`\`

## Task Structure

\`\`\`markdown
### Task N: [Component Name]

**Files:**
- Create: \`exact/path/to/file.py\`
- Modify: \`exact/path/to/existing.py:123-145\`
- Test: \`tests/exact/path/to/test.py\`

**Step 1: Write the failing test**

\`\`\`python
def test_specific_behavior():
    result = function(input)
    assert result == expected
\`\`\`

**Step 2: Run test to verify it fails**

Run: \`pytest tests/path/test.py::test_name -v\`
Expected: FAIL with "function not defined"

**Step 3: Write minimal implementation**

\`\`\`python
def function(input):
    return expected
\`\`\`

**Step 4: Run test to verify it passes**

Run: \`pytest tests/path/test.py::test_name -v\`
Expected: PASS

**Step 5: Commit**

\`\`\`bash
git add tests/path/test.py src/path/file.py
git commit -m "feat: add specific feature"
\`\`\`
\`\`\`

## Remember
- Exact file paths always
- Complete code in plan (not "add validation")
- Exact commands with expected output
- Reference relevant skills with @ syntax
- DRY, YAGNI, TDD, frequent commits

## Execution Handoff

After saving the plan, offer execution choice:

**"Plan complete and saved to \`docs/plans/<filename>.md\`. Two execution options:**

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

**Which approach?"**

**If Subagent-Driven chosen:**
- **REQUIRED SUB-SKILL:** Use superpowers:subagent-driven-development
- Stay in this session
- Fresh subagent per task + code review

**If Parallel Session chosen:**
- Guide them to open new session in worktree
- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans
`,
  "test-automation": `---
name: webapp-testing
description: Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.
license: Complete terms in LICENSE.txt
---

# Web Application Testing

To test local web applications, write native Python Playwright scripts.

**Helper Scripts Available**:
- \`scripts/with_server.py\` - Manages server lifecycle (supports multiple servers)

**Always run scripts with \`--help\` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.

## Decision Tree: Choosing Your Approach

\`\`\`
User task → Is it static HTML?
    ├─ Yes → Read HTML file directly to identify selectors
    │         ├─ Success → Write Playwright script using selectors
    │         └─ Fails/Incomplete → Treat as dynamic (below)
    │
    └─ No (dynamic webapp) → Is the server already running?
        ├─ No → Run: python scripts/with_server.py --help
        │        Then use the helper + write simplified Playwright script
        │
        └─ Yes → Reconnaissance-then-action:
            1. Navigate and wait for networkidle
            2. Take screenshot or inspect DOM
            3. Identify selectors from rendered state
            4. Execute actions with discovered selectors
\`\`\`

## Example: Using with_server.py

To start a server, run \`--help\` first, then use the helper:

**Single server:**
\`\`\`bash
python scripts/with_server.py --server "npm run dev" --port 5173 -- python your_automation.py
\`\`\`

**Multiple servers (e.g., backend + frontend):**
\`\`\`bash
python scripts/with_server.py \\
  --server "cd backend && python server.py" --port 3000 \\
  --server "cd frontend && npm run dev" --port 5173 \\
  -- python your_automation.py
\`\`\`

To create an automation script, include only Playwright logic (servers are managed automatically):
\`\`\`python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode
    page = browser.new_page()
    page.goto('http://localhost:5173') # Server already running and ready
    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute
    # ... your automation logic
    browser.close()
\`\`\`

## Reconnaissance-Then-Action Pattern

1. **Inspect rendered DOM**:
   \`\`\`python
   page.screenshot(path='/tmp/inspect.png', full_page=True)
   content = page.content()
   page.locator('button').all()
   \`\`\`

2. **Identify selectors** from inspection results

3. **Execute actions** using discovered selectors

## Common Pitfall

❌ **Don't** inspect the DOM before waiting for \`networkidle\` on dynamic apps
✅ **Do** wait for \`page.wait_for_load_state('networkidle')\` before inspection

## Best Practices

- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in \`scripts/\` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use \`--help\` to see usage, then invoke directly. 
- Use \`sync_playwright()\` for synchronous scripts
- Always close the browser when done
- Use descriptive selectors: \`text=\`, \`role=\`, CSS selectors, or IDs
- Add appropriate waits: \`page.wait_for_selector()\` or \`page.wait_for_timeout()\`

## Reference Files

- **examples/** - Examples showing common patterns:
  - \`element_discovery.py\` - Discovering buttons, links, and inputs on a page
  - \`static_html_automation.py\` - Using file:// URLs for local HTML
  - \`console_logging.py\` - Capturing console logs during automation`,
  "test-coverage-analysis": `---
name: test-coverage-analysis
description: Code coverage metrics, untested paths, coverage targets, coverage-driven testing, and test gap identification
---

# Test Coverage Analysis

## Overview

Ensure comprehensive test coverage through metrics-driven analysis. This skill covers coverage measurement, gap identification, and strategies for achieving meaningful coverage targets that catch real bugs.

**Use this skill when:**
- Setting coverage targets for new features
- Identifying untested code paths
- Analyzing coverage gaps after implementation
- Planning test expansion for legacy code
- Validating coverage quality (not just metrics)

**Cross-functional pairing:** @engineer **database-optimization** — Database schema changes require coverage validation of new/modified query paths and edge cases

---

## Coverage Metrics Explained

### What Coverage Measures

\`\`\`typescript
// Line Coverage: Did each line execute?
function calculateTotal(items: number[]) {
  const sum = items.reduce((a, b) => a + b, 0);     // Line 1
  const count = items.length;                        // Line 2
  if (count === 0) return 0;                         // Line 3
  return sum / count;                                // Line 4
}

// Test with [1, 2, 3] covers lines 1-4
// Test with [] covers lines 1-3 only
// Line 4 has 50% coverage
\`\`\`

### Coverage Types (Pyramid)

\`\`\`
           Branch Coverage (Condition combinations)
          /                                        \\
         / Covers: if/else, switch, && || ternary \\
        /                                          \\
    Function Coverage (Entry/exit)
   /                                    \\
  / Covers: function called or not       \\
 /                                        \\
Line Coverage (Instruction execution)
Covers: each statement executed or not
\`\`\`

### Coverage Metrics

| Metric | Definition | Target | How to Improve |
|--------|-----------|--------|----------------|
| **Line** | % of lines executed | 80%+ | Write tests for uncovered lines |
| **Branch** | % of conditionals tested | 75%+ | Test both if/else, all cases |
| **Function** | % of functions called | 85%+ | Call all public functions |
| **Statement** | % of statements executed | 80%+ | Similar to line coverage |

---

## Coverage Tools

### Istanbul/NYC (Node.js)

\`\`\`bash
npm install --save-dev nyc

# Generate coverage report
nyc npm test

# Output:
# ======= Coverage summary =======
# Statements   : 85.2% ( 210/246 )
# Branches     : 72.1% ( 95/131 )
# Functions    : 88.0% ( 22/25 )
# Lines        : 85.5% ( 211/247 )
\`\`\`

**Config (\`.nycrc.json\`):**

\`\`\`json
{
  "reporter": ["text", "text-summary", "html", "json"],
  "all": true,
  "include": ["src/**/*.ts"],
  "exclude": ["src/**/*.test.ts", "dist/**"],
  "lines": 80,
  "branches": 75,
  "functions": 85,
  "statements": 80,
  "check-coverage": true
}
\`\`\`

### Vitest Coverage

\`\`\`bash
npm install --save-dev @vitest/coverage-v8

# Run tests with coverage
vitest --coverage

# Output:
# src/utils.ts         92.3% | 12/13
# src/api.ts           78.5% | 42/54
\`\`\`

**Config (\`vitest.config.ts\`):**

\`\`\`typescript
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    coverage: {
      provider: 'v8',
      reporter: ['text', 'html', 'json'],
      lines: 80,
      functions: 80,
      branches: 75,
      statements: 80,
    },
  },
});
\`\`\`

---

## Gap Identification Strategy

### Step 1: Run Coverage Report

\`\`\`bash
npm run coverage 2>&1 | grep -E "^packages/|Lines|Branches"
\`\`\`

### Step 2: Find Uncovered Lines

\`\`\`html
<!-- coverage/index.html -->
<!-- Color coded:
     Green = Covered
     Red = Uncovered
     Yellow = Partially covered
-->
\`\`\`

### Step 3: Analyze Gaps by Type

**Uncovered conditionals:**

\`\`\`typescript
// Missing: test when count === 0
function divide(a: number, b: number) {
  if (b === 0) return null;  // ← Not tested
  return a / b;
}
\`\`\`

**Uncovered error paths:**

\`\`\`typescript
// Missing: test when userId is invalid
async function getUser(userId: string) {
  if (!userId) throw new Error('Invalid user');  // ← Not tested
  return db.get(userId);
}
\`\`\`

**Uncovered branches:**

\`\`\`typescript
// Missing: test success branch
try {
  await api.call();  // ← Not tested when it succeeds
} catch (e) {
  logger.error(e);   // ← Tested
}
\`\`\`

---

## Coverage-Driven Testing

### Approach: Minimum Viable Coverage

\`\`\`typescript
// ❌ Don't test every line—test behavior

// ❌ Bad: 100% line coverage but poor tests
test('adds 1 + 1', () => {
  expect(1 + 1).toBe(2);  // Trivial
});

test('adds 2 + 2', () => {
  expect(2 + 2).toBe(4);  // Trivial
});

// ✅ Good: Meaningful coverage

test('add function', () => {
  expect(add(1, 1)).toBe(2);
  expect(add(-1, 1)).toBe(0);
  expect(add(0, 0)).toBe(0);
});
\`\`\`

### Approach: Risk-Based Coverage

**High-risk code → Higher coverage:**

\`\`\`typescript
// Critical: Payment processing (aim for 95%+)
function processPayment(amount: number, card: Card) {
  if (amount < 0) throw new Error('Invalid amount');
  if (!card.isValid()) throw new Error('Invalid card');
  return chargeCard(card, amount);
}

// Medium-risk: Logging (aim for 70%+)
function log(level: string, msg: string) {
  if (process.env.NODE_ENV === 'test') return;
  console.log(\`[\${level}] \${msg}\`);
}

// Low-risk: UI helpers (aim for 60%+)
function formatDate(date: Date) {
  return date.toLocaleDateString();
}
\`\`\`

---

## Setting Coverage Targets

### Industry Standards

| Industry | Typical Target |
|----------|----------------|
| **Financial** | 90%+ (high risk) |
| **Healthcare** | 85%+ (regulated) |
| **SaaS** | 75-80% (balanced) |
| **Startups** | 60-70% (speed priority) |

### OpenClaw Targets

**Recommended for Phase 2:**

\`\`\`json
{
  "lines": 80,
  "functions": 85,
  "branches": 75,
  "statements": 80
}
\`\`\`

**Tier-based approach:**

\`\`\`typescript
// Tier 1 (Core): 90% coverage
// - Authentication, payment, data access

// Tier 2 (Features): 75% coverage
// - Business logic, API endpoints

// Tier 3 (UI/Utils): 60% coverage
// - UI components, helpers
\`\`\`

---

## Improving Coverage

### Pattern 1: Path Coverage

\`\`\`typescript
// Original: 50% branch coverage
function validate(input: string) {
  if (!input) return false;
  if (input.length < 3) return false;
  return true;
}

// Test cases needed for 100% branch coverage:
test('rejects empty', () => expect(validate('')).toBe(false));
test('rejects short', () => expect(validate('ab')).toBe(false));
test('accepts valid', () => expect(validate('abc')).toBe(true));
\`\`\`

### Pattern 2: Error Path Coverage

\`\`\`typescript
// Original: Missing error tests
async function fetchUser(id: string) {
  const user = await db.get(id);
  return user;
}

// Add error scenarios:
test('handles not found', async () => {
  db.get = jest.fn().mockRejectedValue(new Error('Not found'));
  await expect(fetchUser('invalid')).rejects.toThrow('Not found');
});

test('handles network error', async () => {
  db.get = jest.fn().mockRejectedValue(new Error('Network'));
  await expect(fetchUser('123')).rejects.toThrow('Network');
});
\`\`\`

### Pattern 3: Boundary Coverage

\`\`\`typescript
// Original: 50% coverage
function isAdult(age: number) {
  return age >= 18;
}

// Add boundary tests:
test('boundary: age 17 is not adult', () => {
  expect(isAdult(17)).toBe(false);
});

test('boundary: age 18 is adult', () => {
  expect(isAdult(18)).toBe(true);
});

test('extreme: age 150', () => {
  expect(isAdult(150)).toBe(true);
});

test('invalid: negative age', () => {
  expect(isAdult(-1)).toBe(false);
});
\`\`\`

---

## Coverage Thresholds in CI/CD

### GitHub Actions

\`\`\`yaml
# .github/workflows/test.yml
name: Test & Coverage

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '22'
      
      - run: npm ci
      - run: npm run coverage
      
      - name: Check coverage
        run: |
          if [ \$(cat coverage/coverage-summary.json | jq '.total.lines.pct') -lt 80 ]; then
            echo "Coverage below 80%"
            exit 1
          fi
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/coverage-final.json
\`\`\`

### Enforce Thresholds

\`\`\`typescript
// vitest.config.ts
export default defineConfig({
  test: {
    coverage: {
      lines: 80,
      branches: 75,
      functions: 85,
      statements: 80,
      perFile: true,  // Per-file threshold
    },
  },
});
\`\`\`

---

## Common Coverage Pitfalls

| Pitfall | Risk | Solution |
|---------|------|----------|
| **High coverage, low quality** | False confidence | Test behavior, not lines |
| **Testing implementation** | Tests break with refactors | Test contracts, not internals |
| **Skipping error paths** | Missing bug detection | Mock failures and timeouts |
| **Unrealistic targets** | Team burnout | Set risk-based targets |
| **Ignoring branches** | 80% line ≠ 80% branch | Explicitly test conditions |

---

## Coverage Checklist

- [ ] Coverage tool integrated (Istanbul/Vitest)
- [ ] Coverage targets set for project (lines, branches, functions)
- [ ] CI/CD enforces thresholds
- [ ] Coverage reports accessible (Codecov, GitHub)
- [ ] Team aligned on quality over quantity
- [ ] High-risk code prioritized (auth, payments)
- [ ] Error paths tested
- [ ] Boundary cases tested
- [ ] Coverage gaps documented
- [ ] Monthly review of coverage trends

---

## Related Skills

- @regression-testing - Automated regression suites to maintain coverage
- @database-optimization - Coverage validation for schema changes
- @mutation-testing - Validate that tests actually catch bugs
- @test-automation - Integrate coverage into CI/CD pipelines
`,
  "test-strategy": `---
name: test-driven-development
description: Use when implementing any feature or bugfix, before writing implementation code
---

# Test-Driven Development (TDD)

## Overview

Write the test first. Watch it fail. Write minimal code to pass.

**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.

**Violating the letter of the rules is violating the spirit of the rules.**

## When to Use

**Always:**
- New features
- Bug fixes
- Refactoring
- Behavior changes

**Exceptions (ask your human partner):**
- Throwaway prototypes
- Generated code
- Configuration files

Thinking "skip TDD just this once"? Stop. That's rationalization.

## The Iron Law

\`\`\`
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
\`\`\`

Write code before the test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete

Implement fresh from tests. Period.

## Red-Green-Refactor

\`\`\`dot
digraph tdd_cycle {
    rankdir=LR;
    red [label="RED\\nWrite failing test", shape=box, style=filled, fillcolor="#ffcccc"];
    verify_red [label="Verify fails\\ncorrectly", shape=diamond];
    green [label="GREEN\\nMinimal code", shape=box, style=filled, fillcolor="#ccffcc"];
    verify_green [label="Verify passes\\nAll green", shape=diamond];
    refactor [label="REFACTOR\\nClean up", shape=box, style=filled, fillcolor="#ccccff"];
    next [label="Next", shape=ellipse];

    red -> verify_red;
    verify_red -> green [label="yes"];
    verify_red -> red [label="wrong\\nfailure"];
    green -> verify_green;
    verify_green -> refactor [label="yes"];
    verify_green -> green [label="no"];
    refactor -> verify_green [label="stay\\ngreen"];
    verify_green -> next;
    next -> red;
}
\`\`\`

### RED - Write Failing Test

Write one minimal test showing what should happen.

<Good>
\`\`\`typescript
test('retries failed operations 3 times', async () => {
  let attempts = 0;
  const operation = () => {
    attempts++;
    if (attempts < 3) throw new Error('fail');
    return 'success';
  };

  const result = await retryOperation(operation);

  expect(result).toBe('success');
  expect(attempts).toBe(3);
});
\`\`\`
Clear name, tests real behavior, one thing
</Good>

<Bad>
\`\`\`typescript
test('retry works', async () => {
  const mock = jest.fn()
    .mockRejectedValueOnce(new Error())
    .mockRejectedValueOnce(new Error())
    .mockResolvedValueOnce('success');
  await retryOperation(mock);
  expect(mock).toHaveBeenCalledTimes(3);
});
\`\`\`
Vague name, tests mock not code
</Bad>

**Requirements:**
- One behavior
- Clear name
- Real code (no mocks unless unavoidable)

### Verify RED - Watch It Fail

**MANDATORY. Never skip.**

\`\`\`bash
npm test path/to/test.test.ts
\`\`\`

Confirm:
- Test fails (not errors)
- Failure message is expected
- Fails because feature missing (not typos)

**Test passes?** You're testing existing behavior. Fix test.

**Test errors?** Fix error, re-run until it fails correctly.

### GREEN - Minimal Code

Write simplest code to pass the test.

<Good>
\`\`\`typescript
async function retryOperation<T>(fn: () => Promise<T>): Promise<T> {
  for (let i = 0; i < 3; i++) {
    try {
      return await fn();
    } catch (e) {
      if (i === 2) throw e;
    }
  }
  throw new Error('unreachable');
}
\`\`\`
Just enough to pass
</Good>

<Bad>
\`\`\`typescript
async function retryOperation<T>(
  fn: () => Promise<T>,
  options?: {
    maxRetries?: number;
    backoff?: 'linear' | 'exponential';
    onRetry?: (attempt: number) => void;
  }
): Promise<T> {
  // YAGNI
}
\`\`\`
Over-engineered
</Bad>

Don't add features, refactor other code, or "improve" beyond the test.

### Verify GREEN - Watch It Pass

**MANDATORY.**

\`\`\`bash
npm test path/to/test.test.ts
\`\`\`

Confirm:
- Test passes
- Other tests still pass
- Output pristine (no errors, warnings)

**Test fails?** Fix code, not test.

**Other tests fail?** Fix now.

### REFACTOR - Clean Up

After green only:
- Remove duplication
- Improve names
- Extract helpers

Keep tests green. Don't add behavior.

### Repeat

Next failing test for next feature.

## Good Tests

| Quality | Good | Bad |
|---------|------|-----|
| **Minimal** | One thing. "and" in name? Split it. | \`test('validates email and domain and whitespace')\` |
| **Clear** | Name describes behavior | \`test('test1')\` |
| **Shows intent** | Demonstrates desired API | Obscures what code should do |

## Why Order Matters

**"I'll write tests after to verify it works"**

Tests written after code pass immediately. Passing immediately proves nothing:
- Might test wrong thing
- Might test implementation, not behavior
- Might miss edge cases you forgot
- You never saw it catch the bug

Test-first forces you to see the test fail, proving it actually tests something.

**"I already manually tested all the edge cases"**

Manual testing is ad-hoc. You think you tested everything but:
- No record of what you tested
- Can't re-run when code changes
- Easy to forget cases under pressure
- "It worked when I tried it" ≠ comprehensive

Automated tests are systematic. They run the same way every time.

**"Deleting X hours of work is wasteful"**

Sunk cost fallacy. The time is already gone. Your choice now:
- Delete and rewrite with TDD (X more hours, high confidence)
- Keep it and add tests after (30 min, low confidence, likely bugs)

The "waste" is keeping code you can't trust. Working code without real tests is technical debt.

**"TDD is dogmatic, being pragmatic means adapting"**

TDD IS pragmatic:
- Finds bugs before commit (faster than debugging after)
- Prevents regressions (tests catch breaks immediately)
- Documents behavior (tests show how to use code)
- Enables refactoring (change freely, tests catch breaks)

"Pragmatic" shortcuts = debugging in production = slower.

**"Tests after achieve the same goals - it's spirit not ritual"**

No. Tests-after answer "What does this do?" Tests-first answer "What should this do?"

Tests-after are biased by your implementation. You test what you built, not what's required. You verify remembered edge cases, not discovered ones.

Tests-first force edge case discovery before implementing. Tests-after verify you remembered everything (you didn't).

30 minutes of tests after ≠ TDD. You get coverage, lose proof tests work.

## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Too simple to test" | Simple code breaks. Test takes 30 seconds. |
| "I'll test after" | Tests passing immediately prove nothing. |
| "Tests after achieve same goals" | Tests-after = "what does this do?" Tests-first = "what should this do?" |
| "Already manually tested" | Ad-hoc ≠ systematic. No record, can't re-run. |
| "Deleting X hours is wasteful" | Sunk cost fallacy. Keeping unverified code is technical debt. |
| "Keep as reference, write tests first" | You'll adapt it. That's testing after. Delete means delete. |
| "Need to explore first" | Fine. Throw away exploration, start with TDD. |
| "Test hard = design unclear" | Listen to test. Hard to test = hard to use. |
| "TDD will slow me down" | TDD faster than debugging. Pragmatic = test-first. |
| "Manual test faster" | Manual doesn't prove edge cases. You'll re-test every change. |
| "Existing code has no tests" | You're improving it. Add tests for existing code. |

## Red Flags - STOP and Start Over

- Code before test
- Test after implementation
- Test passes immediately
- Can't explain why test failed
- Tests added "later"
- Rationalizing "just this once"
- "I already manually tested it"
- "Tests after achieve the same purpose"
- "It's about spirit not ritual"
- "Keep as reference" or "adapt existing code"
- "Already spent X hours, deleting is wasteful"
- "TDD is dogmatic, I'm being pragmatic"
- "This is different because..."

**All of these mean: Delete code. Start over with TDD.**

## Example: Bug Fix

**Bug:** Empty email accepted

**RED**
\`\`\`typescript
test('rejects empty email', async () => {
  const result = await submitForm({ email: '' });
  expect(result.error).toBe('Email required');
});
\`\`\`

**Verify RED**
\`\`\`bash
\$ npm test
FAIL: expected 'Email required', got undefined
\`\`\`

**GREEN**
\`\`\`typescript
function submitForm(data: FormData) {
  if (!data.email?.trim()) {
    return { error: 'Email required' };
  }
  // ...
}
\`\`\`

**Verify GREEN**
\`\`\`bash
\$ npm test
PASS
\`\`\`

**REFACTOR**
Extract validation for multiple fields if needed.

## Verification Checklist

Before marking work complete:

- [ ] Every new function/method has a test
- [ ] Watched each test fail before implementing
- [ ] Each test failed for expected reason (feature missing, not typo)
- [ ] Wrote minimal code to pass each test
- [ ] All tests pass
- [ ] Output pristine (no errors, warnings)
- [ ] Tests use real code (mocks only if unavoidable)
- [ ] Edge cases and errors covered

Can't check all boxes? You skipped TDD. Start over.

## When Stuck

| Problem | Solution |
|---------|----------|
| Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |
| Test too complicated | Design too complicated. Simplify interface. |
| Must mock everything | Code too coupled. Use dependency injection. |
| Test setup huge | Extract helpers. Still complex? Simplify design. |

## Debugging Integration

Bug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.

Never fix bugs without a test.

## Testing Anti-Patterns

When adding mocks or test utilities, read @testing-anti-patterns.md to avoid common pitfalls:
- Testing mock behavior instead of real behavior
- Adding test-only methods to production classes
- Mocking without understanding dependencies

## Final Rule

\`\`\`
Production code → test exists and failed first
Otherwise → not TDD
\`\`\`

No exceptions without your human partner's permission.
`,
};
